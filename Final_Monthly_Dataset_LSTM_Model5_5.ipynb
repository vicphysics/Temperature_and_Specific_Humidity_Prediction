{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0008f5-916a-4ef8-a990-bd9896704778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:49:44,293] A new study created in memory with name: no-name-ad476e46-995c-4da6-9479-d5d70e309149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1619 - val_loss: 0.3358\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1279 - val_loss: 0.2745\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0633 - val_loss: 0.2144\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 0.1643\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0451 - val_loss: 0.1585\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0487 - val_loss: 0.1717\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0341 - val_loss: 0.1937\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0109 - val_loss: 0.2205\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0163 - val_loss: 0.2368\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0322 - val_loss: 0.2292\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0245 - val_loss: 0.2188\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0152 - val_loss: 0.2052\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.1890\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0142 - val_loss: 0.1807\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0223 - val_loss: 0.1784\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0246 - val_loss: 0.1806\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0223 - val_loss: 0.1864\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0164 - val_loss: 0.1951\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0077 - val_loss: 0.2062\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2124\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0095 - val_loss: 0.2146\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0116 - val_loss: 0.2133\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0103 - val_loss: 0.2092\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - val_loss: 0.2026\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4273e-04 - val_loss: 0.1997\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2031\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.2195e-05 - val_loss: 0.2030\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.9056e-05 - val_loss: 0.2003\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2006\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2034\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9823e-04 - val_loss: 0.2034\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.3134e-04 - val_loss: 0.2007\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2009\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2037\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3148e-04 - val_loss: 0.2036\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4695e-04 - val_loss: 0.2010\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2012\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2038\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.0344e-04 - val_loss: 0.2038\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0684e-04 - val_loss: 0.2012\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2014\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.3327e-04 - val_loss: 0.2039\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.2877e-04 - val_loss: 0.2013\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2015\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2041\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2040\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.2545e-04 - val_loss: 0.2014\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2016\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2015\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2017\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2017\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2019\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2044\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2019\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2045\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2019\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7497e-04 - val_loss: 0.2046\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2045\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.1849e-04 - val_loss: 0.2046\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2045\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2022\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.6243e-04 - val_loss: 0.2047\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2046\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2021\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.5113e-04 - val_loss: 0.2023\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.0656e-04 - val_loss: 0.2048\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2046\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.9519e-04 - val_loss: 0.2023\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.5078e-04 - val_loss: 0.2048\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2047\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.3928e-04 - val_loss: 0.2024\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9496e-04 - val_loss: 0.2049\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8328e-04 - val_loss: 0.2024\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.3913e-04 - val_loss: 0.2049\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2048\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.2713e-04 - val_loss: 0.2025\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8313e-04 - val_loss: 0.2050\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2024\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.7088e-04 - val_loss: 0.2025\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2695e-04 - val_loss: 0.2050\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2049\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2024\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1443e-04 - val_loss: 0.2026\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7065e-04 - val_loss: 0.2051\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2050\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2025\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5778e-04 - val_loss: 0.2027\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1409e-04 - val_loss: 0.2051\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2050\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0093e-04 - val_loss: 0.2027\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.5729e-04 - val_loss: 0.2052\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.2051\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2026\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.4382e-04 - val_loss: 0.2028\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0032e-04 - val_loss: 0.2052\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2051\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2027\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.8657e-04 - val_loss: 0.2028\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.4316e-04 - val_loss: 0.2053\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2052\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2027\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2903e-04 - val_loss: 0.2029\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.8567e-04 - val_loss: 0.2054\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0022 - val_loss: 0.2028\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.7122e-04 - val_loss: 0.2029\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2799e-04 - val_loss: 0.2054\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2053\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2029\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.1324e-04 - val_loss: 0.2030\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.0080e-05 - val_loss: 0.2055\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2054\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2029\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.5503e-04 - val_loss: 0.2031\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1995e-05 - val_loss: 0.2055\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - val_loss: 0.2054\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.6604e-05 - val_loss: 0.2031\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.6372e-05 - val_loss: 0.2009\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2013\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4323e-04 - val_loss: 0.2040\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.9797e-04 - val_loss: 0.2017\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2046\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2022\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.4846e-04 - val_loss: 0.2025\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1588e-04 - val_loss: 0.2050\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2050\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8018e-04 - val_loss: 0.2028\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7862e-04 - val_loss: 0.2053\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2052\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2029\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1800e-04 - val_loss: 0.2030\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6821e-05 - val_loss: 0.2055\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2054\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2031\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5377e-05 - val_loss: 0.2032\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4237e-04 - val_loss: 0.2011\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2014\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2041\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.9696e-04 - val_loss: 0.2042\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 8.8666e-04 - val_loss: 0.2048\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2048\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2025\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0402e-04 - val_loss: 0.2027\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6378e-04 - val_loss: 0.2052\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2052\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.2029\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.0641e-04 - val_loss: 0.2031\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4901e-08 - val_loss: 0.2056\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2032\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.5251e-05 - val_loss: 0.1987\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.1970\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - val_loss: 0.1979\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 0.2009\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2059\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2082\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2079\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0048 - val_loss: 0.2053\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2008\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.1989\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - val_loss: 0.1996\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:49:58,651] Trial 0 finished with value: 0.003493368625640869 and parameters: {}. Best is trial 0 with value: 0.003493368625640869.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1327 - val_loss: 0.2654\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0295 - val_loss: 0.1705\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0644 - val_loss: 0.1992\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0080 - val_loss: 0.2253\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0220 - val_loss: 0.2149\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0118 - val_loss: 0.2004\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.1995\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - val_loss: 0.2061\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2064\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2024\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.4667e-04 - val_loss: 0.2025\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.2334e-05 - val_loss: 0.2056\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.2044\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.1992\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.1992\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2023\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.3777e-04 - val_loss: 0.2020\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.1692e-04 - val_loss: 0.2046\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2041\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2011\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.9672e-04 - val_loss: 0.2007\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2031\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.9508e-04 - val_loss: 0.2030\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1581e-04 - val_loss: 0.2006\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2006\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2029\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6516e-04 - val_loss: 0.2028\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0214e-04 - val_loss: 0.2004\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2005\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2028\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9357e-04 - val_loss: 0.2026\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4378e-04 - val_loss: 0.2004\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6774e-04 - val_loss: 0.2026\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2849e-04 - val_loss: 0.2004\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2026\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7740e-04 - val_loss: 0.2025\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6313e-05 - val_loss: 0.2003\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2005\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1431e-04 - val_loss: 0.2025\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0237e-05 - val_loss: 0.2045\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2042\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2019\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.9799e-04 - val_loss: 0.2018\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3987e-04 - val_loss: 0.2038\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2014\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.4978e-04 - val_loss: 0.2033\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.5643e-04 - val_loss: 0.2011\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2011\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2032\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6937e-04 - val_loss: 0.2030\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.0703e-04 - val_loss: 0.2009\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2010\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2030\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.9463e-04 - val_loss: 0.2029\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5320e-04 - val_loss: 0.2008\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2030\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9109e-04 - val_loss: 0.2029\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6399e-04 - val_loss: 0.2008\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2029\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3594e-04 - val_loss: 0.2028\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1875e-04 - val_loss: 0.2008\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1414e-04 - val_loss: 0.2029\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0391e-04 - val_loss: 0.2008\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1553e-04 - val_loss: 0.2029\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1024e-04 - val_loss: 0.2008\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2030\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3326e-04 - val_loss: 0.2029\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3164e-04 - val_loss: 0.2009\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2010\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.6277e-04 - val_loss: 0.2030\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6387e-04 - val_loss: 0.2009\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2011\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0094e-04 - val_loss: 0.2030\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0410e-04 - val_loss: 0.2010\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2011\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4554e-04 - val_loss: 0.2031\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5035e-04 - val_loss: 0.2011\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9510e-04 - val_loss: 0.2032\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0129e-04 - val_loss: 0.2011\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2013\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4855e-04 - val_loss: 0.2032\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.5581e-04 - val_loss: 0.2012\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2013\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0512e-04 - val_loss: 0.2033\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1330e-04 - val_loss: 0.2013\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2014\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6420e-04 - val_loss: 0.2034\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7325e-04 - val_loss: 0.2014\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2015\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.2552e-04 - val_loss: 0.2034\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3521e-04 - val_loss: 0.2014\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.8857e-04 - val_loss: 0.2035\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9889e-04 - val_loss: 0.2015\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2016\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5313e-04 - val_loss: 0.2036\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6409e-04 - val_loss: 0.2016\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2038\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1909e-04 - val_loss: 0.2037\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.3053e-04 - val_loss: 0.2017\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.8622e-04 - val_loss: 0.2037\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9817e-04 - val_loss: 0.2018\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.5436e-04 - val_loss: 0.2038\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6670e-04 - val_loss: 0.2018\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9578e-04 - val_loss: 0.2040\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.3623e-04 - val_loss: 0.2019\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2020\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.2205e-04 - val_loss: 0.2041\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2020\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7096e-04 - val_loss: 0.2021\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4761e-04 - val_loss: 0.2041\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.9590e-04 - val_loss: 0.2022\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.7263e-04 - val_loss: 0.2042\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2022\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2025e-04 - val_loss: 0.2023\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.9703e-04 - val_loss: 0.2043\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.4416e-04 - val_loss: 0.2024\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2099e-04 - val_loss: 0.2044\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2023\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6760e-04 - val_loss: 0.2025\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4449e-04 - val_loss: 0.2044\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2024\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9058e-04 - val_loss: 0.2025\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6758e-04 - val_loss: 0.2045\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2025\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1324e-04 - val_loss: 0.2026\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.9037e-04 - val_loss: 0.2046\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2045\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3561e-04 - val_loss: 0.2027\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1278e-04 - val_loss: 0.2047\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2046\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2027\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5766e-04 - val_loss: 0.2028\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3498e-04 - val_loss: 0.2048\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2047\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7946e-04 - val_loss: 0.2029\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5691e-04 - val_loss: 0.2048\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2048\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0108e-04 - val_loss: 0.2029\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8589e-05 - val_loss: 0.2049\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2048\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2029\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2244e-04 - val_loss: 0.2030\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0431e-07 - val_loss: 0.2050\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2049\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3705e-05 - val_loss: 0.2031\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8544e-05 - val_loss: 0.2014\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:50:13,094] Trial 1 finished with value: 0.0016757100820541382 and parameters: {}. Best is trial 1 with value: 0.0016757100820541382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1576 - val_loss: 0.3052\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0867 - val_loss: 0.2302\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0170 - val_loss: 0.1819\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0256 - val_loss: 0.1749\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0294 - val_loss: 0.1830\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0192 - val_loss: 0.2001\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.4606e-04 - val_loss: 0.2209\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0198 - val_loss: 0.2292\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0273 - val_loss: 0.2295\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0272 - val_loss: 0.2247\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0221 - val_loss: 0.2161\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0134 - val_loss: 0.2047\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.1927\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0104 - val_loss: 0.1863\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0166 - val_loss: 0.1845\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0184 - val_loss: 0.1861\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0168 - val_loss: 0.1904\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0125 - val_loss: 0.1970\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.2055\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2102\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.2117\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0089 - val_loss: 0.2106\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0077 - val_loss: 0.2073\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2022\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.0557e-04 - val_loss: 0.2000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2001\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2022\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8255e-04 - val_loss: 0.2061\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2076\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - val_loss: 0.2070\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2047\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2008\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.1992\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.1995\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2015\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2050\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2064\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2060\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2041\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0011 - val_loss: 0.2007\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.1992\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.1996\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2015\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2048\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2062\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2059\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2041\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2009\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.1996\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.1999\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2018\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2050\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2063\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2060\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2043\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2012\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.1999\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2003\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2021\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.2027e-04 - val_loss: 0.2052\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2066\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2063\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2046\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2015\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2003\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2007\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2024\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8816e-04 - val_loss: 0.2055\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2068\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2066\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2049\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2019\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2007\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2010\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6274e-04 - val_loss: 0.2058\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2071\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2068\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2052\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2022\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.2977e-04 - val_loss: 0.2010\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2013\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2974e-05 - val_loss: 0.2032\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9558e-04 - val_loss: 0.2019\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2022\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5010e-04 - val_loss: 0.2039\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1664e-04 - val_loss: 0.2039\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.8859e-04 - val_loss: 0.2026\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7426e-04 - val_loss: 0.2028\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7247e-04 - val_loss: 0.2044\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2030\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.8296e-05 - val_loss: 0.2032\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2526e-04 - val_loss: 0.2019\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.7686e-04 - val_loss: 0.2038\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9729e-04 - val_loss: 0.2039\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.8301e-04 - val_loss: 0.2026\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.6085e-04 - val_loss: 0.2028\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4842e-04 - val_loss: 0.2044\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2044\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2031\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2115e-05 - val_loss: 0.2004\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.1994\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - val_loss: 0.2000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2019\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2050\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2064\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2063\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2048\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2009\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2013\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.3869e-05 - val_loss: 0.2033\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5386e-04 - val_loss: 0.2021\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6777e-04 - val_loss: 0.2024\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5547e-04 - val_loss: 0.2041\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2042\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2029\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4856e-04 - val_loss: 0.2031\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7202e-05 - val_loss: 0.2019\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7513e-04 - val_loss: 0.2040\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.3204e-04 - val_loss: 0.2041\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1748e-04 - val_loss: 0.2031\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1859e-05 - val_loss: 0.2019\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0509e-04 - val_loss: 0.2040\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.0963e-04 - val_loss: 0.2041\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2082e-04 - val_loss: 0.2031\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5584e-05 - val_loss: 0.2019\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8747e-04 - val_loss: 0.2040\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.3044e-04 - val_loss: 0.2041\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8936e-04 - val_loss: 0.2031\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.0676e-05 - val_loss: 0.2020\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.4461e-04 - val_loss: 0.2040\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.7412e-04 - val_loss: 0.2042\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3949e-04 - val_loss: 0.2032\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2234e-04 - val_loss: 0.2020\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8840e-04 - val_loss: 0.2041\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2042\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.9930e-05 - val_loss: 0.2032\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8272e-04 - val_loss: 0.2021\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.7924e-04 - val_loss: 0.2024\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.2527e-04 - val_loss: 0.2042\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2043\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5348e-05 - val_loss: 0.2033\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4760e-04 - val_loss: 0.2022\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.1250e-04 - val_loss: 0.2025\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5851e-04 - val_loss: 0.2042\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1841e-05 - val_loss: 0.2006\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.1997\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2003\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2023\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9460e-04 - val_loss: 0.2054\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2069\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.2068\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2053\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2026\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4282e-04 - val_loss: 0.2016\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2038\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.6684e-04 - val_loss: 0.2041\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9957e-04 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7595e-04 - val_loss: 0.2032\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5233e-04 - val_loss: 0.2021\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.3871e-04 - val_loss: 0.2025\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3273e-04 - val_loss: 0.2043\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0640e-04 - val_loss: 0.2008\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0031 - val_loss: 0.2006\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2026\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0910e-04 - val_loss: 0.2057\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2072\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2071\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2057\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2030\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4716e-05 - val_loss: 0.2020\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2191e-04 - val_loss: 0.2042\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5687e-04 - val_loss: 0.2009\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2001\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2008\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:50:27,528] Trial 2 finished with value: 0.00229664146900177 and parameters: {}. Best is trial 1 with value: 0.0016757100820541382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1223 - val_loss: 0.2190\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0085 - val_loss: 0.2177\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0158 - val_loss: 0.2057\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.1852\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0165 - val_loss: 0.1882\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0131 - val_loss: 0.2011\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.2664e-04 - val_loss: 0.2009\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5684e-05 - val_loss: 0.2090\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0085 - val_loss: 0.2077\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0069 - val_loss: 0.2003\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.1995\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2034\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.4245e-04 - val_loss: 0.1980\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.1977\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.2011\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6858e-04 - val_loss: 0.2075\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2098\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0076 - val_loss: 0.2086\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0064 - val_loss: 0.2044\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.1978\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.1949\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0074 - val_loss: 0.1952\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0071 - val_loss: 0.1983\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2038\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2059\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2053\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2023\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8944e-04 - val_loss: 0.2020\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5958e-04 - val_loss: 0.2042\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2011\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2010\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1075e-04 - val_loss: 0.2030\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1970e-04 - val_loss: 0.2004\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2004\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2027\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7298e-05 - val_loss: 0.2025\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6993e-04 - val_loss: 0.2046\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.9981e-04 - val_loss: 0.2035\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3382e-04 - val_loss: 0.2010\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2010\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0592e-04 - val_loss: 0.2031\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1225e-04 - val_loss: 0.2007\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2008\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2030\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.5812e-04 - val_loss: 0.2029\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1155e-04 - val_loss: 0.2006\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2029\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7008e-04 - val_loss: 0.2028\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4330e-05 - val_loss: 0.2006\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2030\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8591e-04 - val_loss: 0.2029\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0435e-05 - val_loss: 0.2007\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2008\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2031\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6938e-04 - val_loss: 0.2030\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8729e-04 - val_loss: 0.2008\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2032\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.9662e-04 - val_loss: 0.2031\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.2340e-04 - val_loss: 0.2010\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2011\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5222e-04 - val_loss: 0.2033\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8488e-04 - val_loss: 0.2012\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2013\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.2579e-04 - val_loss: 0.2035\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6236e-04 - val_loss: 0.2014\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.1049e-04 - val_loss: 0.2037\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4975e-04 - val_loss: 0.2016\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2018\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2020\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7747e-04 - val_loss: 0.2041\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2041\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.2724e-04 - val_loss: 0.2022\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6702e-04 - val_loss: 0.2043\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2043\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1575e-04 - val_loss: 0.2024\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.5618e-04 - val_loss: 0.2045\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2045\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2025\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0485e-04 - val_loss: 0.2026\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4615e-04 - val_loss: 0.2047\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2047\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0018 - val_loss: 0.2027\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9531e-04 - val_loss: 0.2028\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7640e-05 - val_loss: 0.2050\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2249e-05 - val_loss: 0.1991\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.1976\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.1984\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.2010\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2054\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2073\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2071\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2051\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2013\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.1998\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2004\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2029\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3066e-05 - val_loss: 0.2033\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5195e-04 - val_loss: 0.2016\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.0545e-04 - val_loss: 0.2044\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2046\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.6718e-05 - val_loss: 0.2032\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1465e-04 - val_loss: 0.2017\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2021\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.7511e-04 - val_loss: 0.2044\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2046\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2030\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0768e-05 - val_loss: 0.1996\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.1985\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.1993\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.2019\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.9963e-04 - val_loss: 0.2061\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2080\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0051 - val_loss: 0.2080\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.2061\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2027\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8653e-04 - val_loss: 0.2013\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2020\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.6214e-04 - val_loss: 0.2044\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2032\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7998e-04 - val_loss: 0.2001\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.1991\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2026\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4976e-04 - val_loss: 0.2067\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2086\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0057 - val_loss: 0.2086\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0056 - val_loss: 0.2069\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 0.2036\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0147e-04 - val_loss: 0.1988\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.1963\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0067 - val_loss: 0.1958\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0071 - val_loss: 0.1972\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0058 - val_loss: 0.2002\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2046\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2069\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - val_loss: 0.2071\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2057\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2027\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5795e-04 - val_loss: 0.2018\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2026\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1464e-04 - val_loss: 0.2050\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2055\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2043\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2015\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2007\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - val_loss: 0.2016\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2048\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6493e-04 - val_loss: 0.2010\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2003\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2039\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.5902e-04 - val_loss: 0.2045\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6262e-04 - val_loss: 0.2009\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2002\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2012\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.1763e-04 - val_loss: 0.2045\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.8125e-04 - val_loss: 0.2009\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2013\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2039\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.1869e-04 - val_loss: 0.2047\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1390e-04 - val_loss: 0.2011\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2004\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2015\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.0407e-04 - val_loss: 0.2013\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2007\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:50:42,072] Trial 3 finished with value: 0.002364411950111389 and parameters: {}. Best is trial 1 with value: 0.0016757100820541382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1448 - val_loss: 0.2342\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8132e-04 - val_loss: 0.1137\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0934 - val_loss: 0.1225\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0774 - val_loss: 0.1617\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0353 - val_loss: 0.2157\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0184 - val_loss: 0.2299\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0307 - val_loss: 0.2211\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0209 - val_loss: 0.2005\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4830e-04 - val_loss: 0.1958\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2014\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0174e-04 - val_loss: 0.1980\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2015\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9077e-04 - val_loss: 0.1954\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0066 - val_loss: 0.1977\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 0.2062\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2072\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - val_loss: 0.2023\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4797e-04 - val_loss: 0.2035\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.6631e-04 - val_loss: 0.1994\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2072\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2079\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2039\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5363e-04 - val_loss: 0.1959\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0074 - val_loss: 0.1932\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0100 - val_loss: 0.1952\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0080 - val_loss: 0.2012\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2106\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.2149\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0116 - val_loss: 0.2146\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0113 - val_loss: 0.2104\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0071 - val_loss: 0.2028\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9728e-04 - val_loss: 0.1999\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2011\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2057\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2063\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2032\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0589e-04 - val_loss: 0.2040\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.7510e-04 - val_loss: 0.2011\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2021\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2065\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.2069\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2039\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6927e-04 - val_loss: 0.1977\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0057 - val_loss: 0.1956\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0078 - val_loss: 0.1971\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.2019\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2095\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0061 - val_loss: 0.2130\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0096 - val_loss: 0.2128\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0093 - val_loss: 0.2092\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.2028\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6189e-04 - val_loss: 0.2002\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2013\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2055\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2061\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2033\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4041e-04 - val_loss: 0.2040\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1288e-04 - val_loss: 0.2014\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2024\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2065\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2069\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2041\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4979e-04 - val_loss: 0.1982\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.1963\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0071 - val_loss: 0.1977\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0056 - val_loss: 0.2023\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2096\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0062 - val_loss: 0.2129\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0095 - val_loss: 0.2127\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0093 - val_loss: 0.2094\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0060 - val_loss: 0.2032\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1125e-04 - val_loss: 0.2008\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2018\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2059\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2065\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2038\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.9332e-04 - val_loss: 0.1982\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0052 - val_loss: 0.1963\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0070 - val_loss: 0.1978\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.2023\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2095\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0062 - val_loss: 0.2129\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0095 - val_loss: 0.2127\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0094 - val_loss: 0.2095\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - val_loss: 0.2034\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6278e-05 - val_loss: 0.1948\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0085 - val_loss: 0.1903\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0130 - val_loss: 0.1893\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0140 - val_loss: 0.1916\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0117 - val_loss: 0.1968\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0066 - val_loss: 0.2045\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2084\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.2088\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.2060\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2005\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.1986\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - val_loss: 0.2000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2043\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2051\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9546e-04 - val_loss: 0.2038\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6970e-04 - val_loss: 0.2016\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.1765e-04 - val_loss: 0.2067\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - val_loss: 0.2073\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - val_loss: 0.2048\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 0.1995\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.1978\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0055 - val_loss: 0.1992\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 0.2036\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.3596e-04 - val_loss: 0.2045\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2023\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.5671e-04 - val_loss: 0.2034\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.4028e-05 - val_loss: 0.2013\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 0.2024\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8.5174e-04 - val_loss: 0.2065\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - val_loss: 0.2071\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.2047\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.1995\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.1978\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0055 - val_loss: 0.1993\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0040 - val_loss: 0.2037\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1310e-04 - val_loss: 0.2046\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.1721e-04 - val_loss: 0.2035\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4135e-04 - val_loss: 0.2015\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2026\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4903e-04 - val_loss: 0.2067\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2073\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2049\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.1997\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.1981\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.1996\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2040\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9864e-04 - val_loss: 0.2049\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2028\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1002e-04 - val_loss: 0.2038\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4994e-04 - val_loss: 0.2018\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2029\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2486e-04 - val_loss: 0.2070\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2076\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2052\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2001\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.1984\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2043\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2052\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2031\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5731e-04 - val_loss: 0.2042\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.9930e-04 - val_loss: 0.2021\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.1933e-05 - val_loss: 0.2014\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6639e-04 - val_loss: 0.2067\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2074\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.2051\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.1984\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2043\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8950e-05 - val_loss: 0.2043\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2023\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.5679e-04 - val_loss: 0.2035\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1659e-04 - val_loss: 0.2016\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3899e-04 - val_loss: 0.2069\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2076\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2053\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.1987\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - val_loss: 0.2003\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2046\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2056\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2035\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.7858e-04 - val_loss: 0.1987\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - val_loss: 0.1973\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0059 - val_loss: 0.1990\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0042 - val_loss: 0.2035\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.9463e-04 - val_loss: 0.2046\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2027\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5610e-04 - val_loss: 0.2039\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3013e-04 - val_loss: 0.2020\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6004e-05 - val_loss: 0.2015\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7708e-04 - val_loss: 0.2069\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2077\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.2054\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2005\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.1990\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.2006\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2049\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2059\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2039\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.4696e-04 - val_loss: 0.1991\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.1978\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0055 - val_loss: 0.1995\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:50:57,220] Trial 4 finished with value: 0.003726065158843994 and parameters: {}. Best is trial 1 with value: 0.0016757100820541382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1425 - val_loss: 0.2932\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0724 - val_loss: 0.2180\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0073 - val_loss: 0.1634\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0416 - val_loss: 0.1507\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0516 - val_loss: 0.1540\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0476 - val_loss: 0.1643\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0372 - val_loss: 0.1782\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0233 - val_loss: 0.1941\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0074 - val_loss: 0.2114\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0099 - val_loss: 0.2203\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0185 - val_loss: 0.2234\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0216 - val_loss: 0.2224\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0205 - val_loss: 0.2184\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0164 - val_loss: 0.2124\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0103 - val_loss: 0.2051\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.1966\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.1919\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0108 - val_loss: 0.1900\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0128 - val_loss: 0.1906\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0123 - val_loss: 0.1930\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0098 - val_loss: 0.1970\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2021\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5497e-04 - val_loss: 0.2081\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0053 - val_loss: 0.2118\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0090 - val_loss: 0.2133\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0105 - val_loss: 0.2130\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0102 - val_loss: 0.2112\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0084 - val_loss: 0.2081\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.2038\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.0212e-04 - val_loss: 0.1985\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.1953\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0077 - val_loss: 0.1940\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0090 - val_loss: 0.1943\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0087 - val_loss: 0.1961\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0070 - val_loss: 0.1991\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2033\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2806e-04 - val_loss: 0.2056\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2062\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2054\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2033\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0313e-04 - val_loss: 0.2000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.1984\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.1984\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.1998\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2024\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6018e-04 - val_loss: 0.2062\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2081\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2086\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.2076\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.2054\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2021\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2004\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2003\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2015\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1028e-04 - val_loss: 0.2049\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0710e-04 - val_loss: 0.2022\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.1712e-04 - val_loss: 0.2033\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5411e-04 - val_loss: 0.2029\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2873e-04 - val_loss: 0.2039\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7206e-04 - val_loss: 0.2034\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.3033e-04 - val_loss: 0.2017\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8216e-04 - val_loss: 0.2050\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2058\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2052\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8843e-04 - val_loss: 0.2003\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.1989\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.1990\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2004\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2030\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.2896e-05 - val_loss: 0.2067\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2087\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.2092\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.2083\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.2062\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2030\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3220e-04 - val_loss: 0.2014\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2013\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2026\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3804e-04 - val_loss: 0.2050\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2059\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2054\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2036\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9981e-04 - val_loss: 0.2007\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.1994\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.1995\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2010\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2036\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2731e-04 - val_loss: 0.2047\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1932e-04 - val_loss: 0.2025\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7797e-04 - val_loss: 0.2037\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0265e-04 - val_loss: 0.2035\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4475e-04 - val_loss: 0.2019\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.4498e-05 - val_loss: 0.2055\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2064\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.2059\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.2041\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2012\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.1999\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2001\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - val_loss: 0.2016\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2033\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5131e-04 - val_loss: 0.2005\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.1993\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.1995\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2011\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2038\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.0170e-04 - val_loss: 0.2049\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0622e-05 - val_loss: 0.2030\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3267e-04 - val_loss: 0.2042\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7534e-04 - val_loss: 0.2025\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2309e-04 - val_loss: 0.2025\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6008e-04 - val_loss: 0.2037\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1816e-04 - val_loss: 0.2036\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6000e-04 - val_loss: 0.2021\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9173e-04 - val_loss: 0.2021\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.8599e-04 - val_loss: 0.2035\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.3107e-04 - val_loss: 0.2033\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0745e-04 - val_loss: 0.2019\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6278e-04 - val_loss: 0.2032\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1810e-05 - val_loss: 0.2018\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.2345e-05 - val_loss: 0.2031\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3694e-05 - val_loss: 0.2043\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2027\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6507e-04 - val_loss: 0.2026\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9168e-04 - val_loss: 0.2039\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9255e-04 - val_loss: 0.2038\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4306e-04 - val_loss: 0.2023\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9784e-04 - val_loss: 0.2023\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8543e-04 - val_loss: 0.2037\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3471e-04 - val_loss: 0.2035\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1682e-04 - val_loss: 0.2021\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9625e-04 - val_loss: 0.2022\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.5825e-04 - val_loss: 0.2035\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.8540e-04 - val_loss: 0.2034\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.8814e-04 - val_loss: 0.2020\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0729e-04 - val_loss: 0.2033\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.2367e-04 - val_loss: 0.2020\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.7591e-04 - val_loss: 0.2033\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0121e-04 - val_loss: 0.2019\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.7514e-04 - val_loss: 0.2033\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0635e-04 - val_loss: 0.2020\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9445e-04 - val_loss: 0.2034\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2951e-04 - val_loss: 0.2020\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2690e-04 - val_loss: 0.2034\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6456e-04 - val_loss: 0.2020\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2035\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6801e-04 - val_loss: 0.2034\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0732e-04 - val_loss: 0.2021\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2027\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.0580e-04 - val_loss: 0.2050\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2053\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.6184e-04 - val_loss: 0.2010\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.2008\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - val_loss: 0.2031\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.8013e-05 - val_loss: 0.2068\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - val_loss: 0.2085\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - val_loss: 0.2084\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0052 - val_loss: 0.2068\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - val_loss: 0.2037\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.8505e-04 - val_loss: 0.1995\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - val_loss: 0.1972\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - val_loss: 0.1967\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0064 - val_loss: 0.1978\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0053 - val_loss: 0.2004\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2041\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.9175e-04 - val_loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:51:12,345] Trial 5 finished with value: 0.002862483263015747 and parameters: {}. Best is trial 1 with value: 0.0016757100820541382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1796 - val_loss: 0.3011\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0877 - val_loss: 0.2340\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0227 - val_loss: 0.1729\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0398 - val_loss: 0.1665\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0403 - val_loss: 0.1832\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0203 - val_loss: 0.2102\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0078 - val_loss: 0.2194\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0161 - val_loss: 0.2181\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0143 - val_loss: 0.2101\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.1968\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0079 - val_loss: 0.1911\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0133 - val_loss: 0.1924\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0115 - val_loss: 0.1989\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.2086\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.2128\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0093 - val_loss: 0.2127\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0092 - val_loss: 0.2094\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.2032\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0269e-04 - val_loss: 0.2009\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2021\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2059\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2066\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2044\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7283e-04 - val_loss: 0.1998\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.1984\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.1998\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2035\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3850e-05 - val_loss: 0.2092\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - val_loss: 0.2118\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - val_loss: 0.2119\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0084 - val_loss: 0.2098\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.2057\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.1998\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.1967\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0069 - val_loss: 0.1962\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.1980\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0055 - val_loss: 0.2018\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2072\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2100\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0065 - val_loss: 0.2104\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0069 - val_loss: 0.2088\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - val_loss: 0.2053\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2002\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.1976\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - val_loss: 0.1973\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.1991\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2026\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2633e-04 - val_loss: 0.2077\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.2104\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0070 - val_loss: 0.2108\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.2094\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.2062\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2014\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.1990\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - val_loss: 0.1987\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.2004\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2038\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9473e-04 - val_loss: 0.2050\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6863e-04 - val_loss: 0.2016\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2011\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2026\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2529e-04 - val_loss: 0.2057\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2067\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0033 - val_loss: 0.2058\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2031\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9370e-04 - val_loss: 0.2025\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6479e-04 - val_loss: 0.2039\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6408e-04 - val_loss: 0.2032\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7639e-04 - val_loss: 0.2045\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8509e-04 - val_loss: 0.2013\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2009\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2024\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.4743e-04 - val_loss: 0.2056\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2066\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2058\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2032\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1793e-04 - val_loss: 0.2026\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.4150e-04 - val_loss: 0.2040\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0987e-04 - val_loss: 0.2033\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3288e-05 - val_loss: 0.2047\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9258e-04 - val_loss: 0.2018\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2015\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2032\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.4369e-05 - val_loss: 0.2067\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.2079\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - val_loss: 0.2070\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2043\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.1999\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - val_loss: 0.1979\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.1980\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.2002\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2041\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0428e-04 - val_loss: 0.2056\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2050\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2024\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1308e-04 - val_loss: 0.2020\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.7723e-04 - val_loss: 0.2036\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6804e-04 - val_loss: 0.2031\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6147e-04 - val_loss: 0.2006\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2004\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2022\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4119e-04 - val_loss: 0.2058\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - val_loss: 0.2070\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2060\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.2032\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.1987\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.1967\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.1967\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 0.2007\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2046\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2062\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2056\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2030\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9036e-04 - val_loss: 0.2027\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0198e-04 - val_loss: 0.2045\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2040\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7674e-04 - val_loss: 0.2015\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2013\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2033\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2050e-05 - val_loss: 0.2030\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.9142e-04 - val_loss: 0.2048\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2686e-04 - val_loss: 0.2033\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6883e-05 - val_loss: 0.2051\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2020\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8557e-04 - val_loss: 0.2035\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4426e-04 - val_loss: 0.2011\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2010\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6561e-04 - val_loss: 0.2070\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2085\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.2078\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2050\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2005\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1985\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.1987\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.2011\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2053\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0020 - val_loss: 0.2070\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2065\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2040\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0615e-04 - val_loss: 0.1997\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.1978\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.1983\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.2007\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2050\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2063\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2039\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7067e-04 - val_loss: 0.1998\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.1980\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.1985\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.2010\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2070\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2066\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2043\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - val_loss: 0.2002\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.1985\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.1990\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2015\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2056\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2074\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2071\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2048\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.1991\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - val_loss: 0.1996\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - val_loss: 0.2021\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2062\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2079\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.2076\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.2053\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.1998\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - val_loss: 0.2003\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2027\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7869e-04 - val_loss: 0.2067\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - val_loss: 0.2084\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - val_loss: 0.2081\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - val_loss: 0.2059\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.2020\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2004\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2009\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2032\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.6734e-05 - val_loss: 0.2035\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2605e-04 - val_loss: 0.2017\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2021\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2043\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2044\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:51:26,993] Trial 6 finished with value: 0.0005867928266525269 and parameters: {}. Best is trial 6 with value: 0.0005867928266525269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1517 - val_loss: 0.2792\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0537 - val_loss: 0.2008\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0170 - val_loss: 0.1933\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0153 - val_loss: 0.2145\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.2162\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0095 - val_loss: 0.2055\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2061\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9966e-04 - val_loss: 0.2146\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0081 - val_loss: 0.2141\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0077 - val_loss: 0.2070\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4984e-04 - val_loss: 0.1950\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0110 - val_loss: 0.1905\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0154 - val_loss: 0.1916\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0142 - val_loss: 0.1972\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0086 - val_loss: 0.2066\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.3603e-04 - val_loss: 0.2104\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.2094\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2044\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2040\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2073\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2066\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2053\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2515e-04 - val_loss: 0.2115\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.2136\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0081 - val_loss: 0.2122\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - val_loss: 0.2077\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2007\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 0.1975\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0076 - val_loss: 0.1976\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0074 - val_loss: 0.2006\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.2062\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2083\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2073\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2036\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2054\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.4774e-04 - val_loss: 0.2047\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.8860e-04 - val_loss: 0.2068\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2059\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2022\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2044\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2832e-04 - val_loss: 0.2090\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2105\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.2093\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.2057\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9644e-04 - val_loss: 0.1999\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.1973\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - val_loss: 0.1974\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - val_loss: 0.1999\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2046\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5060e-05 - val_loss: 0.2064\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2056\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2020\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2040\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5204e-04 - val_loss: 0.2082\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2095\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.2084\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.2050\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1996e-04 - val_loss: 0.1996\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.1972\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0071 - val_loss: 0.1972\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.1996\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.2040\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2535e-04 - val_loss: 0.2103\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.2136\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0093 - val_loss: 0.2143\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0100 - val_loss: 0.2127\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0084 - val_loss: 0.2090\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2034\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3272e-04 - val_loss: 0.2007\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - val_loss: 0.2004\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2024\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2063\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2077\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.2067\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2037\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9452e-04 - val_loss: 0.2032\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2040e-04 - val_loss: 0.2048\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4193e-04 - val_loss: 0.2042\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0793e-04 - val_loss: 0.2015\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2012\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2032\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7152e-04 - val_loss: 0.2076\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2091\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.2081\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2048\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9164e-04 - val_loss: 0.1996\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1973\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - val_loss: 0.1974\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - val_loss: 0.1998\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2042\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1032e-04 - val_loss: 0.2059\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2052\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2025\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2022\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6114e-04 - val_loss: 0.2036\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9838e-04 - val_loss: 0.2053\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2047\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.2876e-04 - val_loss: 0.2021\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2018\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.8468e-05 - val_loss: 0.2074\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2087\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2078\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2049\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2003\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.1982\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.1983\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.2005\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2045\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6443e-04 - val_loss: 0.2060\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2054\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.5033e-04 - val_loss: 0.2025\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2043\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8526e-04 - val_loss: 0.2038\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5119e-04 - val_loss: 0.2014\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2013\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2031\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3090e-04 - val_loss: 0.2068\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - val_loss: 0.2081\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2073\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2046\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.1234e-04 - val_loss: 0.2002\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.1982\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.1984\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.2005\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2044\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5404e-04 - val_loss: 0.2059\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2054\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2281e-04 - val_loss: 0.2027\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.8421e-04 - val_loss: 0.2043\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.0682e-04 - val_loss: 0.2039\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.0567e-04 - val_loss: 0.2017\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2015\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0637e-04 - val_loss: 0.2069\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2081\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - val_loss: 0.2074\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.2048\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2005\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.1986\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.1988\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.2009\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2046\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2061\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2056\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9393e-04 - val_loss: 0.2030\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4394e-04 - val_loss: 0.2046\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2042\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2305e-04 - val_loss: 0.2020\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6806e-05 - val_loss: 0.2033\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4876e-04 - val_loss: 0.2050\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2045\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4636e-04 - val_loss: 0.2023\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9014e-04 - val_loss: 0.2036\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4096e-05 - val_loss: 0.2052\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2047\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2040\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4918e-04 - val_loss: 0.2037\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3542e-04 - val_loss: 0.2016\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2015\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7348e-04 - val_loss: 0.2068\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2080\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2073\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2049\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1989\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.1992\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2012\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2049\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2064\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2059\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2036\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8545e-07 - val_loss: 0.2033\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2919e-04 - val_loss: 0.2050\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2046\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9014e-04 - val_loss: 0.2038\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1960e-04 - val_loss: 0.2017\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.9616e-05 - val_loss: 0.2069\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:51:46,247] Trial 7 finished with value: 0.004610776901245117 and parameters: {}. Best is trial 6 with value: 0.0005867928266525269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.1365 - val_loss: 0.2703\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0514 - val_loss: 0.1965\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0184 - val_loss: 0.2138\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0078 - val_loss: 0.2012\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0072 - val_loss: 0.2131\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0064 - val_loss: 0.2048\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2121\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.2059\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2112\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2061\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2104\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2060\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2097\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2058\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2092\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2057\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2088\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2055\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2084\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2054\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2082\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2053\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2080\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2078\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2077\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2050\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2076\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2075\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9067e-04 - val_loss: 0.2050\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2074\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.2995e-04 - val_loss: 0.2049\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2073\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.8020e-04 - val_loss: 0.2049\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2073\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3897e-04 - val_loss: 0.2049\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2072\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0413e-04 - val_loss: 0.2049\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2072\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7428e-04 - val_loss: 0.2049\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2072\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.4826e-04 - val_loss: 0.2048\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2071\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.2508e-04 - val_loss: 0.2048\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2071\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0436e-04 - val_loss: 0.2048\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2071\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.8541e-04 - val_loss: 0.2048\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2071\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.6806e-04 - val_loss: 0.2048\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2070\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5187e-04 - val_loss: 0.2048\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2070\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3680e-04 - val_loss: 0.2048\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2070\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2262e-04 - val_loss: 0.2048\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2070\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0940e-04 - val_loss: 0.2047\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2070\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9684e-04 - val_loss: 0.2047\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2069\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8492e-04 - val_loss: 0.2047\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2069\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7365e-04 - val_loss: 0.2047\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2069\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6295e-04 - val_loss: 0.2047\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2069\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5273e-04 - val_loss: 0.2047\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2069\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4297e-04 - val_loss: 0.2047\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2068\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3370e-04 - val_loss: 0.2047\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2068\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2480e-04 - val_loss: 0.2047\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2068\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1622e-04 - val_loss: 0.2047\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2068\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0800e-04 - val_loss: 0.2046\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2068\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0004e-04 - val_loss: 0.2046\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2068\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9230e-04 - val_loss: 0.2046\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8472e-04 - val_loss: 0.2046\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7745e-04 - val_loss: 0.2046\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7038e-04 - val_loss: 0.2046\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6334e-04 - val_loss: 0.2046\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5644e-04 - val_loss: 0.2046\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4967e-04 - val_loss: 0.2046\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0017 - val_loss: 0.2066\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4297e-04 - val_loss: 0.2046\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2066\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3629e-04 - val_loss: 0.2045\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2066\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2972e-04 - val_loss: 0.2045\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2066\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2319e-04 - val_loss: 0.2045\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2066\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1667e-04 - val_loss: 0.2045\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2066\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1021e-04 - val_loss: 0.2045\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2065\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0379e-04 - val_loss: 0.2045\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2065\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.9735e-04 - val_loss: 0.2045\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2065\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9096e-04 - val_loss: 0.2045\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2065\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.8458e-04 - val_loss: 0.2045\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2065\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.7824e-04 - val_loss: 0.2045\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2065\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7181e-04 - val_loss: 0.2044\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6553e-04 - val_loss: 0.2044\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.5921e-04 - val_loss: 0.2044\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5292e-04 - val_loss: 0.2044\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4665e-04 - val_loss: 0.2044\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4045e-04 - val_loss: 0.2044\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.3428e-04 - val_loss: 0.2044\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2812e-04 - val_loss: 0.2044\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2063\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2209e-04 - val_loss: 0.2044\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2063\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.1611e-04 - val_loss: 0.2043\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2063\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1015e-04 - val_loss: 0.2043\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.2063\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0439e-04 - val_loss: 0.2043\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2063\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.9860e-04 - val_loss: 0.2043\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2063\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.9302e-04 - val_loss: 0.2043\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8743e-04 - val_loss: 0.2043\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.8196e-04 - val_loss: 0.2043\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.7668e-04 - val_loss: 0.2043\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7153e-04 - val_loss: 0.2043\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6651e-04 - val_loss: 0.2043\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6157e-04 - val_loss: 0.2042\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5687e-04 - val_loss: 0.2042\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5225e-04 - val_loss: 0.2042\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4787e-04 - val_loss: 0.2042\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4351e-04 - val_loss: 0.2042\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3949e-04 - val_loss: 0.2042\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3563e-04 - val_loss: 0.2042\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3197e-04 - val_loss: 0.2042\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.2846e-04 - val_loss: 0.2042\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2519e-04 - val_loss: 0.2042\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2207e-04 - val_loss: 0.2042\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1926e-04 - val_loss: 0.2042\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.1659e-04 - val_loss: 0.2041\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1420e-04 - val_loss: 0.2041\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.1203e-04 - val_loss: 0.2041\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1006e-04 - val_loss: 0.2041\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0835e-04 - val_loss: 0.2041\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0686e-04 - val_loss: 0.2041\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0565e-04 - val_loss: 0.2041\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2059\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0459e-04 - val_loss: 0.2041\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2059\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0391e-04 - val_loss: 0.2041\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2059\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0345e-04 - val_loss: 0.2041\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:52:06,897] Trial 8 finished with value: 0.0016683340072631836 and parameters: {}. Best is trial 6 with value: 0.0005867928266525269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.1419 - val_loss: 0.3093\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0984 - val_loss: 0.2806\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0823 - val_loss: 0.2503\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0489 - val_loss: 0.2380\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0367 - val_loss: 0.2262\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0245 - val_loss: 0.2144\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0123 - val_loss: 0.2032\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8.6679e-04 - val_loss: 0.1923\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - val_loss: 0.1858\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0168 - val_loss: 0.1827\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0200 - val_loss: 0.1820\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0207 - val_loss: 0.1833\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0195 - val_loss: 0.1859\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0168 - val_loss: 0.1897\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0132 - val_loss: 0.1942\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0087 - val_loss: 0.1992\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2048\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.2085\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0055 - val_loss: 0.2105\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0075 - val_loss: 0.2113\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0083 - val_loss: 0.2109\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0078 - val_loss: 0.2095\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0064 - val_loss: 0.2072\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2042\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2005\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.1982\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - val_loss: 0.1971\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0060 - val_loss: 0.1972\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.1983\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2002\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2029\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.9009e-04 - val_loss: 0.2062\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2082\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 0.2091\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - val_loss: 0.2091\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0060 - val_loss: 0.2081\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.2063\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2038\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7256e-04 - val_loss: 0.2006\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.1986\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 0.1978\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - val_loss: 0.1980\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.1991\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2010\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2036\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3748e-04 - val_loss: 0.2051\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2055\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2050\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9745e-04 - val_loss: 0.2015\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2004\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.2004\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6134e-05 - val_loss: 0.2055\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2068\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2070\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2064\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2050\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2028\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0515e-04 - val_loss: 0.2017\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2016\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2025\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3241e-04 - val_loss: 0.2041\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2047\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9476e-05 - val_loss: 0.2011\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2002\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2003\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2013\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9491e-05 - val_loss: 0.2038\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3254e-04 - val_loss: 0.2036\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8842e-04 - val_loss: 0.2025\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1923e-04 - val_loss: 0.2024\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.2587e-04 - val_loss: 0.2032\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9365e-05 - val_loss: 0.2030\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0374e-04 - val_loss: 0.2037\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2834e-04 - val_loss: 0.2035\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0154e-04 - val_loss: 0.2024\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.9048e-04 - val_loss: 0.2023\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.8310e-04 - val_loss: 0.2031\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4661e-05 - val_loss: 0.2030\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3714e-04 - val_loss: 0.2037\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0517e-04 - val_loss: 0.2035\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8750e-04 - val_loss: 0.2024\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9629e-04 - val_loss: 0.2023\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8151e-04 - val_loss: 0.2031\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3006e-05 - val_loss: 0.2030\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2282e-04 - val_loss: 0.2037\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2497e-04 - val_loss: 0.2035\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1217e-04 - val_loss: 0.2024\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6733e-04 - val_loss: 0.2024\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.4863e-04 - val_loss: 0.2032\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9514e-05 - val_loss: 0.2030\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.3119e-05 - val_loss: 0.2038\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6756e-04 - val_loss: 0.2036\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5733e-04 - val_loss: 0.2025\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1993e-04 - val_loss: 0.2024\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9912e-04 - val_loss: 0.2032\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2097e-04 - val_loss: 0.2031\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9996e-05 - val_loss: 0.2038\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2227e-04 - val_loss: 0.2036\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1342e-04 - val_loss: 0.2025\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6265e-04 - val_loss: 0.2025\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4074e-04 - val_loss: 0.2033\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8030e-04 - val_loss: 0.2031\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0264e-05 - val_loss: 0.2021\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9535e-04 - val_loss: 0.2021\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2029\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5913e-04 - val_loss: 0.2046\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2052\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1336e-04 - val_loss: 0.2018\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2009\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2010\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2020\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1065e-04 - val_loss: 0.2045\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1203e-04 - val_loss: 0.2013\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2005\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2007\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2018\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2960e-04 - val_loss: 0.2044\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8830e-05 - val_loss: 0.2013\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2006\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2008\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2019\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1320e-04 - val_loss: 0.2045\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9823e-04 - val_loss: 0.2015\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2007\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2010\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2021\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0986e-04 - val_loss: 0.2047\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2046\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.1953e-04 - val_loss: 0.2017\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2010\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2012\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2023\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0957e-04 - val_loss: 0.2042\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2048\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.7496e-04 - val_loss: 0.2020\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2013\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2015\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4087e-04 - val_loss: 0.2044\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2052\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2051\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.4396e-04 - val_loss: 0.2023\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.4668e-04 - val_loss: 0.2015\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6383e-04 - val_loss: 0.2047\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2055\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2053\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2043\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6593e-04 - val_loss: 0.2018\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2020\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5646e-05 - val_loss: 0.2032\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1334e-04 - val_loss: 0.2024\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7550e-04 - val_loss: 0.2026\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0646e-04 - val_loss: 0.2036\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2278e-04 - val_loss: 0.2037\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7428e-04 - val_loss: 0.2029\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5326e-04 - val_loss: 0.2030\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2186e-04 - val_loss: 0.2040\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.7115e-04 - val_loss: 0.2040\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.9243e-04 - val_loss: 0.2032\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9622e-05 - val_loss: 0.2015\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2012\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.7656e-04 - val_loss: 0.2044\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2053\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2052\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8885e-04 - val_loss: 0.2019\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.8443e-04 - val_loss: 0.2033\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4021e-04 - val_loss: 0.2034\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7788e-04 - val_loss: 0.2026\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7085e-04 - val_loss: 0.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:52:26,997] Trial 9 finished with value: 0.0002699345350265503 and parameters: {}. Best is trial 9 with value: 0.0002699345350265503.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1564 - val_loss: 0.3549\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1547 - val_loss: 0.3495\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1471 - val_loss: 0.3451\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1420 - val_loss: 0.3441\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1410 - val_loss: 0.3431\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1400 - val_loss: 0.3421\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1390 - val_loss: 0.3411\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1380 - val_loss: 0.3401\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1370 - val_loss: 0.3391\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1360 - val_loss: 0.3381\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1350 - val_loss: 0.3371\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1340 - val_loss: 0.3361\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1330 - val_loss: 0.3351\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1320 - val_loss: 0.3341\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1310 - val_loss: 0.3331\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1300 - val_loss: 0.3321\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1290 - val_loss: 0.3311\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1280 - val_loss: 0.3301\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1270 - val_loss: 0.3291\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1260 - val_loss: 0.3281\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1250 - val_loss: 0.3271\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1240 - val_loss: 0.3261\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1230 - val_loss: 0.3251\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1220 - val_loss: 0.3241\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1210 - val_loss: 0.3231\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1200 - val_loss: 0.3221\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1190 - val_loss: 0.3211\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1180 - val_loss: 0.3201\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1170 - val_loss: 0.3191\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1160 - val_loss: 0.3181\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1150 - val_loss: 0.3171\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1140 - val_loss: 0.3161\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1130 - val_loss: 0.3151\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1120 - val_loss: 0.3141\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1110 - val_loss: 0.3131\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1100 - val_loss: 0.3121\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1090 - val_loss: 0.3111\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1080 - val_loss: 0.3101\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1070 - val_loss: 0.3091\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1060 - val_loss: 0.3081\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1050 - val_loss: 0.3071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1040 - val_loss: 0.3061\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1030 - val_loss: 0.3051\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1020 - val_loss: 0.3041\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1010 - val_loss: 0.3031\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1000 - val_loss: 0.3021\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0990 - val_loss: 0.3011\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0980 - val_loss: 0.3001\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0970 - val_loss: 0.2991\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0960 - val_loss: 0.2981\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0950 - val_loss: 0.2971\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0940 - val_loss: 0.2961\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0930 - val_loss: 0.2951\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0920 - val_loss: 0.2941\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0910 - val_loss: 0.2931\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0900 - val_loss: 0.2921\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0890 - val_loss: 0.2911\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0880 - val_loss: 0.2901\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0870 - val_loss: 0.2891\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0860 - val_loss: 0.2881\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0850 - val_loss: 0.2871\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0840 - val_loss: 0.2861\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0830 - val_loss: 0.2851\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0820 - val_loss: 0.2841\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0810 - val_loss: 0.2831\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0800 - val_loss: 0.2821\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0790 - val_loss: 0.2811\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0780 - val_loss: 0.2801\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0770 - val_loss: 0.2791\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0760 - val_loss: 0.2781\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0750 - val_loss: 0.2771\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0740 - val_loss: 0.2761\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0730 - val_loss: 0.2751\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0720 - val_loss: 0.2741\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0710 - val_loss: 0.2731\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0700 - val_loss: 0.2721\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0690 - val_loss: 0.2711\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0680 - val_loss: 0.2701\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0670 - val_loss: 0.2691\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0660 - val_loss: 0.2681\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0650 - val_loss: 0.2671\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0640 - val_loss: 0.2661\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0630 - val_loss: 0.2651\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0620 - val_loss: 0.2641\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0610 - val_loss: 0.2631\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0600 - val_loss: 0.2621\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0590 - val_loss: 0.2611\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0580 - val_loss: 0.2601\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0570 - val_loss: 0.2591\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0560 - val_loss: 0.2581\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0550 - val_loss: 0.2571\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0540 - val_loss: 0.2561\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0530 - val_loss: 0.2551\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0520 - val_loss: 0.2541\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0510 - val_loss: 0.2531\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0500 - val_loss: 0.2521\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0490 - val_loss: 0.2511\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0480 - val_loss: 0.2501\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0470 - val_loss: 0.2491\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0460 - val_loss: 0.2481\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0450 - val_loss: 0.2471\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0440 - val_loss: 0.2461\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0430 - val_loss: 0.2451\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0420 - val_loss: 0.2441\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.2431\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0400 - val_loss: 0.2421\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0390 - val_loss: 0.2411\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0380 - val_loss: 0.2401\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0370 - val_loss: 0.2391\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0360 - val_loss: 0.2381\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0350 - val_loss: 0.2371\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0340 - val_loss: 0.2361\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.2351\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0320 - val_loss: 0.2341\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0310 - val_loss: 0.2331\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0300 - val_loss: 0.2321\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0290 - val_loss: 0.2311\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0280 - val_loss: 0.2301\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0270 - val_loss: 0.2291\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0260 - val_loss: 0.2281\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0250 - val_loss: 0.2271\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0240 - val_loss: 0.2261\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0230 - val_loss: 0.2251\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0220 - val_loss: 0.2241\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0210 - val_loss: 0.2231\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0200 - val_loss: 0.2221\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0190 - val_loss: 0.2211\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0180 - val_loss: 0.2201\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0170 - val_loss: 0.2191\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0160 - val_loss: 0.2181\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0150 - val_loss: 0.2171\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0140 - val_loss: 0.2161\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0130 - val_loss: 0.2151\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0120 - val_loss: 0.2141\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - val_loss: 0.2131\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0100 - val_loss: 0.2121\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0090 - val_loss: 0.2111\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0080 - val_loss: 0.2101\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0070 - val_loss: 0.2091\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - val_loss: 0.2081\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.2071\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2061\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6893e-04 - val_loss: 0.2031\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1069e-05 - val_loss: 0.2023\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.3107e-04 - val_loss: 0.2017\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2007\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2007\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2011\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.4731e-04 - val_loss: 0.2027\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5568e-04 - val_loss: 0.2032\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6784e-05 - val_loss: 0.2036\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7500e-04 - val_loss: 0.2039\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.2441e-04 - val_loss: 0.2040\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.4886e-04 - val_loss: 0.2040\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.6087e-04 - val_loss: 0.2039\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.7169e-04 - val_loss: 0.2037\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9141e-04 - val_loss: 0.2035\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2917e-04 - val_loss: 0.2031\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8545e-06 - val_loss: 0.2029\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0927e-04 - val_loss: 0.2029\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9145e-04 - val_loss: 0.2029\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6540e-04 - val_loss: 0.2030\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4196e-04 - val_loss: 0.2032\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9126e-05 - val_loss: 0.2033\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5911e-04 - val_loss: 0.2033\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4010e-04 - val_loss: 0.2032\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2992e-05 - val_loss: 0.2030\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8241e-04 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6727e-04 - val_loss: 0.2029\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4365e-04 - val_loss: 0.2030\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2238e-04 - val_loss: 0.2032\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.6755e-05 - val_loss: 0.2033\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7498e-04 - val_loss: 0.2033\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5439e-04 - val_loss: 0.2032\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5852e-05 - val_loss: 0.2030\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7083e-04 - val_loss: 0.2029\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5685e-04 - val_loss: 0.2029\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3426e-04 - val_loss: 0.2030\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1393e-04 - val_loss: 0.2032\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.4354e-05 - val_loss: 0.2033\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8182e-04 - val_loss: 0.2033\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6055e-04 - val_loss: 0.2032\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1395e-05 - val_loss: 0.2030\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6585e-04 - val_loss: 0.2029\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5237e-04 - val_loss: 0.2029\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3022e-04 - val_loss: 0.2030\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1030e-04 - val_loss: 0.2032\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7632e-05 - val_loss: 0.2033\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8477e-04 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6320e-04 - val_loss: 0.2032\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3780e-05 - val_loss: 0.2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:52:46,695] Trial 10 finished with value: 0.00016370415687561035 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1414 - val_loss: 0.2777\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0673 - val_loss: 0.1854\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0248 - val_loss: 0.1808\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0124 - val_loss: 0.2216\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0298 - val_loss: 0.2298\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0356 - val_loss: 0.2190\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0234 - val_loss: 0.1970\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.4341e-04 - val_loss: 0.1677\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0289 - val_loss: 0.1540\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0424 - val_loss: 0.1523\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0438 - val_loss: 0.1596\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0365 - val_loss: 0.1733\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0233 - val_loss: 0.1913\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0061 - val_loss: 0.2120\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0135 - val_loss: 0.2236\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0243 - val_loss: 0.2282\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0282 - val_loss: 0.2272\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0269 - val_loss: 0.2220\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0215 - val_loss: 0.2135\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0129 - val_loss: 0.2026\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.1895\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0110 - val_loss: 0.1817\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0188 - val_loss: 0.1782\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0222 - val_loss: 0.1786\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0220 - val_loss: 0.1822\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0185 - val_loss: 0.1884\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0125 - val_loss: 0.1969\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0043 - val_loss: 0.2072\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.2134\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0119 - val_loss: 0.2162\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0145 - val_loss: 0.2160\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0141 - val_loss: 0.2131\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0112 - val_loss: 0.2080\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0060 - val_loss: 0.2008\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.1969\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - val_loss: 0.1961\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0059 - val_loss: 0.1978\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - val_loss: 0.2019\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.5168e-04 - val_loss: 0.2081\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0059 - val_loss: 0.2111\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0089 - val_loss: 0.2114\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0091 - val_loss: 0.2092\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0069 - val_loss: 0.2048\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.1984\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.1951\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0071 - val_loss: 0.1946\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0076 - val_loss: 0.1966\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - val_loss: 0.2007\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2068\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.2099\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0075 - val_loss: 0.2103\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0079 - val_loss: 0.2084\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.2043\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.1982\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - val_loss: 0.1951\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0072 - val_loss: 0.1947\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0076 - val_loss: 0.1967\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0057 - val_loss: 0.2008\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2069\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2099\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0075 - val_loss: 0.2104\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - val_loss: 0.2086\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0061 - val_loss: 0.2046\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.1987\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.1957\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - val_loss: 0.1953\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - val_loss: 0.1973\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0052 - val_loss: 0.2014\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2073\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - val_loss: 0.2104\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0078 - val_loss: 0.2109\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0083 - val_loss: 0.2090\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0065 - val_loss: 0.2051\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - val_loss: 0.1994\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.1964\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - val_loss: 0.1961\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0064 - val_loss: 0.1980\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - val_loss: 0.2020\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9761e-04 - val_loss: 0.2079\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0053 - val_loss: 0.2109\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0083 - val_loss: 0.2114\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0088 - val_loss: 0.2096\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0070 - val_loss: 0.2058\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.2001\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.1972\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - val_loss: 0.1968\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0057 - val_loss: 0.1988\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.2027\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4472e-04 - val_loss: 0.2041\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5970e-04 - val_loss: 0.1999\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.1993\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2010\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2047\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2059\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2047\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2007\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2023\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3778e-04 - val_loss: 0.2059\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2069\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2057\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2023\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8512e-04 - val_loss: 0.2015\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0342e-04 - val_loss: 0.2022\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5894e-04 - val_loss: 0.2036\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.6382e-04 - val_loss: 0.2027\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.8086e-05 - val_loss: 0.1996\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - val_loss: 0.1991\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2009\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2058\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2047\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2015\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2008\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2024\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2800e-04 - val_loss: 0.2060\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2071\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2059\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2026\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3583e-05 - val_loss: 0.2018\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.3409e-04 - val_loss: 0.2033\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6279e-04 - val_loss: 0.2025\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7735e-04 - val_loss: 0.2039\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5730e-04 - val_loss: 0.2000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.1995\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2012\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2050\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2062\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2051\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2019\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.4084e-04 - val_loss: 0.2012\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6475e-04 - val_loss: 0.2021\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9651e-04 - val_loss: 0.2036\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0100e-04 - val_loss: 0.2027\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8963e-05 - val_loss: 0.1998\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.1993\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2011\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2061\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2051\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2019\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3127e-04 - val_loss: 0.2013\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2029\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2368e-04 - val_loss: 0.2021\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1330e-04 - val_loss: 0.2037\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9991e-04 - val_loss: 0.2029\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8828e-04 - val_loss: 0.1999\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1995\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2013\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2051\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2063\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2053\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2021\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2343e-04 - val_loss: 0.2015\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4402e-04 - val_loss: 0.2024\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.8394e-04 - val_loss: 0.2039\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2687e-04 - val_loss: 0.2002\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.1998\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2016\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2066\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 0.2055\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2024\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.5479e-04 - val_loss: 0.2018\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.8438e-04 - val_loss: 0.2034\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.1487e-04 - val_loss: 0.2027\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.1807e-06 - val_loss: 0.2042\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.0444e-04 - val_loss: 0.2005\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2001\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2019\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.2234e-04 - val_loss: 0.2056\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2069\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - val_loss: 0.2058\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0031 - val_loss: 0.2027\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.7879e-05 - val_loss: 0.1978\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - val_loss: 0.1955\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0072 - val_loss: 0.1956\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0071 - val_loss: 0.1979\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2021\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9517e-04 - val_loss: 0.2080\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0053 - val_loss: 0.2112\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - val_loss: 0.2120\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0092 - val_loss: 0.2105\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0078 - val_loss: 0.2071\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2018\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6132e-04 - val_loss: 0.1993\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.1991\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2011\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2050\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2064\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2056\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2027\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2368e-06 - val_loss: 0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:53:05,182] Trial 11 finished with value: 0.0004741251468658447 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1638 - val_loss: 0.3561\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1642 - val_loss: 0.3453\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1435 - val_loss: 0.3334\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1296 - val_loss: 0.3275\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1243 - val_loss: 0.3231\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1198 - val_loss: 0.3197\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1162 - val_loss: 0.3162\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1127 - val_loss: 0.3126\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1091 - val_loss: 0.3089\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1055 - val_loss: 0.3054\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1020 - val_loss: 0.3018\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0985 - val_loss: 0.2983\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0950 - val_loss: 0.2947\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0914 - val_loss: 0.2909\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0877 - val_loss: 0.2869\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0838 - val_loss: 0.2827\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0797 - val_loss: 0.2782\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0752 - val_loss: 0.2736\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0706 - val_loss: 0.2689\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0659 - val_loss: 0.2643\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0611 - val_loss: 0.2596\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0564 - val_loss: 0.2548\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0516 - val_loss: 0.2499\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0466 - val_loss: 0.2448\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0415 - val_loss: 0.2395\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0363 - val_loss: 0.2342\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0310 - val_loss: 0.2288\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0256 - val_loss: 0.2233\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0201 - val_loss: 0.2177\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0145 - val_loss: 0.2119\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0087 - val_loss: 0.2059\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0026 - val_loss: 0.1996\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - val_loss: 0.1948\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0084 - val_loss: 0.1914\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0118 - val_loss: 0.1892\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0140 - val_loss: 0.1882\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0150 - val_loss: 0.1881\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0151 - val_loss: 0.1888\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0144 - val_loss: 0.1903\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0129 - val_loss: 0.1923\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0108 - val_loss: 0.1949\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - val_loss: 0.1979\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0053 - val_loss: 0.2013\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - val_loss: 0.2074\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - val_loss: 0.2090\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2098\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0066 - val_loss: 0.2099\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - val_loss: 0.2093\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0062 - val_loss: 0.2082\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - val_loss: 0.2066\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - val_loss: 0.2045\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2020\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2003\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - val_loss: 0.1995\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - val_loss: 0.1994\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.2000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - val_loss: 0.2011\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.8971e-04 - val_loss: 0.2049\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - val_loss: 0.2067\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.2065\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2058\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2046\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.6465e-04 - val_loss: 0.2018\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.2020\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.9993e-04 - val_loss: 0.2044\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2052\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 0.2052\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - val_loss: 0.2047\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.9259e-04 - val_loss: 0.2020\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2011\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2010\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - val_loss: 0.2015\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.2025\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3625e-04 - val_loss: 0.2041\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.9854e-04 - val_loss: 0.2048\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2050\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2045\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2034\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.6232e-04 - val_loss: 0.2019\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.2010\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2015\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.7191e-04 - val_loss: 0.2041\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.7229e-04 - val_loss: 0.2049\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 0.2051\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.2258e-04 - val_loss: 0.2021\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.2013\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2018\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4080e-04 - val_loss: 0.2044\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.2052\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2053\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - val_loss: 0.2048\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7894e-04 - val_loss: 0.2024\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.0340e-04 - val_loss: 0.2016\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.2015\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2021\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6937e-05 - val_loss: 0.2046\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2054\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2056\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - val_loss: 0.2051\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6481e-04 - val_loss: 0.2027\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.0418e-04 - val_loss: 0.2019\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2024\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.0700e-04 - val_loss: 0.2034\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.4112e-04 - val_loss: 0.2038\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0107e-04 - val_loss: 0.2035\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.4569e-04 - val_loss: 0.2027\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6521e-04 - val_loss: 0.2026\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1272e-04 - val_loss: 0.2030\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6233e-04 - val_loss: 0.2040\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.2190e-04 - val_loss: 0.2043\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.2964e-04 - val_loss: 0.2032\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7345e-05 - val_loss: 0.2030\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0088e-04 - val_loss: 0.2034\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.1403e-04 - val_loss: 0.2032\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.5682e-06 - val_loss: 0.2024\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.5658e-04 - val_loss: 0.2023\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6366e-04 - val_loss: 0.2028\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7789e-04 - val_loss: 0.2038\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3695e-04 - val_loss: 0.2041\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.7255e-04 - val_loss: 0.2039\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0028e-04 - val_loss: 0.2030\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2107e-04 - val_loss: 0.2029\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.8285e-04 - val_loss: 0.2033\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5013e-04 - val_loss: 0.2031\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.7566e-05 - val_loss: 0.2035\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7076e-04 - val_loss: 0.2033\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.6217e-04 - val_loss: 0.2026\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.0315e-04 - val_loss: 0.2025\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.1312e-04 - val_loss: 0.2029\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.3250e-04 - val_loss: 0.2039\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.7528e-04 - val_loss: 0.2043\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.3362e-04 - val_loss: 0.2032\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3605e-05 - val_loss: 0.2019\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2013\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2019\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2794e-04 - val_loss: 0.2046\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2055\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2057\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2053\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7163e-04 - val_loss: 0.2023\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5509e-04 - val_loss: 0.2023\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.9283e-04 - val_loss: 0.2028\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4940e-04 - val_loss: 0.2039\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1222e-04 - val_loss: 0.2043\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6971e-04 - val_loss: 0.2033\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.6485e-05 - val_loss: 0.2020\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2015\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2021\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2033\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0979e-04 - val_loss: 0.2037\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6945e-04 - val_loss: 0.2036\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1284e-04 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9942e-04 - val_loss: 0.2028\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6786e-04 - val_loss: 0.2033\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4353e-04 - val_loss: 0.2032\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2097e-05 - val_loss: 0.2025\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4056e-04 - val_loss: 0.2025\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7228e-04 - val_loss: 0.2030\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2703e-04 - val_loss: 0.2041\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.3280e-04 - val_loss: 0.2045\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3198e-04 - val_loss: 0.2022\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.3018e-04 - val_loss: 0.2017\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2017\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2024\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.8715e-04 - val_loss: 0.2035\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5770e-04 - val_loss: 0.2040\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1646e-04 - val_loss: 0.2038\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6227e-04 - val_loss: 0.2031\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4689e-05 - val_loss: 0.2031\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1152e-04 - val_loss: 0.2036\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9817e-04 - val_loss: 0.2035\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.8834e-04 - val_loss: 0.2028\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7985e-04 - val_loss: 0.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:53:23,364] Trial 12 finished with value: 0.00041057169437408447 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1472 - val_loss: 0.2925\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0704 - val_loss: 0.2352\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0213 - val_loss: 0.1945\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0159 - val_loss: 0.1858\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0215 - val_loss: 0.1920\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0134 - val_loss: 0.2046\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8272e-04 - val_loss: 0.2089\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 0.2076\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.2023\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - val_loss: 0.2012\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - val_loss: 0.2035\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.8381e-04 - val_loss: 0.2085\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - val_loss: 0.2102\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0066 - val_loss: 0.2091\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - val_loss: 0.2057\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2003\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - val_loss: 0.1978\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - val_loss: 0.1978\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - val_loss: 0.2000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2041\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7037e-04 - val_loss: 0.2057\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2029\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5180e-04 - val_loss: 0.2027\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.7783e-04 - val_loss: 0.2043\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.7193e-04 - val_loss: 0.2039\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4081e-04 - val_loss: 0.2019\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - val_loss: 0.2017\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6112e-06 - val_loss: 0.2031\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.2167e-04 - val_loss: 0.2046\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.3465e-04 - val_loss: 0.2023\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - val_loss: 0.2022\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.8797e-04 - val_loss: 0.2035\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4663e-04 - val_loss: 0.2016\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2016\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5102e-04 - val_loss: 0.2062\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - val_loss: 0.2073\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.2068\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - val_loss: 0.2047\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.1997\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - val_loss: 0.1999\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - val_loss: 0.2017\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - val_loss: 0.2049\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.2062\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2058\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2039\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4066e-04 - val_loss: 0.2007\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - val_loss: 0.1993\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - val_loss: 0.1996\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - val_loss: 0.2014\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2060\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2057\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.3415e-04 - val_loss: 0.2008\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - val_loss: 0.1994\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.1998\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - val_loss: 0.2016\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.2048\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - val_loss: 0.2062\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - val_loss: 0.2059\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0027 - val_loss: 0.2042\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.2787e-04 - val_loss: 0.2011\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - val_loss: 0.1998\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - val_loss: 0.2002\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0030 - val_loss: 0.2020\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2052\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2065\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2063\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.2046\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 0.2015\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2003\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.2007\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2025\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.5366e-04 - val_loss: 0.2056\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - val_loss: 0.2069\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.2066\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - val_loss: 0.2050\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2011\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2029\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1412e-04 - val_loss: 0.2060\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - val_loss: 0.2073\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - val_loss: 0.2070\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.2054\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2024\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.1916e-04 - val_loss: 0.2012\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2016\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.2033\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0516e-04 - val_loss: 0.2035\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6001e-04 - val_loss: 0.2022\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7128e-04 - val_loss: 0.2041\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.1165e-04 - val_loss: 0.2042\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.9228e-04 - val_loss: 0.2029\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.6819e-04 - val_loss: 0.2031\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5879e-04 - val_loss: 0.2047\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2047\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.5293e-05 - val_loss: 0.2006\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - val_loss: 0.1996\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - val_loss: 0.2002\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2021\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2067\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - val_loss: 0.2066\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 0.2050\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2022\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.8391e-04 - val_loss: 0.2011\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2016\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6417e-04 - val_loss: 0.2036\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.8049e-04 - val_loss: 0.2024\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.3631e-04 - val_loss: 0.2027\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1881e-04 - val_loss: 0.2044\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4869e-06 - val_loss: 0.2006\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - val_loss: 0.1997\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - val_loss: 0.2003\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - val_loss: 0.2023\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.2834e-04 - val_loss: 0.2054\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - val_loss: 0.2069\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.2068\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - val_loss: 0.2053\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.0543e-04 - val_loss: 0.2016\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2038\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0372e-04 - val_loss: 0.2040\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3771e-04 - val_loss: 0.2029\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.3885e-04 - val_loss: 0.2032\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.1195e-06 - val_loss: 0.2049\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2050\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.4654e-04 - val_loss: 0.2012\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - val_loss: 0.2003\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.2009\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2029\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.2735e-04 - val_loss: 0.2060\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2074\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - val_loss: 0.2073\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - val_loss: 0.2059\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - val_loss: 0.2032\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.8597e-05 - val_loss: 0.1994\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.1974\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1970\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - val_loss: 0.1980\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - val_loss: 0.2003\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - val_loss: 0.2037\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.1406e-04 - val_loss: 0.2054\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2056\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - val_loss: 0.2044\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.2012\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2018\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2037\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2229e-04 - val_loss: 0.2041\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9647e-04 - val_loss: 0.2031\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2207e-04 - val_loss: 0.2035\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1790e-04 - val_loss: 0.2026\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.4187e-04 - val_loss: 0.2030\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4813e-04 - val_loss: 0.2048\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.1213e-04 - val_loss: 0.2017\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2016\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.4449e-04 - val_loss: 0.2040\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6115e-04 - val_loss: 0.2030\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.1201e-04 - val_loss: 0.2035\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.6181e-04 - val_loss: 0.2025\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.6073e-04 - val_loss: 0.2031\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4012e-04 - val_loss: 0.2049\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2052\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8656e-04 - val_loss: 0.2018\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2010\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2017\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.8718e-04 - val_loss: 0.2041\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.1451e-04 - val_loss: 0.2032\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.3467e-05 - val_loss: 0.2036\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.3850e-04 - val_loss: 0.2027\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.7119e-04 - val_loss: 0.2032\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.5507e-05 - val_loss: 0.2024\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1503e-04 - val_loss: 0.2029\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.5205e-04 - val_loss: 0.2048\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.7863e-04 - val_loss: 0.2018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2011\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - val_loss: 0.2018\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:53:40,940] Trial 13 finished with value: 0.0014047622680664062 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1543 - val_loss: 0.3773\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1899 - val_loss: 0.3488\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1413 - val_loss: 0.3284\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1244 - val_loss: 0.3191\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1157 - val_loss: 0.3105\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1072 - val_loss: 0.3023\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0986 - val_loss: 0.2938\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0900 - val_loss: 0.2862\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0828 - val_loss: 0.2791\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0758 - val_loss: 0.2719\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0686 - val_loss: 0.2645\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0612 - val_loss: 0.2567\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0534 - val_loss: 0.2485\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0452 - val_loss: 0.2398\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0367 - val_loss: 0.2307\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0278 - val_loss: 0.2213\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0185 - val_loss: 0.2118\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0090 - val_loss: 0.2022\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.3226e-04 - val_loss: 0.1955\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0075 - val_loss: 0.1912\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0119 - val_loss: 0.1888\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0143 - val_loss: 0.1880\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0150 - val_loss: 0.1886\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0145 - val_loss: 0.1904\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0127 - val_loss: 0.1930\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0101 - val_loss: 0.1965\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0066 - val_loss: 0.2005\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2051\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - val_loss: 0.2081\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - val_loss: 0.2098\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0067 - val_loss: 0.2104\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0072 - val_loss: 0.2100\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0068 - val_loss: 0.2087\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0055 - val_loss: 0.2066\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - val_loss: 0.2038\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.7224e-04 - val_loss: 0.2003\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.1982\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - val_loss: 0.1972\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.1972\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0059 - val_loss: 0.1982\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - val_loss: 0.2000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - val_loss: 0.2026\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.6554e-04 - val_loss: 0.2057\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0026 - val_loss: 0.2076\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0045 - val_loss: 0.2085\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0054 - val_loss: 0.2084\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - val_loss: 0.2074\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - val_loss: 0.2057\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2033\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5064e-04 - val_loss: 0.2002\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.1983\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0048 - val_loss: 0.1975\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0056 - val_loss: 0.1977\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0054 - val_loss: 0.1988\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - val_loss: 0.2006\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2031\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.4703e-06 - val_loss: 0.2045\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.2049\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.9354e-05 - val_loss: 0.2028\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6202e-04 - val_loss: 0.2033\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1216e-04 - val_loss: 0.2030\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.3329e-04 - val_loss: 0.2036\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.1763e-04 - val_loss: 0.2032\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.3838e-05 - val_loss: 0.2020\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6176e-04 - val_loss: 0.2039\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.0816e-04 - val_loss: 0.2044\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0013 - val_loss: 0.2040\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.4001e-04 - val_loss: 0.2027\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.0546e-04 - val_loss: 0.2025\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6884e-04 - val_loss: 0.2031\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6164e-05 - val_loss: 0.2045\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2049\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.3005e-05 - val_loss: 0.2012\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2002\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.2002\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.2011\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.6651e-04 - val_loss: 0.2051\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - val_loss: 0.2063\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - val_loss: 0.2066\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2060\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.2047\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.4219e-04 - val_loss: 0.2016\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - val_loss: 0.2015\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2023\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.3041e-04 - val_loss: 0.2039\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.4263e-04 - val_loss: 0.2044\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 0.2041\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.6875e-04 - val_loss: 0.2029\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.8336e-04 - val_loss: 0.2028\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.7004e-04 - val_loss: 0.2034\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1400e-04 - val_loss: 0.2032\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9781e-05 - val_loss: 0.2021\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8288e-04 - val_loss: 0.2020\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2212e-04 - val_loss: 0.2043\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2045\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1304e-04 - val_loss: 0.2014\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2006\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - val_loss: 0.2007\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0025 - val_loss: 0.2016\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5010e-04 - val_loss: 0.2040\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.2116e-04 - val_loss: 0.2037\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.7992e-04 - val_loss: 0.2026\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4.8459e-04 - val_loss: 0.2025\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.9305e-04 - val_loss: 0.2033\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5998e-04 - val_loss: 0.2031\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0669e-05 - val_loss: 0.2038\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.8323e-04 - val_loss: 0.2036\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6243e-04 - val_loss: 0.2026\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.8377e-04 - val_loss: 0.2025\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.7569e-04 - val_loss: 0.2032\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.2208e-05 - val_loss: 0.2031\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.5029e-05 - val_loss: 0.2038\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4091e-04 - val_loss: 0.2036\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3094e-04 - val_loss: 0.2025\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.0531e-04 - val_loss: 0.2024\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.8845e-04 - val_loss: 0.2032\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7246e-05 - val_loss: 0.2031\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.2838e-05 - val_loss: 0.2038\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.4935e-04 - val_loss: 0.2036\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.4522e-04 - val_loss: 0.2025\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.8565e-04 - val_loss: 0.2025\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6406e-04 - val_loss: 0.2033\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1560e-04 - val_loss: 0.2031\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0667e-05 - val_loss: 0.2038\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.8471e-04 - val_loss: 0.2036\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.8368e-04 - val_loss: 0.2026\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.4407e-04 - val_loss: 0.2025\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2002e-04 - val_loss: 0.2033\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.6162e-04 - val_loss: 0.2032\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.7419e-05 - val_loss: 0.2022\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.6147e-04 - val_loss: 0.2021\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9111e-04 - val_loss: 0.2030\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.6595e-04 - val_loss: 0.2046\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.2051\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - val_loss: 0.2048\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.6867e-04 - val_loss: 0.2018\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2010\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2011\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - val_loss: 0.2038\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.6102e-04 - val_loss: 0.2045\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.0435e-05 - val_loss: 0.2014\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.2007\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - val_loss: 0.2009\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0023 - val_loss: 0.2019\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.8979e-04 - val_loss: 0.2044\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 0.2042\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - val_loss: 0.2032\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4.1246e-05 - val_loss: 0.2014\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.2007\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - val_loss: 0.2019\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7176e-04 - val_loss: 0.2045\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7627e-04 - val_loss: 0.2016\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.2011\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0021 - val_loss: 0.2021\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.6200e-04 - val_loss: 0.2047\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2045\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.8978e-04 - val_loss: 0.2018\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - val_loss: 0.2013\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - val_loss: 0.2024\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.8298e-04 - val_loss: 0.2041\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 9.9793e-04 - val_loss: 0.2049\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.3618e-04 - val_loss: 0.2021\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2014\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - val_loss: 0.2016\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.2471e-04 - val_loss: 0.2044\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.2052\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - val_loss: 0.2050\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.9584e-04 - val_loss: 0.2023\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 8.1679e-04 - val_loss: 0.2016\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2018\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - val_loss: 0.2029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:53:59,549] Trial 14 finished with value: 0.00025822222232818604 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1698 - val_loss: 0.3638\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1662 - val_loss: 0.3517\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1487 - val_loss: 0.3495\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1457 - val_loss: 0.3399\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1353 - val_loss: 0.3285\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1244 - val_loss: 0.3202\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1165 - val_loss: 0.3135\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1092 - val_loss: 0.3046\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0999 - val_loss: 0.2943\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0911 - val_loss: 0.2871\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0840 - val_loss: 0.2793\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0763 - val_loss: 0.2709\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0681 - val_loss: 0.2620\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0592 - val_loss: 0.2527\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0499 - val_loss: 0.2430\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0401 - val_loss: 0.2330\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0299 - val_loss: 0.2225\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0192 - val_loss: 0.2102\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0069 - val_loss: 0.1958\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0076 - val_loss: 0.1876\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0157 - val_loss: 0.1840\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0192 - val_loss: 0.1839\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0194 - val_loss: 0.1844\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0190 - val_loss: 0.1857\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0178 - val_loss: 0.1882\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0153 - val_loss: 0.1919\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0117 - val_loss: 0.1964\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0071 - val_loss: 0.2015\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2068\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2103\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.2124\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0091 - val_loss: 0.2130\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0098 - val_loss: 0.2125\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0093 - val_loss: 0.2111\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0079 - val_loss: 0.2089\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0057 - val_loss: 0.2059\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2022\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.3202e-04 - val_loss: 0.1999\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.1989\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.1989\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.1999\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2017\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2057\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2060\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2053\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2038\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6634e-04 - val_loss: 0.2015\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2003\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2003\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2011\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2727e-04 - val_loss: 0.2053\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2065\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2068\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.2061\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.3555e-04 - val_loss: 0.2010\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2009\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2017\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.3891e-04 - val_loss: 0.2039\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.0279e-04 - val_loss: 0.2035\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.9591e-04 - val_loss: 0.2023\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.8650e-04 - val_loss: 0.2020\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2027\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.2368e-04 - val_loss: 0.2043\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2047\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3063e-04 - val_loss: 0.2026\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2947e-04 - val_loss: 0.2033\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1292e-04 - val_loss: 0.2029\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2085e-04 - val_loss: 0.2035\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.8829e-04 - val_loss: 0.2032\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6360e-05 - val_loss: 0.2019\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2025\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8343e-04 - val_loss: 0.2040\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.8169e-04 - val_loss: 0.2045\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2041\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2568e-04 - val_loss: 0.2027\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9212e-04 - val_loss: 0.2025\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7085e-04 - val_loss: 0.2031\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2472e-05 - val_loss: 0.2046\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2051\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.1944e-05 - val_loss: 0.2011\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - val_loss: 0.2001\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.2001\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0031 - val_loss: 0.2010\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2027\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2835e-04 - val_loss: 0.2052\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2065\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - val_loss: 0.2068\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - val_loss: 0.2061\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - val_loss: 0.2047\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.2024\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2293e-04 - val_loss: 0.2013\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2021\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.6322e-04 - val_loss: 0.2043\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6614e-04 - val_loss: 0.2027\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.7676e-04 - val_loss: 0.2024\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.9249e-04 - val_loss: 0.2032\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7583e-05 - val_loss: 0.2029\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.4737e-04 - val_loss: 0.2036\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.1649e-04 - val_loss: 0.2033\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1174e-04 - val_loss: 0.2021\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.5803e-04 - val_loss: 0.2043\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - val_loss: 0.2044\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1679e-05 - val_loss: 0.2028\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9296e-04 - val_loss: 0.2035\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.8248e-04 - val_loss: 0.2032\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 8.9079e-05 - val_loss: 0.2021\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.5285e-04 - val_loss: 0.2043\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - val_loss: 0.2044\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0774e-05 - val_loss: 0.2029\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.5667e-04 - val_loss: 0.2036\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.2276e-04 - val_loss: 0.2033\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3393e-04 - val_loss: 0.2021\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.2020\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.9667e-04 - val_loss: 0.2043\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - val_loss: 0.2045\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5686e-05 - val_loss: 0.2011\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2002\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - val_loss: 0.2003\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.2012\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3219e-04 - val_loss: 0.2055\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - val_loss: 0.2068\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.2071\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - val_loss: 0.2065\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - val_loss: 0.2051\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.1361e-04 - val_loss: 0.2019\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2026\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0899e-04 - val_loss: 0.2043\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.2045\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.6171e-04 - val_loss: 0.2013\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.2004\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.2005\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2015\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4429e-04 - val_loss: 0.2040\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5519e-04 - val_loss: 0.2037\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.0232e-04 - val_loss: 0.2026\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.1923e-04 - val_loss: 0.2025\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.3373e-04 - val_loss: 0.2033\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5874e-04 - val_loss: 0.2031\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2531e-05 - val_loss: 0.2038\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.0737e-04 - val_loss: 0.2036\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.7213e-04 - val_loss: 0.2025\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.3315e-04 - val_loss: 0.2024\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3338e-04 - val_loss: 0.2032\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.1585e-05 - val_loss: 0.2030\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.8094e-05 - val_loss: 0.2038\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4199e-04 - val_loss: 0.2036\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.1626e-04 - val_loss: 0.2025\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8018e-04 - val_loss: 0.2024\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.7273e-04 - val_loss: 0.2032\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.8907e-05 - val_loss: 0.2030\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2447e-04 - val_loss: 0.2038\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2105e-04 - val_loss: 0.2035\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.0044e-04 - val_loss: 0.2024\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.9107e-04 - val_loss: 0.2024\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7941e-04 - val_loss: 0.2032\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.5807e-05 - val_loss: 0.2030\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2411e-04 - val_loss: 0.2038\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.2428e-04 - val_loss: 0.2035\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.0656e-04 - val_loss: 0.2025\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.8216e-04 - val_loss: 0.2024\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.6817e-04 - val_loss: 0.2032\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.8935e-05 - val_loss: 0.2030\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0903e-04 - val_loss: 0.2038\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 6.4093e-04 - val_loss: 0.2036\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.2482e-04 - val_loss: 0.2025\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6218e-04 - val_loss: 0.2024\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.4685e-04 - val_loss: 0.2032\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.1213e-05 - val_loss: 0.2031\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 8.5637e-05 - val_loss: 0.2038\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6517e-04 - val_loss: 0.2036\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:54:17,861] Trial 15 finished with value: 0.0004500150680541992 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1457 - val_loss: 0.3597\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1562 - val_loss: 0.3123\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0909 - val_loss: 0.2421\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0318 - val_loss: 0.1981\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.1864\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0171 - val_loss: 0.1893\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0132 - val_loss: 0.1994\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2169\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0154 - val_loss: 0.2219\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0208 - val_loss: 0.2182\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0174 - val_loss: 0.2090\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0085 - val_loss: 0.1956\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.1904\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0099 - val_loss: 0.1912\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0091 - val_loss: 0.1965\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2052\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.2086\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0081 - val_loss: 0.2079\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.2038\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.1969\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.1942\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.1952\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0054 - val_loss: 0.1991\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2055\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2082\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0073 - val_loss: 0.2078\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.2049\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0040 - val_loss: 0.1997\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.1977\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.1985\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2017\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4026e-04 - val_loss: 0.2021\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9391e-04 - val_loss: 0.2001\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2007\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2227e-04 - val_loss: 0.2035\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2037\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2017\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.8542e-04 - val_loss: 0.1976\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.1962\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.1973\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2004\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2053\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2075\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0060 - val_loss: 0.2075\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0059 - val_loss: 0.2054\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2015\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0024e-04 - val_loss: 0.2000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.4996e-04 - val_loss: 0.2035\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - val_loss: 0.2023\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.6365e-04 - val_loss: 0.1989\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - val_loss: 0.1978\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - val_loss: 0.1988\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - val_loss: 0.2017\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0847e-04 - val_loss: 0.2062\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0044 - val_loss: 0.2083\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0064 - val_loss: 0.2084\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0064 - val_loss: 0.2065\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - val_loss: 0.2030\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.1979\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0040 - val_loss: 0.1953\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0067 - val_loss: 0.1948\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - val_loss: 0.1964\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0056 - val_loss: 0.1997\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - val_loss: 0.2045\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2069\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.2073\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.2058\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - val_loss: 0.2026\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.0387e-04 - val_loss: 0.1980\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.1956\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - val_loss: 0.1953\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0069 - val_loss: 0.1969\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.2002\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2073\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - val_loss: 0.2077\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - val_loss: 0.2063\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.2034\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.8367e-04 - val_loss: 0.1990\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.1968\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.1966\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - val_loss: 0.1982\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.2013\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - val_loss: 0.2058\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2081\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.2085\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - val_loss: 0.2073\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - val_loss: 0.2045\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2003\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.1982\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.1980\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - val_loss: 0.1995\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2025\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.9759e-05 - val_loss: 0.2069\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2092\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0065 - val_loss: 0.2096\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0070 - val_loss: 0.2084\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.2057\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2016\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.9082e-04 - val_loss: 0.1996\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.1994\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - val_loss: 0.2009\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2042\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2020\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.3975e-04 - val_loss: 0.2016\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2029\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4524e-04 - val_loss: 0.2024\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1522e-04 - val_loss: 0.2036\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.6406e-04 - val_loss: 0.2031\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.3720e-04 - val_loss: 0.2010\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2021\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2813e-04 - val_loss: 0.2050\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2059\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2052\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2030\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.9205e-04 - val_loss: 0.1994\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - val_loss: 0.1977\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - val_loss: 0.1979\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - val_loss: 0.1996\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2028\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3853e-05 - val_loss: 0.2040\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3092e-04 - val_loss: 0.2016\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - val_loss: 0.2014\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2028\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5524e-05 - val_loss: 0.2024\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8299e-04 - val_loss: 0.2037\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9257e-04 - val_loss: 0.2033\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7787e-04 - val_loss: 0.2014\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2012\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2027\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2407e-05 - val_loss: 0.2056\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.2066\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.2060\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - val_loss: 0.2038\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2003\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.1987\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.1988\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.2006\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2038\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - val_loss: 0.2051\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2047\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2027\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1462e-04 - val_loss: 0.2025\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.1011e-04 - val_loss: 0.2039\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.9331e-04 - val_loss: 0.2017\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4128e-04 - val_loss: 0.2029\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1212e-04 - val_loss: 0.2011\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2011\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3401e-04 - val_loss: 0.2057\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2068\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - val_loss: 0.2062\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - val_loss: 0.2041\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2007\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.1991\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.1994\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.2012\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2056\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2052\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2033\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.9920e-04 - val_loss: 0.2000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - val_loss: 0.1986\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0042 - val_loss: 0.1989\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 0.2008\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0012 - val_loss: 0.2054\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0026 - val_loss: 0.2051\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2033\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.2346e-04 - val_loss: 0.2000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - val_loss: 0.1987\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.1991\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2010\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0018 - val_loss: 0.2042\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2056\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.2053\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2035\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.9569e-04 - val_loss: 0.2004\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - val_loss: 0.1991\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - val_loss: 0.1995\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - val_loss: 0.2014\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - val_loss: 0.2046\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2060\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2057\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.2040\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2009\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.1997\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2001\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2019\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.9496e-04 - val_loss: 0.2051\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:54:37,365] Trial 16 finished with value: 0.003736823797225952 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1393 - val_loss: 0.3044\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0892 - val_loss: 0.2356\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0249 - val_loss: 0.1922\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0132 - val_loss: 0.1918\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0112 - val_loss: 0.2034\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2012\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.7327e-04 - val_loss: 0.2055\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2017\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2319e-04 - val_loss: 0.1887\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0104 - val_loss: 0.1862\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0119 - val_loss: 0.1946\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - val_loss: 0.2047\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2079\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0063 - val_loss: 0.2056\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.1989\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.1977\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3640e-04 - val_loss: 0.2080\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.2101\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - val_loss: 0.2082\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0063 - val_loss: 0.2027\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5777e-04 - val_loss: 0.1930\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.1910\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0110 - val_loss: 0.1917\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0103 - val_loss: 0.1959\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.2029\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.2850e-04 - val_loss: 0.2058\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2052\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2015\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5817e-04 - val_loss: 0.2013\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5787e-04 - val_loss: 0.2042\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2037\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2003\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.2002\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - val_loss: 0.2030\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.7185e-04 - val_loss: 0.2025\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4313e-04 - val_loss: 0.1992\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.1992\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2021\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0093e-04 - val_loss: 0.2075\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.2095\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0074 - val_loss: 0.2086\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0064 - val_loss: 0.2050\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.1989\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.1962\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.1967\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.2000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2057\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2080\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2075\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.2043\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.1989\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.1966\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0057 - val_loss: 0.1973\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2006\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2061\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2085\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - val_loss: 0.2081\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - val_loss: 0.2053\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2002\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.1982\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.1990\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2021\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8372e-04 - val_loss: 0.2074\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - val_loss: 0.2097\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0071 - val_loss: 0.2094\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.2067\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2020\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7861e-04 - val_loss: 0.2001\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2009\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2042\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2403e-04 - val_loss: 0.2027\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4667e-05 - val_loss: 0.2009\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2016\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2048\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0021 - val_loss: 0.2028\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2356e-04 - val_loss: 0.1987\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.1974\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - val_loss: 0.1985\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - val_loss: 0.2017\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.6337e-04 - val_loss: 0.2069\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - val_loss: 0.2093\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.2093\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0065 - val_loss: 0.2071\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 0.2029\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6753e-04 - val_loss: 0.1969\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1937\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0090 - val_loss: 0.1932\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0096 - val_loss: 0.1949\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0078 - val_loss: 0.1987\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2043\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2071\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2075\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - val_loss: 0.2058\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.2022\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3632e-04 - val_loss: 0.2010\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0018 - val_loss: 0.2020\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 7.6230e-04 - val_loss: 0.2051\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.2057\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.2042\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 0.2009\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - val_loss: 0.1999\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2011\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - val_loss: 0.2050\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0021 - val_loss: 0.2036\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.0313e-04 - val_loss: 0.2004\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - val_loss: 0.1995\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - val_loss: 0.2008\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8174e-04 - val_loss: 0.2004\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2025\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2379e-04 - val_loss: 0.2024\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.2930e-05 - val_loss: 0.1999\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - val_loss: 0.2000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - val_loss: 0.2023\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0881e-04 - val_loss: 0.2063\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.2079\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0053 - val_loss: 0.2073\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.2048\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.1989\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.1992\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2014\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2051\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - val_loss: 0.2066\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2062\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2040\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2003\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.1988\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0040 - val_loss: 0.1991\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2013\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2064\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.2061\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2041\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2006\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.1991\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.1995\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2016\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2052\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2067\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2065\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2045\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2011\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.1997\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2002\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2022\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2020e-04 - val_loss: 0.2058\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2073\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2070\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0041 - val_loss: 0.2051\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2018\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2004\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2009\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0742e-05 - val_loss: 0.2031\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1468e-04 - val_loss: 0.2017\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.1381e-04 - val_loss: 0.2039\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2040\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1035e-04 - val_loss: 0.2028\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5870e-04 - val_loss: 0.2046\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2046\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6813e-04 - val_loss: 0.2001\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.1990\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.1996\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2018\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0011 - val_loss: 0.2054\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.2070\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0041 - val_loss: 0.2069\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.2052\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - val_loss: 0.2021\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.5998e-04 - val_loss: 0.2009\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0265e-04 - val_loss: 0.2037\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6479e-04 - val_loss: 0.2024\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.7979e-04 - val_loss: 0.2027\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.0516e-04 - val_loss: 0.2047\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2048\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.2668e-04 - val_loss: 0.2005\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - val_loss: 0.1995\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - val_loss: 0.2002\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - val_loss: 0.2024\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4213e-04 - val_loss: 0.2060\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.2076\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - val_loss: 0.2075\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - val_loss: 0.2059\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - val_loss: 0.2029\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.6129e-05 - val_loss: 0.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:54:57,952] Trial 17 finished with value: 0.0012393742799758911 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.1414 - val_loss: 0.2701\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - val_loss: 0.1788\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0394 - val_loss: 0.1628\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0447 - val_loss: 0.1739\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - val_loss: 0.1934\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0129 - val_loss: 0.2181\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0111 - val_loss: 0.2276\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0204 - val_loss: 0.2271\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0200 - val_loss: 0.2202\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0135 - val_loss: 0.2093\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.1961\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0095 - val_loss: 0.1897\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0156 - val_loss: 0.1882\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0167 - val_loss: 0.1906\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0142 - val_loss: 0.1959\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0087 - val_loss: 0.2034\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2125\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.2177\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0132 - val_loss: 0.2197\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0153 - val_loss: 0.2193\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0149 - val_loss: 0.2168\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0125 - val_loss: 0.2126\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0084 - val_loss: 0.2067\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.1995\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.1951\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0089 - val_loss: 0.1934\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0106 - val_loss: 0.1939\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0099 - val_loss: 0.1965\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0073 - val_loss: 0.2007\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2061\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2091\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2101\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.2093\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.2069\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2032\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7567e-04 - val_loss: 0.2015\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2016\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2033\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3200e-04 - val_loss: 0.2064\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2076\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2052\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2020\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2006\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2009\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2027\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1362e-04 - val_loss: 0.2058\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0022 - val_loss: 0.2070\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.2067\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2050\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2007\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2011\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2028\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.2826e-04 - val_loss: 0.2058\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2071\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2069\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.2052\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2014\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2032\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3410e-04 - val_loss: 0.2062\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - val_loss: 0.2074\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - val_loss: 0.2072\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - val_loss: 0.2056\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.0344e-04 - val_loss: 0.2015\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - val_loss: 0.2019\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1669e-04 - val_loss: 0.2038\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7142e-04 - val_loss: 0.2025\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.8105e-04 - val_loss: 0.2028\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.1347e-04 - val_loss: 0.2044\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.1615e-04 - val_loss: 0.2045\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.9730e-04 - val_loss: 0.2032\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1129e-04 - val_loss: 0.2034\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0405e-04 - val_loss: 0.2050\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2050\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5169e-04 - val_loss: 0.2010\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2001\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.2006\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2025\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.8000e-04 - val_loss: 0.2056\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2069\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2068\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2053\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3196e-04 - val_loss: 0.2016\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2038\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0233e-04 - val_loss: 0.2040\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1606e-04 - val_loss: 0.2028\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5406e-04 - val_loss: 0.2031\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4197e-04 - val_loss: 0.2048\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7208e-04 - val_loss: 0.2011\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2003\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2009\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2027\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0699e-04 - val_loss: 0.2058\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2072\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2071\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2057\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8996e-04 - val_loss: 0.2020\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2025\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.5859e-04 - val_loss: 0.2042\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8975e-04 - val_loss: 0.2045\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2033\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2186e-04 - val_loss: 0.2036\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9854e-04 - val_loss: 0.2026\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5762e-04 - val_loss: 0.2030\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6135e-04 - val_loss: 0.2047\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2037\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6041e-04 - val_loss: 0.2013\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2011\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1302e-04 - val_loss: 0.2061\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2075\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2074\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2060\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2035\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0561e-05 - val_loss: 0.1998\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.1979\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.1974\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - val_loss: 0.1984\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2007\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2040\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.9605e-04 - val_loss: 0.2057\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2059\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2047\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2023\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2040\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1348e-04 - val_loss: 0.2044\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7466e-04 - val_loss: 0.2034\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3039e-05 - val_loss: 0.2038\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.1239e-04 - val_loss: 0.2029\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1795e-04 - val_loss: 0.2034\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0561e-05 - val_loss: 0.2051\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2054\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2043\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.8362e-04 - val_loss: 0.2020\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2013\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2038\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.2287e-04 - val_loss: 0.2042\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.2289e-04 - val_loss: 0.2033\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2285e-04 - val_loss: 0.2037\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3347e-04 - val_loss: 0.2028\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6258e-04 - val_loss: 0.2033\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0618e-05 - val_loss: 0.2051\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2054\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2043\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2421e-04 - val_loss: 0.2021\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2020\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2579e-04 - val_loss: 0.2043\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.3557e-04 - val_loss: 0.2034\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7551e-06 - val_loss: 0.2012\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2006\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2014\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2034\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0875e-05 - val_loss: 0.2064\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2079\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.2079\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - val_loss: 0.2067\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - val_loss: 0.2043\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 8.8237e-04 - val_loss: 0.2008\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0026 - val_loss: 0.1989\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0044 - val_loss: 0.1986\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0048 - val_loss: 0.1996\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0038 - val_loss: 0.2018\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - val_loss: 0.2069\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - val_loss: 0.2058\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2036\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.0821e-04 - val_loss: 0.2002\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.1985\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - val_loss: 0.1983\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.1994\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2016\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2050\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2067\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2069\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2059\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2100e-04 - val_loss: 0.2004\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1987\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - val_loss: 0.1985\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 0.1996\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2019\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:55:21,749] Trial 18 finished with value: 0.001422286033630371 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.1582 - val_loss: 0.2872\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0830 - val_loss: 0.1920\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0154 - val_loss: 0.2123\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0113 - val_loss: 0.1922\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - val_loss: 0.1952\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - val_loss: 0.2035\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - val_loss: 0.1995\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.5901e-04 - val_loss: 0.2027\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - val_loss: 0.1998\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.4899e-04 - val_loss: 0.2035\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2017\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.9066e-04 - val_loss: 0.1964\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - val_loss: 0.1955\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - val_loss: 0.1980\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - val_loss: 0.2035\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2052\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.2034\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0019 - val_loss: 0.1989\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - val_loss: 0.1978\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.1996\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2052\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2035\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.1994\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.1984\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.1999\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2037\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2030\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.1993\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1982\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.1996\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2040\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.2025\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1706e-04 - val_loss: 0.1989\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.1980\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0040 - val_loss: 0.1992\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0027 - val_loss: 0.2026\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.7084e-04 - val_loss: 0.2034\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7597e-05 - val_loss: 0.1985\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.1976\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.1988\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 0.2021\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0021e-04 - val_loss: 0.2028\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.8951e-04 - val_loss: 0.2015\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2002e-04 - val_loss: 0.2023\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.1894e-04 - val_loss: 0.2010\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.2018\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4527e-04 - val_loss: 0.2047\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2052\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2036\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.2001\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.1990\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 0.2000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2029\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.7245e-04 - val_loss: 0.2035\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2154e-06 - val_loss: 0.2027\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.8383e-04 - val_loss: 0.2013\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1746e-04 - val_loss: 0.2021\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.3677e-05 - val_loss: 0.2008\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9660e-04 - val_loss: 0.2043\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2047\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2031\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.1997\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.1987\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.1996\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2024\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9731e-04 - val_loss: 0.2030\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.7143e-04 - val_loss: 0.2015\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7766e-04 - val_loss: 0.2022\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5042e-05 - val_loss: 0.2009\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7228e-04 - val_loss: 0.2041\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2045\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2029\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8268e-04 - val_loss: 0.1996\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.1985\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.1994\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2021\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7635e-05 - val_loss: 0.2064\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2084\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.2083\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.2063\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2026\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6845e-04 - val_loss: 0.1975\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.1947\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0076 - val_loss: 0.1941\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - val_loss: 0.1953\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0071 - val_loss: 0.1982\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2025\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1471e-04 - val_loss: 0.2047\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2048\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2032\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0231e-04 - val_loss: 0.1999\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.1988\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.1995\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2019\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5537e-04 - val_loss: 0.2057\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.2075\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.2073\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - val_loss: 0.2054\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2021\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2395e-04 - val_loss: 0.2007\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2034\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.7057e-04 - val_loss: 0.2036\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8543e-04 - val_loss: 0.2025\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0056e-05 - val_loss: 0.2045\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2046\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2031\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1965e-04 - val_loss: 0.2000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.1989\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.1996\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2019\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1733e-04 - val_loss: 0.2056\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - val_loss: 0.2072\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0047 - val_loss: 0.2071\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.2053\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2020\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5788e-04 - val_loss: 0.2008\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2013\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3715e-04 - val_loss: 0.2036\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7173e-04 - val_loss: 0.2022\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5784e-04 - val_loss: 0.2025\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0392e-04 - val_loss: 0.2045\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2031\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5216e-04 - val_loss: 0.2001\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.1991\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.1997\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2020\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1256e-04 - val_loss: 0.2056\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2072\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.2071\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2053\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2022\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1673e-04 - val_loss: 0.2009\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2014\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8043e-04 - val_loss: 0.2037\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2023\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7538e-04 - val_loss: 0.2027\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1636e-05 - val_loss: 0.2046\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2047\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4073e-04 - val_loss: 0.2003\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.1993\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2021\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7769e-04 - val_loss: 0.2057\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2073\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2072\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.2055\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2024\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5775e-04 - val_loss: 0.2012\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.3715e-04 - val_loss: 0.2039\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2026\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.9123e-04 - val_loss: 0.2029\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6148e-04 - val_loss: 0.2017\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5835e-04 - val_loss: 0.2041\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2029\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3082e-04 - val_loss: 0.2001\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1991\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.1998\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2020\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.4707e-04 - val_loss: 0.2056\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2072\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2071\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2055\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2024\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4925e-04 - val_loss: 0.2013\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2018\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2038\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2040\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.0706e-05 - val_loss: 0.2031\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9415e-04 - val_loss: 0.2019\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.3922e-04 - val_loss: 0.2023\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8657e-04 - val_loss: 0.2043\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2045\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.2648e-04 - val_loss: 0.2003\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.1994\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2001\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2023\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0601e-04 - val_loss: 0.2058\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2074\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:55:43,922] Trial 19 finished with value: 0.004553154110908508 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.1596 - val_loss: 0.3488\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1453 - val_loss: 0.3490\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1421 - val_loss: 0.3078\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0959 - val_loss: 0.2767\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0697 - val_loss: 0.2540\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0490 - val_loss: 0.2323\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0286 - val_loss: 0.2127\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0094 - val_loss: 0.1953\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0083 - val_loss: 0.1864\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0170 - val_loss: 0.1830\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0203 - val_loss: 0.1833\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0199 - val_loss: 0.1863\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0168 - val_loss: 0.1913\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0119 - val_loss: 0.1977\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0055 - val_loss: 0.2053\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.2098\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - val_loss: 0.2117\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - val_loss: 0.2115\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0081 - val_loss: 0.2096\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0063 - val_loss: 0.2062\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - val_loss: 0.2016\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - val_loss: 0.1991\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.1986\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0044 - val_loss: 0.1997\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - val_loss: 0.2022\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7683e-04 - val_loss: 0.2059\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.2077\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - val_loss: 0.2079\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - val_loss: 0.2067\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.2042\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2006\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - val_loss: 0.1988\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - val_loss: 0.1985\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - val_loss: 0.1996\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - val_loss: 0.2020\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - val_loss: 0.2054\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2071\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - val_loss: 0.2073\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0043 - val_loss: 0.2063\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - val_loss: 0.2041\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - val_loss: 0.2008\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - val_loss: 0.1992\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.1990\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - val_loss: 0.2000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - val_loss: 0.2022\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.0527e-04 - val_loss: 0.2054\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - val_loss: 0.2071\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2073\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - val_loss: 0.2064\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - val_loss: 0.2043\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 0.2012\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.1996\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.1994\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2005\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2026\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5970e-04 - val_loss: 0.2057\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2073\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2076\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2066\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2046\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2001\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.1999\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2010\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2031\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9235e-05 - val_loss: 0.2061\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2077\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.2079\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 0.2070\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 0.2051\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2021\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.9061e-04 - val_loss: 0.2006\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2005\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2015\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3251e-04 - val_loss: 0.2043\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2154e-04 - val_loss: 0.2021\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.8592e-04 - val_loss: 0.2018\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.0315e-04 - val_loss: 0.2047\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2053\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2047\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2030\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.3873e-04 - val_loss: 0.2026\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0467e-04 - val_loss: 0.2034\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0650e-04 - val_loss: 0.2030\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0154e-04 - val_loss: 0.2038\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.6884e-04 - val_loss: 0.2034\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.2678e-04 - val_loss: 0.2018\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2025\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2735e-04 - val_loss: 0.2045\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2046\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - val_loss: 0.2029\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1580e-04 - val_loss: 0.2026\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5118e-04 - val_loss: 0.2034\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8142e-04 - val_loss: 0.2030\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0140e-04 - val_loss: 0.2038\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.8590e-04 - val_loss: 0.2034\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6466e-04 - val_loss: 0.2019\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3962e-04 - val_loss: 0.2046\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2047\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.8081e-05 - val_loss: 0.2027\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1401e-04 - val_loss: 0.2036\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2230e-04 - val_loss: 0.2032\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7579e-05 - val_loss: 0.2017\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2025\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4401e-04 - val_loss: 0.2045\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2052\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2046\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.0420e-05 - val_loss: 0.2027\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9570e-04 - val_loss: 0.2036\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5559e-04 - val_loss: 0.2032\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7975e-05 - val_loss: 0.2018\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5267e-04 - val_loss: 0.2046\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2053\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2048\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5107e-05 - val_loss: 0.2006\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.1995\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.1996\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2008\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2030\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6584e-04 - val_loss: 0.2061\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2079\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.2083\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - val_loss: 0.2073\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2055\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2027\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3562e-04 - val_loss: 0.2013\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0952e-04 - val_loss: 0.2043\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2045\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2030\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5119e-04 - val_loss: 0.2027\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1476e-04 - val_loss: 0.2036\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7413e-04 - val_loss: 0.2033\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5019e-04 - val_loss: 0.2019\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2027\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1775e-04 - val_loss: 0.2047\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2054\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2049\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2034\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4253e-04 - val_loss: 0.2008\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.1997\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.1998\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2010\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2032\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.3342e-05 - val_loss: 0.2041\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.5652e-04 - val_loss: 0.2038\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.2522e-04 - val_loss: 0.2024\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9049e-04 - val_loss: 0.2022\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.4455e-04 - val_loss: 0.2032\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6508e-05 - val_loss: 0.2029\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9766e-04 - val_loss: 0.2039\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.0697e-04 - val_loss: 0.2036\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0813e-04 - val_loss: 0.2022\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7489e-04 - val_loss: 0.2020\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0215e-04 - val_loss: 0.2051\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2058\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0026 - val_loss: 0.2053\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0021 - val_loss: 0.2038\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.0289e-04 - val_loss: 0.2013\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2001\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2002\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2015\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9452e-04 - val_loss: 0.2045\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2028\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4629e-04 - val_loss: 0.2027\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9242e-04 - val_loss: 0.2036\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.7995e-04 - val_loss: 0.2034\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5369e-04 - val_loss: 0.2021\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.1897e-05 - val_loss: 0.2051\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2058\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2054\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7380e-04 - val_loss: 0.2015\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2004\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2005\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9297e-04 - val_loss: 0.2048\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:56:05,344] Trial 20 finished with value: 0.0016692131757736206 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.1563 - val_loss: 0.3593\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1712 - val_loss: 0.3304\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1276 - val_loss: 0.3236\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1201 - val_loss: 0.3161\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1125 - val_loss: 0.3087\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1057 - val_loss: 0.3020\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0991 - val_loss: 0.2957\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0928 - val_loss: 0.2894\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0863 - val_loss: 0.2836\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0799 - val_loss: 0.2779\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0744 - val_loss: 0.2726\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0691 - val_loss: 0.2670\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0635 - val_loss: 0.2611\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0577 - val_loss: 0.2554\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0517 - val_loss: 0.2502\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0464 - val_loss: 0.2436\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0398 - val_loss: 0.2368\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0335 - val_loss: 0.2303\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0271 - val_loss: 0.2235\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0202 - val_loss: 0.2162\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0129 - val_loss: 0.2084\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0051 - val_loss: 0.2000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - val_loss: 0.1939\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0094 - val_loss: 0.1899\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0135 - val_loss: 0.1876\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0157 - val_loss: 0.1868\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0164 - val_loss: 0.1874\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0158 - val_loss: 0.1899\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0129 - val_loss: 0.1941\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - val_loss: 0.1992\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.2047\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2080\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - val_loss: 0.2094\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0065 - val_loss: 0.2094\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0065 - val_loss: 0.2082\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - val_loss: 0.2059\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - val_loss: 0.2027\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.5883e-04 - val_loss: 0.2011\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2007\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0023 - val_loss: 0.2015\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.6982e-04 - val_loss: 0.2039\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.1085e-04 - val_loss: 0.2033\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0167e-04 - val_loss: 0.2017\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 0.2021\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.6723e-04 - val_loss: 0.2038\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4276e-04 - val_loss: 0.2043\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.1636e-04 - val_loss: 0.2021\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.6130e-04 - val_loss: 0.2017\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - val_loss: 0.2024\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5836e-04 - val_loss: 0.2040\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.7217e-04 - val_loss: 0.2045\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.1982e-04 - val_loss: 0.2024\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.2265e-04 - val_loss: 0.2020\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.4738e-04 - val_loss: 0.2042\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 0.2041\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.7021e-04 - val_loss: 0.2025\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.4538e-04 - val_loss: 0.2022\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.2477e-04 - val_loss: 0.2028\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.8478e-04 - val_loss: 0.2044\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0013 - val_loss: 0.2048\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - val_loss: 0.2027\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.9883e-04 - val_loss: 0.2023\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.7498e-04 - val_loss: 0.2030\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4636e-04 - val_loss: 0.2045\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - val_loss: 0.2049\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6782e-04 - val_loss: 0.2025\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.4069e-04 - val_loss: 0.2031\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.0042e-05 - val_loss: 0.2046\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 0.2050\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4479e-04 - val_loss: 0.2026\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.1458e-04 - val_loss: 0.2032\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.9942e-05 - val_loss: 0.2028\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.9166e-04 - val_loss: 0.2034\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9999e-04 - val_loss: 0.2030\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0911e-04 - val_loss: 0.2036\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.6399e-04 - val_loss: 0.2032\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.0799e-05 - val_loss: 0.2018\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - val_loss: 0.2023\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.0559e-04 - val_loss: 0.2039\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.7915e-04 - val_loss: 0.2044\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.8009e-04 - val_loss: 0.2025\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.9254e-04 - val_loss: 0.2022\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.9338e-04 - val_loss: 0.2029\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2890e-04 - val_loss: 0.2044\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - val_loss: 0.2043\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0012 - val_loss: 0.2029\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.7597e-04 - val_loss: 0.2026\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.0478e-04 - val_loss: 0.2033\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2836e-04 - val_loss: 0.2029\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2873e-04 - val_loss: 0.2035\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7655e-04 - val_loss: 0.2031\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2932e-06 - val_loss: 0.2037\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.7937e-04 - val_loss: 0.2033\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8115e-04 - val_loss: 0.2020\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0762e-04 - val_loss: 0.2041\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6308e-04 - val_loss: 0.2046\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8345e-04 - val_loss: 0.2028\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5980e-04 - val_loss: 0.2025\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4865e-04 - val_loss: 0.2031\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2591e-05 - val_loss: 0.2028\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.1146e-04 - val_loss: 0.2034\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.1579e-04 - val_loss: 0.2031\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6687e-05 - val_loss: 0.2037\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6303e-04 - val_loss: 0.2033\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8765e-04 - val_loss: 0.2021\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4705e-04 - val_loss: 0.2042\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2047\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2042\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5776e-04 - val_loss: 0.2026\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.3616e-04 - val_loss: 0.2033\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2754e-04 - val_loss: 0.2029\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8744e-04 - val_loss: 0.2036\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4112e-04 - val_loss: 0.2032\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.6619e-05 - val_loss: 0.2020\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6396e-04 - val_loss: 0.2042\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2047\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2042\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1154e-04 - val_loss: 0.2027\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7606e-04 - val_loss: 0.2033\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9485e-04 - val_loss: 0.2030\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0844e-04 - val_loss: 0.2037\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2540e-04 - val_loss: 0.2033\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9090e-04 - val_loss: 0.2021\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2019\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4650e-04 - val_loss: 0.2043\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8470e-05 - val_loss: 0.2028\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3817e-04 - val_loss: 0.2035\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.3197e-04 - val_loss: 0.2032\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.3081e-05 - val_loss: 0.2020\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1814e-04 - val_loss: 0.2042\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2047\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.3656e-05 - val_loss: 0.2028\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1748e-04 - val_loss: 0.2035\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6310e-04 - val_loss: 0.2032\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7412e-05 - val_loss: 0.2021\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4243e-04 - val_loss: 0.2043\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2048\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2044\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6852e-05 - val_loss: 0.2011\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2002\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2003\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2012\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3694e-04 - val_loss: 0.2055\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2068\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2071\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2065\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2051\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2030\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7340e-04 - val_loss: 0.2019\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4811e-04 - val_loss: 0.2043\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4055e-04 - val_loss: 0.2014\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2006\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2016\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4965e-04 - val_loss: 0.2041\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5564e-04 - val_loss: 0.2039\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1263e-04 - val_loss: 0.2028\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8521e-04 - val_loss: 0.2027\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9223e-04 - val_loss: 0.2034\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:56:26,584] Trial 21 finished with value: 0.00029246509075164795 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1673 - val_loss: 0.3604\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1688 - val_loss: 0.3596\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1579 - val_loss: 0.3535\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1506 - val_loss: 0.3428\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1395 - val_loss: 0.3298\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1261 - val_loss: 0.3315\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1287 - val_loss: 0.3291\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1254 - val_loss: 0.3229\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1192 - val_loss: 0.3173\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1146 - val_loss: 0.3136\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1108 - val_loss: 0.3078\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1050 - val_loss: 0.3012\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0978 - val_loss: 0.2957\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0919 - val_loss: 0.2882\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0848 - val_loss: 0.2828\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0794 - val_loss: 0.2770\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0737 - val_loss: 0.2720\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0684 - val_loss: 0.2649\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0614 - val_loss: 0.2576\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0544 - val_loss: 0.2512\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0481 - val_loss: 0.2445\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0414 - val_loss: 0.2375\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0344 - val_loss: 0.2305\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0273 - val_loss: 0.2232\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0199 - val_loss: 0.2154\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0122 - val_loss: 0.2073\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - val_loss: 0.1988\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.1926\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0105 - val_loss: 0.1884\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0148 - val_loss: 0.1857\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0174 - val_loss: 0.1845\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0187 - val_loss: 0.1844\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0187 - val_loss: 0.1854\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0177 - val_loss: 0.1873\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0158 - val_loss: 0.1899\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0132 - val_loss: 0.1932\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0099 - val_loss: 0.1970\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - val_loss: 0.2013\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - val_loss: 0.2059\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - val_loss: 0.2091\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0060 - val_loss: 0.2111\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0080 - val_loss: 0.2122\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0091 - val_loss: 0.2123\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0092 - val_loss: 0.2116\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0085 - val_loss: 0.2101\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0070 - val_loss: 0.2080\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - val_loss: 0.2053\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - val_loss: 0.2021\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - val_loss: 0.2000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.1989\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - val_loss: 0.1988\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - val_loss: 0.1995\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - val_loss: 0.2009\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - val_loss: 0.2030\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.9947e-05 - val_loss: 0.2057\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2073\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - val_loss: 0.2080\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - val_loss: 0.2078\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - val_loss: 0.2069\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.2052\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.2030\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4454e-04 - val_loss: 0.2017\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.2014\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 0.2019\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.5562e-05 - val_loss: 0.2035\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.3018e-04 - val_loss: 0.2031\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.7117e-05 - val_loss: 0.2034\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1102e-04 - val_loss: 0.2030\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.5321e-04 - val_loss: 0.2033\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1583e-04 - val_loss: 0.2029\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.3778e-04 - val_loss: 0.2033\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4009e-04 - val_loss: 0.2028\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0486e-04 - val_loss: 0.2032\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8.0124e-05 - val_loss: 0.2028\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.5779e-04 - val_loss: 0.2031\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2946e-05 - val_loss: 0.2027\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.9926e-04 - val_loss: 0.2031\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.8892e-06 - val_loss: 0.2042\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.1693e-04 - val_loss: 0.2026\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.6749e-04 - val_loss: 0.2023\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.4138e-04 - val_loss: 0.2027\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.9335e-04 - val_loss: 0.2039\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.9082e-04 - val_loss: 0.2042\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.5578e-04 - val_loss: 0.2024\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.9369e-04 - val_loss: 0.2021\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6075e-04 - val_loss: 0.2038\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.4774e-04 - val_loss: 0.2041\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.5564e-04 - val_loss: 0.2036\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.5577e-04 - val_loss: 0.2023\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.7443e-04 - val_loss: 0.2020\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.1046e-04 - val_loss: 0.2037\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.1020e-04 - val_loss: 0.2040\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.2976e-04 - val_loss: 0.2036\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.4109e-04 - val_loss: 0.2023\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.7827e-04 - val_loss: 0.2020\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.9797e-04 - val_loss: 0.2037\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.2849e-04 - val_loss: 0.2041\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.5403e-04 - val_loss: 0.2036\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4.7153e-04 - val_loss: 0.2024\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.4148e-04 - val_loss: 0.2021\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.5271e-04 - val_loss: 0.2038\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.7620e-04 - val_loss: 0.2041\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0010 - val_loss: 0.2036\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.2568e-04 - val_loss: 0.2024\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.8344e-04 - val_loss: 0.2021\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.9280e-04 - val_loss: 0.2026\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.9028e-04 - val_loss: 0.2039\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.3934e-04 - val_loss: 0.2042\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.9223e-04 - val_loss: 0.2025\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1433e-04 - val_loss: 0.2022\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.2217e-04 - val_loss: 0.2027\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.1901e-04 - val_loss: 0.2039\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.1046e-04 - val_loss: 0.2043\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.6517e-04 - val_loss: 0.2026\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.3957e-04 - val_loss: 0.2023\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.4652e-04 - val_loss: 0.2028\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.4323e-04 - val_loss: 0.2040\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.8562e-04 - val_loss: 0.2043\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - val_loss: 0.2039\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4130e-04 - val_loss: 0.2027\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6201e-04 - val_loss: 0.2023\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6839e-04 - val_loss: 0.2028\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6527e-04 - val_loss: 0.2041\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.6278e-04 - val_loss: 0.2044\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.1897e-04 - val_loss: 0.2027\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.8318e-04 - val_loss: 0.2024\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.8913e-04 - val_loss: 0.2029\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.8635e-04 - val_loss: 0.2042\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0010 - val_loss: 0.2045\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.9724e-04 - val_loss: 0.2028\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0385e-04 - val_loss: 0.2025\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.0949e-04 - val_loss: 0.2030\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0706e-04 - val_loss: 0.2042\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2041\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.7573e-04 - val_loss: 0.2029\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2437e-04 - val_loss: 0.2026\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.2978e-04 - val_loss: 0.2031\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.7746e-05 - val_loss: 0.2043\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - val_loss: 0.2042\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4503e-04 - val_loss: 0.2027\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5019e-04 - val_loss: 0.2032\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1409e-05 - val_loss: 0.2028\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7235e-04 - val_loss: 0.2033\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1182e-04 - val_loss: 0.2030\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2697e-04 - val_loss: 0.2035\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4305e-04 - val_loss: 0.2031\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9125e-06 - val_loss: 0.2036\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.5069e-04 - val_loss: 0.2032\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.9854e-05 - val_loss: 0.2021\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2019\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3802e-04 - val_loss: 0.2038\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.6440e-04 - val_loss: 0.2042\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.4923e-04 - val_loss: 0.2026\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9657e-04 - val_loss: 0.2024\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.5281e-04 - val_loss: 0.2029\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0666e-04 - val_loss: 0.2042\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2041\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.8276e-04 - val_loss: 0.2029\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8653e-04 - val_loss: 0.2027\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6538e-04 - val_loss: 0.2032\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9173e-05 - val_loss: 0.2029\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4313e-04 - val_loss: 0.2034\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5944e-04 - val_loss: 0.2031\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1855e-05 - val_loss: 0.2035\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2297e-04 - val_loss: 0.2032\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6278e-05 - val_loss: 0.2021\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9196e-04 - val_loss: 0.2019\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8281e-04 - val_loss: 0.2039\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3367e-04 - val_loss: 0.2043\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4521e-04 - val_loss: 0.2027\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8761e-04 - val_loss: 0.2025\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3328e-04 - val_loss: 0.2030\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8753e-05 - val_loss: 0.2043\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2047\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0175e-05 - val_loss: 0.2028\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0316e-04 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2534e-04 - val_loss: 0.2030\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.2077e-05 - val_loss: 0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:56:46,481] Trial 22 finished with value: 0.00043354928493499756 and parameters: {}. Best is trial 10 with value: 0.00016370415687561035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1503 - val_loss: 0.3293\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1211 - val_loss: 0.3036\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1015 - val_loss: 0.2818\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0798 - val_loss: 0.2710\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0677 - val_loss: 0.2596\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0563 - val_loss: 0.2459\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0424 - val_loss: 0.2304\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0283 - val_loss: 0.2196\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0169 - val_loss: 0.2062\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - val_loss: 0.1904\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0127 - val_loss: 0.1821\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0210 - val_loss: 0.1794\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0236 - val_loss: 0.1808\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0221 - val_loss: 0.1851\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0179 - val_loss: 0.1912\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0118 - val_loss: 0.1984\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0046 - val_loss: 0.2064\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - val_loss: 0.2110\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0079 - val_loss: 0.2128\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0097 - val_loss: 0.2126\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0094 - val_loss: 0.2105\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0074 - val_loss: 0.2070\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.2022\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.2693e-04 - val_loss: 0.1997\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - val_loss: 0.1991\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - val_loss: 0.2001\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.2026\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.6975e-04 - val_loss: 0.2063\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - val_loss: 0.2081\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0050 - val_loss: 0.2083\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0051 - val_loss: 0.2069\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2042\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2004\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - val_loss: 0.1984\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - val_loss: 0.1980\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - val_loss: 0.1992\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0040 - val_loss: 0.2016\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2052\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 0.2070\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.2072\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0040 - val_loss: 0.2060\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.2036\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6572e-04 - val_loss: 0.2001\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.1983\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - val_loss: 0.1980\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0051 - val_loss: 0.1992\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.2016\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2069\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.2071\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - val_loss: 0.2061\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.2038\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.8529e-04 - val_loss: 0.2003\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - val_loss: 0.1986\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0046 - val_loss: 0.1984\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.1995\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - val_loss: 0.2019\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.2053\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - val_loss: 0.2071\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.2074\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - val_loss: 0.2063\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - val_loss: 0.2041\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.2605e-04 - val_loss: 0.2007\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - val_loss: 0.1991\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0041 - val_loss: 0.1988\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - val_loss: 0.2000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - val_loss: 0.2023\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.4098e-04 - val_loss: 0.2057\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - val_loss: 0.2075\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0043 - val_loss: 0.2078\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - val_loss: 0.2067\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - val_loss: 0.2045\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 0.2012\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.1995\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.1993\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.2005\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - val_loss: 0.2028\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.9062e-04 - val_loss: 0.2061\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.2079\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2081\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0050 - val_loss: 0.2071\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - val_loss: 0.2049\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - val_loss: 0.1998\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2009\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2032\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5848e-05 - val_loss: 0.2040\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.4199e-04 - val_loss: 0.2034\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.6114e-04 - val_loss: 0.2016\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2023\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0581e-04 - val_loss: 0.2044\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4142e-04 - val_loss: 0.2021\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5591e-04 - val_loss: 0.2051\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2057\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - val_loss: 0.2050\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2030\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1265e-04 - val_loss: 0.2026\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.7024e-04 - val_loss: 0.2035\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9227e-04 - val_loss: 0.2030\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.0424e-04 - val_loss: 0.2038\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2144e-04 - val_loss: 0.2033\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.3445e-05 - val_loss: 0.2015\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2012\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 0.2022\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.4600e-04 - val_loss: 0.2044\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2051\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.7277e-04 - val_loss: 0.2022\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6682e-04 - val_loss: 0.2031\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9055e-05 - val_loss: 0.2052\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2058\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - val_loss: 0.2051\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.2735e-05 - val_loss: 0.2002\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.1988\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.1988\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.2001\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.2025\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2713e-04 - val_loss: 0.2060\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - val_loss: 0.2078\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0046 - val_loss: 0.2082\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0050 - val_loss: 0.2073\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0041 - val_loss: 0.2052\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - val_loss: 0.2021\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010 - val_loss: 0.2006\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - val_loss: 0.2005\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2039\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.7240e-04 - val_loss: 0.2047\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.6784e-04 - val_loss: 0.2022\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6470e-04 - val_loss: 0.2032\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.8059e-05 - val_loss: 0.2028\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.3651e-04 - val_loss: 0.2037\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9244e-04 - val_loss: 0.2033\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.7320e-04 - val_loss: 0.2017\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - val_loss: 0.2015\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.2026\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0435e-04 - val_loss: 0.2048\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.2055\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2049\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2032\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6492e-06 - val_loss: 0.2028\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.4910e-04 - val_loss: 0.2038\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9508e-04 - val_loss: 0.2033\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.9237e-04 - val_loss: 0.2017\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.4525e-04 - val_loss: 0.2048\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2056\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - val_loss: 0.2050\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - val_loss: 0.2032\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.8394e-05 - val_loss: 0.2004\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.1991\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - val_loss: 0.1992\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - val_loss: 0.2005\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - val_loss: 0.2030\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6917e-04 - val_loss: 0.2064\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - val_loss: 0.2083\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - val_loss: 0.2087\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0056 - val_loss: 0.2079\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - val_loss: 0.2059\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - val_loss: 0.2029\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.7961e-04 - val_loss: 0.2014\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2013\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2025\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.9119e-04 - val_loss: 0.2048\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2056\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - val_loss: 0.2051\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.4012e-04 - val_loss: 0.2006\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - val_loss: 0.1994\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.1995\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - val_loss: 0.2009\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0023 - val_loss: 0.2034\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.1526e-04 - val_loss: 0.2044\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.5029e-04 - val_loss: 0.2025\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0095e-04 - val_loss: 0.2023\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.5838e-04 - val_loss: 0.2034\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.3887e-04 - val_loss: 0.2031\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0580e-05 - val_loss: 0.2042\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - val_loss: 0.2038\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.7675e-04 - val_loss: 0.2023\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.4984e-04 - val_loss: 0.2022\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.8665e-04 - val_loss: 0.2033\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2784e-04 - val_loss: 0.2030\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0480e-04 - val_loss: 0.2041\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 9.2022e-04 - val_loss: 0.2038\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.1016e-04 - val_loss: 0.2023\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.0310e-04 - val_loss: 0.2021\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0010 - val_loss: 0.2032\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:57:04,193] Trial 23 finished with value: 9.453296661376953e-05 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1518 - val_loss: 0.2942\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0886 - val_loss: 0.2345\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0283 - val_loss: 0.1783\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0256 - val_loss: 0.1660\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0343 - val_loss: 0.1728\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0270 - val_loss: 0.1871\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0126 - val_loss: 0.2054\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0056 - val_loss: 0.2128\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0125 - val_loss: 0.2127\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0119 - val_loss: 0.2075\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0063 - val_loss: 0.1989\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.1959\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - val_loss: 0.1970\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0050 - val_loss: 0.2015\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.6786e-04 - val_loss: 0.2086\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0064 - val_loss: 0.2116\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0093 - val_loss: 0.2111\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - val_loss: 0.2079\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0054 - val_loss: 0.2022\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.4082e-04 - val_loss: 0.1999\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - val_loss: 0.2007\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2021\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9664e-04 - val_loss: 0.2027\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.9005e-04 - val_loss: 0.2056\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - val_loss: 0.2058\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - val_loss: 0.2035\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3106e-04 - val_loss: 0.1991\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.1975\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - val_loss: 0.1985\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - val_loss: 0.2018\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2071\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - val_loss: 0.2095\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0065 - val_loss: 0.2093\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - val_loss: 0.2069\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - val_loss: 0.2024\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6829e-04 - val_loss: 0.2007\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - val_loss: 0.2014\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.2048\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2029\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4150e-04 - val_loss: 0.2034\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9217e-04 - val_loss: 0.2016\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2023\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.1335e-04 - val_loss: 0.2051\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0021 - val_loss: 0.2054\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - val_loss: 0.2035\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.9238e-04 - val_loss: 0.1995\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 0.1982\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0048 - val_loss: 0.1992\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.2024\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2290e-04 - val_loss: 0.2074\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0044 - val_loss: 0.2097\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0067 - val_loss: 0.2096\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0066 - val_loss: 0.2074\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2032\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8153e-04 - val_loss: 0.1972\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - val_loss: 0.1940\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0090 - val_loss: 0.1934\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0097 - val_loss: 0.1950\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0080 - val_loss: 0.1987\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.2042\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.2069\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - val_loss: 0.2072\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - val_loss: 0.2054\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - val_loss: 0.2015\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2003\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2043\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.2033\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.4215e-04 - val_loss: 0.1998\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.1987\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0043 - val_loss: 0.1999\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - val_loss: 0.2031\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1347e-04 - val_loss: 0.2039\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.6895e-04 - val_loss: 0.2024\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.7313e-04 - val_loss: 0.2033\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.5417e-04 - val_loss: 0.2019\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3787e-04 - val_loss: 0.2057\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - val_loss: 0.2062\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - val_loss: 0.2045\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - val_loss: 0.1998\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - val_loss: 0.2010\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - val_loss: 0.2033\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0832e-04 - val_loss: 0.1999\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.1989\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - val_loss: 0.2001\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - val_loss: 0.2034\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7800e-04 - val_loss: 0.2042\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.9485e-04 - val_loss: 0.2037\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6802e-04 - val_loss: 0.2024\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5315e-04 - val_loss: 0.2033\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.5876e-04 - val_loss: 0.2020\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 0.2029\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7100e-05 - val_loss: 0.2059\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2064\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - val_loss: 0.2049\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2014\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.2003\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.2015\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2046\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2053\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.9310e-04 - val_loss: 0.2005\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - val_loss: 0.1996\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - val_loss: 0.2008\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - val_loss: 0.2041\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.2039e-04 - val_loss: 0.2002\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.1994\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2007\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.1797e-04 - val_loss: 0.2048\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.7247e-04 - val_loss: 0.2002\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - val_loss: 0.1994\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - val_loss: 0.2007\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2040\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.9483e-04 - val_loss: 0.2049\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9697e-04 - val_loss: 0.2004\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - val_loss: 0.1996\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - val_loss: 0.2009\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2051\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0021 - val_loss: 0.2038\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.1281e-04 - val_loss: 0.2006\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0024 - val_loss: 0.1998\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - val_loss: 0.2012\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2053\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2041\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - val_loss: 0.2009\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2001\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2015\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2047\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2056\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - val_loss: 0.2044\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.2004\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2018\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2050\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 0.2059\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - val_loss: 0.2047\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - val_loss: 0.2015\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - val_loss: 0.2007\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2021\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.3110e-04 - val_loss: 0.2053\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2062\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - val_loss: 0.2050\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - val_loss: 0.2019\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2011\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1119e-04 - val_loss: 0.2056\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - val_loss: 0.2065\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - val_loss: 0.2053\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.2022\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.4119e-04 - val_loss: 0.2014\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2027\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.8969e-04 - val_loss: 0.2060\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - val_loss: 0.2068\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.2056\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - val_loss: 0.2025\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.1768e-04 - val_loss: 0.2017\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2112e-05 - val_loss: 0.2022\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.9718e-04 - val_loss: 0.2035\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.8248e-04 - val_loss: 0.2026\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.8721e-04 - val_loss: 0.2039\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5247e-04 - val_loss: 0.2030\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9874e-05 - val_loss: 0.2042\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.2869e-04 - val_loss: 0.2004\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - val_loss: 0.1998\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - val_loss: 0.2014\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.2048\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2059\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2048\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2012\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2026\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.1102e-04 - val_loss: 0.2059\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.2069\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.2058\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.2027\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8482e-04 - val_loss: 0.2020\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.9069e-04 - val_loss: 0.2034\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.8724e-04 - val_loss: 0.2026\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.8075e-04 - val_loss: 0.2040\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.3636e-04 - val_loss: 0.2031\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1823e-04 - val_loss: 0.2004\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.1999\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:57:21,310] Trial 24 finished with value: 0.003085419535636902 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1605 - val_loss: 0.3368\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1297 - val_loss: 0.3089\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1031 - val_loss: 0.2853\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0805 - val_loss: 0.2649\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0620 - val_loss: 0.2477\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0446 - val_loss: 0.2324\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0289 - val_loss: 0.2192\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0156 - val_loss: 0.2053\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.1910\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0126 - val_loss: 0.1824\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0211 - val_loss: 0.1782\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0252 - val_loss: 0.1774\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0259 - val_loss: 0.1790\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0242 - val_loss: 0.1826\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0206 - val_loss: 0.1876\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0155 - val_loss: 0.1939\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0092 - val_loss: 0.2012\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2096\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.2150\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0120 - val_loss: 0.2179\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0149 - val_loss: 0.2187\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0157 - val_loss: 0.2178\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0148 - val_loss: 0.2154\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0124 - val_loss: 0.2118\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.2072\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2017\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.1983\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.1968\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.1969\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.1983\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.2010\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2046\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2066\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2071\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2063\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2043\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.1998\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.1997\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2010\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2033\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5697e-04 - val_loss: 0.2042\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2037\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6088e-04 - val_loss: 0.2021\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0957e-04 - val_loss: 0.2050\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2057\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2051\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1289e-04 - val_loss: 0.2006\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1993\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.1994\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2007\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2031\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.5504e-05 - val_loss: 0.2064\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2082\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.2087\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.2079\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2060\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2031\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.1599e-05 - val_loss: 0.2017\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2027\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1437e-04 - val_loss: 0.2050\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.2058\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - val_loss: 0.2053\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2037\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7098e-04 - val_loss: 0.2011\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - val_loss: 0.1999\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2001\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.2014\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.5872e-04 - val_loss: 0.2048\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2045\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.5697e-04 - val_loss: 0.2029\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.8880e-04 - val_loss: 0.2039\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8708e-04 - val_loss: 0.2037\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6438e-04 - val_loss: 0.2023\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.2861e-04 - val_loss: 0.2023\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.8619e-04 - val_loss: 0.2034\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.5819e-04 - val_loss: 0.2032\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.5487e-05 - val_loss: 0.2019\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4448e-05 - val_loss: 0.2053\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - val_loss: 0.2062\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - val_loss: 0.2058\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - val_loss: 0.2042\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2005\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2007\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2020\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2044\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 0.2054\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - val_loss: 0.2051\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2037\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0755e-04 - val_loss: 0.2012\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - val_loss: 0.2001\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.2004\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - val_loss: 0.2018\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2050\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2037\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0250e-04 - val_loss: 0.2012\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - val_loss: 0.2002\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.2005\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.2019\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2055\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0021 - val_loss: 0.2039\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3153e-04 - val_loss: 0.2015\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.2008\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2022\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.2380e-04 - val_loss: 0.2047\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - val_loss: 0.2056\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - val_loss: 0.2042\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2011\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2026\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.6626e-04 - val_loss: 0.2051\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - val_loss: 0.2061\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2059\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2046\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2021\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.6898e-04 - val_loss: 0.2011\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - val_loss: 0.2014\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.2029\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.8524e-04 - val_loss: 0.2054\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2065\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2063\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.2049\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2024\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7994e-04 - val_loss: 0.2014\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.0278e-04 - val_loss: 0.2033\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.3499e-04 - val_loss: 0.2023\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.1786e-04 - val_loss: 0.2025\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.9050e-04 - val_loss: 0.2039\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.8622e-04 - val_loss: 0.2039\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5631e-04 - val_loss: 0.2028\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4839e-04 - val_loss: 0.2030\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.8327e-05 - val_loss: 0.2019\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.8479e-04 - val_loss: 0.2022\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.2144e-04 - val_loss: 0.2036\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8781e-04 - val_loss: 0.2037\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.8700e-04 - val_loss: 0.2026\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9138e-04 - val_loss: 0.2028\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.1121e-05 - val_loss: 0.2042\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8531e-04 - val_loss: 0.2009\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.2004\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - val_loss: 0.2009\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.2025\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.0073e-04 - val_loss: 0.2052\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2064\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2063\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2051\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1784e-04 - val_loss: 0.2019\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - val_loss: 0.2023\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.0739e-04 - val_loss: 0.2039\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.5378e-04 - val_loss: 0.2041\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.6101e-04 - val_loss: 0.2031\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.0053e-05 - val_loss: 0.2034\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.4036e-04 - val_loss: 0.2024\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0040e-04 - val_loss: 0.2028\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.4212e-04 - val_loss: 0.2043\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1334e-04 - val_loss: 0.2013\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.2006\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0026 - val_loss: 0.2011\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.7266e-04 - val_loss: 0.2056\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2069\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.2068\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.2056\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0025 - val_loss: 0.2033\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.6455e-04 - val_loss: 0.2000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.1983\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - val_loss: 0.1979\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - val_loss: 0.1988\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - val_loss: 0.2008\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.2916e-04 - val_loss: 0.2054\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2055\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - val_loss: 0.2045\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2024\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.1220e-04 - val_loss: 0.2017\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - val_loss: 0.2023\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6126e-04 - val_loss: 0.2040\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:57:38,270] Trial 25 finished with value: 0.0008264034986495972 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1558 - val_loss: 0.3218\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1025 - val_loss: 0.2549\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0360 - val_loss: 0.1902\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0266 - val_loss: 0.1718\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0380 - val_loss: 0.1807\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0265 - val_loss: 0.2006\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0065 - val_loss: 0.2237\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0167 - val_loss: 0.2333\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0263 - val_loss: 0.2345\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0275 - val_loss: 0.2301\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0230 - val_loss: 0.2218\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0144 - val_loss: 0.2103\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1964\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0111 - val_loss: 0.1886\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0187 - val_loss: 0.1859\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0212 - val_loss: 0.1872\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0198 - val_loss: 0.1916\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0152 - val_loss: 0.1984\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0082 - val_loss: 0.2069\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.2078e-04 - val_loss: 0.2115\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0054 - val_loss: 0.2129\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.2118\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0060 - val_loss: 0.2085\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2034\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2011\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.2013\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2036\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2076\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2092\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 0.2087\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2063\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.9416e-04 - val_loss: 0.2022\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.2005\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.2009\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2031\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2069\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2085\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2081\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2061\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2009\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2014\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2035\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2071\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2087\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2084\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2065\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2022\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2043\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9308e-04 - val_loss: 0.2077\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2092\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.2090\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.2071\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2039\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.2826e-04 - val_loss: 0.2026\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2031\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2050\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.7691e-04 - val_loss: 0.2052\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9890e-04 - val_loss: 0.2039\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.0788e-04 - val_loss: 0.2042\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6253e-04 - val_loss: 0.2060\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2061\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0470e-04 - val_loss: 0.2018\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2008\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2015\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2036\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2668e-04 - val_loss: 0.2071\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2087\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2086\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2070\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2041\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.1139e-04 - val_loss: 0.2029\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.1514e-04 - val_loss: 0.2054\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2057\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2277e-04 - val_loss: 0.2018\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2009\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2017\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4058e-04 - val_loss: 0.2073\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2089\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2089\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.2074\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2046\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6274e-04 - val_loss: 0.2005\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.1984\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0058 - val_loss: 0.1980\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.1991\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - val_loss: 0.2016\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2054\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2072\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2074\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2062\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2037\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8750e-04 - val_loss: 0.2028\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2492e-04 - val_loss: 0.2056\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0017 - val_loss: 0.2060\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2019\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2027\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2048\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2471e-04 - val_loss: 0.2053\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8386e-04 - val_loss: 0.2021\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2014\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - val_loss: 0.2023\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2045\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4138e-04 - val_loss: 0.2050\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.9819e-04 - val_loss: 0.2019\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2013\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2022\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9339e-04 - val_loss: 0.2050\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0173e-04 - val_loss: 0.2019\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0019 - val_loss: 0.2013\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - val_loss: 0.2022\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6738e-04 - val_loss: 0.2050\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.0288e-04 - val_loss: 0.2020\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.2014\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - val_loss: 0.2023\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2045\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0344e-04 - val_loss: 0.2051\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.5327e-04 - val_loss: 0.2021\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.2016\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2025\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2047\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.7011e-04 - val_loss: 0.2053\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.2749e-04 - val_loss: 0.2023\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2054\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.1229e-04 - val_loss: 0.2025\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.5816e-04 - val_loss: 0.2050\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2056\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - val_loss: 0.2048\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2027\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010 - val_loss: 0.2021\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5954e-04 - val_loss: 0.2052\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2058\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2028\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.2628e-04 - val_loss: 0.2023\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.6168e-04 - val_loss: 0.2054\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2059\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2051\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - val_loss: 0.2030\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2813e-04 - val_loss: 0.2025\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.6570e-04 - val_loss: 0.2055\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.2061\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2053\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.3230e-04 - val_loss: 0.2027\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.5990e-04 - val_loss: 0.2036\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2345e-05 - val_loss: 0.2057\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.2063\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2055\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2034\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3946e-04 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6474e-04 - val_loss: 0.2037\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1785e-04 - val_loss: 0.2032\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.3978e-04 - val_loss: 0.2040\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.1027e-04 - val_loss: 0.2034\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7364e-04 - val_loss: 0.2043\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.5011e-04 - val_loss: 0.2036\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.4942e-05 - val_loss: 0.2018\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0019 - val_loss: 0.2014\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2024\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2047\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2054\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.4616e-04 - val_loss: 0.2023\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.1674e-04 - val_loss: 0.2055\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2061\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2054\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2034\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2842e-04 - val_loss: 0.2029\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.9977e-04 - val_loss: 0.2038\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.1531e-04 - val_loss: 0.2033\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.9723e-04 - val_loss: 0.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:57:56,254] Trial 26 finished with value: 0.0005773603916168213 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1570 - val_loss: 0.3855\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1929 - val_loss: 0.3698\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1709 - val_loss: 0.3476\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1446 - val_loss: 0.3411\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1388 - val_loss: 0.3387\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1367 - val_loss: 0.3336\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1311 - val_loss: 0.3279\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1254 - val_loss: 0.3199\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1176 - val_loss: 0.3155\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1122 - val_loss: 0.3103\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1059 - val_loss: 0.3004\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0964 - val_loss: 0.2887\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0843 - val_loss: 0.2751\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0706 - val_loss: 0.2618\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0574 - val_loss: 0.2488\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0443 - val_loss: 0.2356\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0321 - val_loss: 0.2260\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0226 - val_loss: 0.2165\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0131 - val_loss: 0.2063\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.1955\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0076 - val_loss: 0.1880\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0148 - val_loss: 0.1836\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0191 - val_loss: 0.1817\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0208 - val_loss: 0.1820\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0206 - val_loss: 0.1839\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0187 - val_loss: 0.1872\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0155 - val_loss: 0.1915\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0112 - val_loss: 0.1972\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - val_loss: 0.2038\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.4502e-04 - val_loss: 0.2077\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.2094\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0064 - val_loss: 0.2093\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0063 - val_loss: 0.2076\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - val_loss: 0.2050\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.3515e-04 - val_loss: 0.2008\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2007\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2018\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2974e-04 - val_loss: 0.2046\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9251e-04 - val_loss: 0.2026\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6027e-04 - val_loss: 0.2023\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2967e-04 - val_loss: 0.2032\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0977e-05 - val_loss: 0.2029\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7880e-04 - val_loss: 0.2037\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4105e-04 - val_loss: 0.2033\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6351e-04 - val_loss: 0.2019\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4574e-04 - val_loss: 0.2046\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2047\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6880e-05 - val_loss: 0.2028\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4474e-04 - val_loss: 0.2037\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.7447e-04 - val_loss: 0.2033\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1736e-04 - val_loss: 0.2019\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4291e-04 - val_loss: 0.2046\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2047\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2032\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3330e-06 - val_loss: 0.2029\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0190e-04 - val_loss: 0.2037\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1406e-04 - val_loss: 0.2033\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6846e-04 - val_loss: 0.2020\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2027\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6496e-04 - val_loss: 0.2046\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2053\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2048\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3208e-05 - val_loss: 0.2008\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.1997\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - val_loss: 0.1998\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2009\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2030\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4995e-04 - val_loss: 0.2060\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.2076\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2079\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 0.2072\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2055\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2029\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3900e-04 - val_loss: 0.2017\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8874e-04 - val_loss: 0.2045\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.2048\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0784e-04 - val_loss: 0.2010\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2001\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2013\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.9039e-04 - val_loss: 0.2042\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3145e-04 - val_loss: 0.2026\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8261e-04 - val_loss: 0.2024\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1481e-04 - val_loss: 0.2034\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1668e-04 - val_loss: 0.2032\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4820e-06 - val_loss: 0.2019\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0154e-04 - val_loss: 0.2048\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2055\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2051\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2037\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1726e-04 - val_loss: 0.2014\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2003\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.2004\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2778e-04 - val_loss: 0.2045\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3124e-04 - val_loss: 0.2028\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6024e-04 - val_loss: 0.2037\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.6724e-04 - val_loss: 0.2035\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6022e-04 - val_loss: 0.2023\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6874e-04 - val_loss: 0.2022\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.3032e-04 - val_loss: 0.2032\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8755e-05 - val_loss: 0.2031\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3773e-05 - val_loss: 0.2040\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.1046e-04 - val_loss: 0.2037\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8453e-04 - val_loss: 0.2025\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5969e-04 - val_loss: 0.2024\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3680e-04 - val_loss: 0.2034\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3675e-04 - val_loss: 0.2032\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.1824e-05 - val_loss: 0.2020\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2726e-04 - val_loss: 0.2050\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2057\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2053\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.8431e-04 - val_loss: 0.2017\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2006\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2008\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2019\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7219e-04 - val_loss: 0.2049\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2046\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4749e-04 - val_loss: 0.2011\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2002\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2004\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2016\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8246e-04 - val_loss: 0.2046\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3362e-06 - val_loss: 0.2031\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.7634e-05 - val_loss: 0.2040\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.7309e-04 - val_loss: 0.2039\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.0387e-04 - val_loss: 0.2027\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8301e-04 - val_loss: 0.2026\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1479e-04 - val_loss: 0.2036\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9295e-04 - val_loss: 0.2035\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6536e-04 - val_loss: 0.2024\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8447e-04 - val_loss: 0.2024\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8250e-04 - val_loss: 0.2034\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5599e-04 - val_loss: 0.2033\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.5576e-04 - val_loss: 0.2022\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6969e-04 - val_loss: 0.2022\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.4552e-04 - val_loss: 0.2033\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1303e-04 - val_loss: 0.2032\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0741e-05 - val_loss: 0.2021\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - val_loss: 0.2032\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1710e-05 - val_loss: 0.2031\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.8788e-05 - val_loss: 0.2041\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.3117e-04 - val_loss: 0.2039\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.7252e-04 - val_loss: 0.2028\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.0273e-04 - val_loss: 0.2027\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.2619e-04 - val_loss: 0.2037\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8706e-04 - val_loss: 0.2036\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6647e-04 - val_loss: 0.2025\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.7532e-04 - val_loss: 0.2025\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.6787e-04 - val_loss: 0.2035\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.7371e-04 - val_loss: 0.2034\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.7807e-04 - val_loss: 0.2023\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4157e-04 - val_loss: 0.2023\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.1389e-04 - val_loss: 0.2034\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.4621e-04 - val_loss: 0.2033\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6694e-04 - val_loss: 0.2022\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.3804e-04 - val_loss: 0.2023\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.9704e-04 - val_loss: 0.2033\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7504e-04 - val_loss: 0.2033\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0656e-04 - val_loss: 0.2022\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.8872e-04 - val_loss: 0.2022\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.3900e-04 - val_loss: 0.2033\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4083e-04 - val_loss: 0.2032\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.9423e-05 - val_loss: 0.2021\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2022\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.5387e-04 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3092e-04 - val_loss: 0.2032\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.4133e-05 - val_loss: 0.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:58:15,624] Trial 27 finished with value: 0.0010101646184921265 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.1506 - val_loss: 0.3234\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1169 - val_loss: 0.2595\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0478 - val_loss: 0.2126\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2129\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.1966\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0131 - val_loss: 0.1997\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0092 - val_loss: 0.2110\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0065 - val_loss: 0.2113\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0067 - val_loss: 0.2059\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6217e-04 - val_loss: 0.1955\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0098 - val_loss: 0.1919\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0133 - val_loss: 0.1939\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0112 - val_loss: 0.2002\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - val_loss: 0.2092\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.2133\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0088 - val_loss: 0.2135\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0090 - val_loss: 0.2105\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.2046\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.5093e-04 - val_loss: 0.2024\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2034\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2071\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2077\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2055\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7670e-04 - val_loss: 0.2010\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.1995\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2008\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2045\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5944e-05 - val_loss: 0.2101\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2128\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0085 - val_loss: 0.2129\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0086 - val_loss: 0.2107\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0065 - val_loss: 0.2065\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2005\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.1974\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0070 - val_loss: 0.1967\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0076 - val_loss: 0.1984\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - val_loss: 0.2021\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2074\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2101\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.2104\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - val_loss: 0.2088\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.2053\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2002\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.1977\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0064 - val_loss: 0.1973\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0067 - val_loss: 0.1989\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.2023\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2072\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2096\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0058 - val_loss: 0.2100\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.2086\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2054\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.1985\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - val_loss: 0.1982\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0057 - val_loss: 0.1997\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.2028\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2073\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2096\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0059 - val_loss: 0.2100\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.2086\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2056\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2013\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.1990\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.1987\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2002\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2031\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9524e-04 - val_loss: 0.2074\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - val_loss: 0.2097\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0060 - val_loss: 0.2100\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0063 - val_loss: 0.2086\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - val_loss: 0.2058\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2016\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.1994\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0042 - val_loss: 0.1992\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.2005\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2034\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.9150e-04 - val_loss: 0.2075\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2097\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0060 - val_loss: 0.2100\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0063 - val_loss: 0.2087\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2059\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2018\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.1998\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.1995\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2008\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2036\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.2154e-05 - val_loss: 0.2076\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - val_loss: 0.2097\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0061 - val_loss: 0.2100\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0064 - val_loss: 0.2087\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - val_loss: 0.2060\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2021\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.1998\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2010\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7238e-04 - val_loss: 0.2046\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5328e-04 - val_loss: 0.2017\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2013\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2024\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2057\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2049\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2027\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4500e-04 - val_loss: 0.2022\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1142e-04 - val_loss: 0.2056\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2063\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2055\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2032\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0774e-04 - val_loss: 0.2026\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5516e-04 - val_loss: 0.2036\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3486e-04 - val_loss: 0.2030\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5393e-04 - val_loss: 0.2040\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9525e-04 - val_loss: 0.2034\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2730e-04 - val_loss: 0.2043\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.8867e-04 - val_loss: 0.2036\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3870e-04 - val_loss: 0.2016\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2012\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2023\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2048\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2056\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2048\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2998e-04 - val_loss: 0.2022\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6874e-04 - val_loss: 0.2056\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2063\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2055\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1389e-04 - val_loss: 0.2027\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4241e-04 - val_loss: 0.2037\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4338e-04 - val_loss: 0.2031\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2830e-04 - val_loss: 0.2041\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1581e-04 - val_loss: 0.2035\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.9705e-06 - val_loss: 0.2014\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2011\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2022\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2047\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2055\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2048\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7635e-04 - val_loss: 0.2022\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8948e-04 - val_loss: 0.2056\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2063\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2055\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6218e-05 - val_loss: 0.2028\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9886e-04 - val_loss: 0.2038\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.8522e-04 - val_loss: 0.2032\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7191e-04 - val_loss: 0.2042\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.6938e-04 - val_loss: 0.2036\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7601e-04 - val_loss: 0.2016\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2013\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2024\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.9532e-04 - val_loss: 0.2049\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2057\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2049\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2028\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6385e-04 - val_loss: 0.2024\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2034\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5257e-05 - val_loss: 0.2029\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7745e-04 - val_loss: 0.2039\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0481e-04 - val_loss: 0.2033\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3586e-05 - val_loss: 0.2043\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9535e-04 - val_loss: 0.2037\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0984e-04 - val_loss: 0.2017\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2014\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2025\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4369e-04 - val_loss: 0.2050\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2050\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2030\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0527e-04 - val_loss: 0.2025\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.4694e-04 - val_loss: 0.2035\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8467e-04 - val_loss: 0.2030\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1331e-04 - val_loss: 0.2040\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.6501e-04 - val_loss: 0.2035\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2125e-04 - val_loss: 0.2016\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2013\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2024\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.3116e-04 - val_loss: 0.2049\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2057\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2050\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2029\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0394e-04 - val_loss: 0.2025\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.2602e-04 - val_loss: 0.2036\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1668e-04 - val_loss: 0.2031\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6475e-04 - val_loss: 0.2041\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2186e-04 - val_loss: 0.2035\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9224e-04 - val_loss: 0.2016\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2013\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2025\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2649e-04 - val_loss: 0.2050\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2051\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:58:35,843] Trial 28 finished with value: 0.0002742260694503784 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1512 - val_loss: 0.3793\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1832 - val_loss: 0.3549\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1517 - val_loss: 0.3444\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1396 - val_loss: 0.3292\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1248 - val_loss: 0.3188\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1152 - val_loss: 0.3094\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1060 - val_loss: 0.3006\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0974 - val_loss: 0.2920\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0888 - val_loss: 0.2839\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0812 - val_loss: 0.2782\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0752 - val_loss: 0.2716\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0681 - val_loss: 0.2657\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0624 - val_loss: 0.2597\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0563 - val_loss: 0.2532\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0498 - val_loss: 0.2463\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0430 - val_loss: 0.2394\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0361 - val_loss: 0.2324\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0292 - val_loss: 0.2254\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0223 - val_loss: 0.2183\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0153 - val_loss: 0.2111\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0081 - val_loss: 0.2037\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7718e-04 - val_loss: 0.1960\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.1904\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0126 - val_loss: 0.1865\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0165 - val_loss: 0.1841\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0188 - val_loss: 0.1831\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0198 - val_loss: 0.1833\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0197 - val_loss: 0.1844\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0185 - val_loss: 0.1864\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0166 - val_loss: 0.1891\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0139 - val_loss: 0.1923\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0106 - val_loss: 0.1961\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0069 - val_loss: 0.2002\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2046\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2077\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2097\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0067 - val_loss: 0.2107\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0077 - val_loss: 0.2109\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0078 - val_loss: 0.2102\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0072 - val_loss: 0.2090\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0059 - val_loss: 0.2071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2046\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.1997\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.1988\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.1987\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.1994\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2007\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2027\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.3426e-04 - val_loss: 0.2051\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2066\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2072\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - val_loss: 0.2071\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2062\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2048\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2027\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1196e-04 - val_loss: 0.2016\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2029\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2680e-04 - val_loss: 0.2046\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2055\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2055\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2049\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2036\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5462e-04 - val_loss: 0.2017\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2007\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2005\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2011\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2023\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7413e-04 - val_loss: 0.2042\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2051\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2052\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2046\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6928e-04 - val_loss: 0.2016\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2006\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2005\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2011\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2024\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3475e-04 - val_loss: 0.2042\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2052\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2053\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2048\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2653e-04 - val_loss: 0.2018\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2009\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2008\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2014\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2026\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9688e-04 - val_loss: 0.2045\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2054\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2056\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2050\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2038\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9880e-04 - val_loss: 0.2021\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2012\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2011\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2017\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2029\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9433e-04 - val_loss: 0.2048\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2057\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2059\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2053\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2041\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5127e-04 - val_loss: 0.2015\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2014\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2697e-04 - val_loss: 0.2037\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5456e-04 - val_loss: 0.2034\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4629e-04 - val_loss: 0.2024\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.2630e-04 - val_loss: 0.2022\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0519e-04 - val_loss: 0.2028\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6862e-04 - val_loss: 0.2039\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.0739e-04 - val_loss: 0.2043\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2039\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 8.1228e-04 - val_loss: 0.2029\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.0427e-04 - val_loss: 0.2027\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2602e-04 - val_loss: 0.2032\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9171e-05 - val_loss: 0.2029\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7868e-04 - val_loss: 0.2034\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.9182e-04 - val_loss: 0.2031\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2888e-05 - val_loss: 0.2022\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1337e-04 - val_loss: 0.2021\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9624e-04 - val_loss: 0.2038\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0368e-04 - val_loss: 0.2042\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.5227e-04 - val_loss: 0.2029\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4407e-04 - val_loss: 0.2027\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4875e-04 - val_loss: 0.2032\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0722e-05 - val_loss: 0.2030\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7314e-04 - val_loss: 0.2034\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0877e-04 - val_loss: 0.2032\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1275e-05 - val_loss: 0.2023\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.7352e-04 - val_loss: 0.2021\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - val_loss: 0.2027\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4023e-04 - val_loss: 0.2039\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6482e-04 - val_loss: 0.2043\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.2558e-04 - val_loss: 0.2030\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6379e-04 - val_loss: 0.2028\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.6341e-04 - val_loss: 0.2033\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4937e-04 - val_loss: 0.2030\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.0302e-05 - val_loss: 0.2035\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0419e-04 - val_loss: 0.2033\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5025e-04 - val_loss: 0.2024\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7018e-04 - val_loss: 0.2022\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.0541e-04 - val_loss: 0.2028\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3294e-04 - val_loss: 0.2040\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7203e-04 - val_loss: 0.2044\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2041\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3612e-04 - val_loss: 0.2031\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0157e-05 - val_loss: 0.2029\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4812e-04 - val_loss: 0.2034\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6496e-04 - val_loss: 0.2032\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6746e-05 - val_loss: 0.2023\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6030e-04 - val_loss: 0.2022\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7466e-04 - val_loss: 0.2027\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.8373e-04 - val_loss: 0.2040\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.3733e-04 - val_loss: 0.2044\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.3018e-04 - val_loss: 0.2031\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2900e-05 - val_loss: 0.2029\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2963e-04 - val_loss: 0.2034\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.9284e-04 - val_loss: 0.2032\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3791e-05 - val_loss: 0.2023\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.1417e-04 - val_loss: 0.2022\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.2117e-04 - val_loss: 0.2028\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2444e-04 - val_loss: 0.2040\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.0091e-04 - val_loss: 0.2044\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2041\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2032\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6091e-05 - val_loss: 0.2016\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2009\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2017\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2030\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.5920e-05 - val_loss: 0.2050\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2060\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2062\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2058\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2047\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1718e-04 - val_loss: 0.2022\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3397e-04 - val_loss: 0.2021\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7819e-04 - val_loss: 0.2028\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2704e-04 - val_loss: 0.2041\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.4478e-04 - val_loss: 0.2045\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0710e-04 - val_loss: 0.2018\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2012\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1912e-04 - val_loss: 0.2039\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6865e-04 - val_loss: 0.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:58:54,218] Trial 29 finished with value: 0.0005796104669570923 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1458 - val_loss: 0.3308\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1233 - val_loss: 0.3063\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1001 - val_loss: 0.2867\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0808 - val_loss: 0.2730\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0701 - val_loss: 0.2632\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0601 - val_loss: 0.2509\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0480 - val_loss: 0.2371\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0342 - val_loss: 0.2203\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0175 - val_loss: 0.2030\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3833e-04 - val_loss: 0.1973\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0060 - val_loss: 0.1980\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - val_loss: 0.2035\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6626e-04 - val_loss: 0.2035\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3705e-04 - val_loss: 0.1997\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2035\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8831e-04 - val_loss: 0.2033\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4277e-04 - val_loss: 0.2003\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2004\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2032\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0516e-04 - val_loss: 0.2030\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4182e-05 - val_loss: 0.2004\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2005\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2029\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7568e-05 - val_loss: 0.2073\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2087\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - val_loss: 0.2081\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2057\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2013\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.1994\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.1998\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1593e-04 - val_loss: 0.2060\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2075\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2070\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2048\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2010\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.1995\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.1999\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2021\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4177e-04 - val_loss: 0.2057\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2073\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2070\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2052\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2019\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6581e-04 - val_loss: 0.2006\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2011\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7758e-04 - val_loss: 0.2034\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1573e-04 - val_loss: 0.2020\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5207e-04 - val_loss: 0.2024\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9479e-04 - val_loss: 0.2043\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2044\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2030\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2456e-04 - val_loss: 0.2002\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.1992\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.1999\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2021\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9587e-04 - val_loss: 0.2056\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2072\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.2071\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2057\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2029\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1261e-04 - val_loss: 0.1989\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.1968\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.1964\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.1976\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2001\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2056\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2059\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2047\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3570e-04 - val_loss: 0.2016\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2023\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4887e-04 - val_loss: 0.2042\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2046\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0810e-04 - val_loss: 0.2015\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2008\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2016\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0269e-04 - val_loss: 0.2041\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9802e-04 - val_loss: 0.2011\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2005\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2013\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2409e-04 - val_loss: 0.2039\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.3229e-04 - val_loss: 0.2030\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0444e-04 - val_loss: 0.2010\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2005\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2013\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2033\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4940e-04 - val_loss: 0.2038\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.7519e-04 - val_loss: 0.2030\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.4267e-05 - val_loss: 0.2010\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2005\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2013\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.7941e-04 - val_loss: 0.2039\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.1270e-04 - val_loss: 0.2031\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2751e-04 - val_loss: 0.2011\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2006\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2014\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6240e-04 - val_loss: 0.2040\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.9798e-04 - val_loss: 0.2032\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2262e-04 - val_loss: 0.2012\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2007\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2016\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7137e-04 - val_loss: 0.2041\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3796e-04 - val_loss: 0.2014\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2017\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9250e-04 - val_loss: 0.2042\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2035\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6246e-04 - val_loss: 0.2015\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2010\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2018\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2038\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1865e-04 - val_loss: 0.2043\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9040e-04 - val_loss: 0.2017\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2012\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2020\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.4622e-04 - val_loss: 0.2045\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.1894e-04 - val_loss: 0.2018\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2021\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.8485e-04 - val_loss: 0.2041\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2039\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.4674e-04 - val_loss: 0.2019\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2023\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.5150e-04 - val_loss: 0.2042\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2047\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7314e-04 - val_loss: 0.2021\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.3265e-04 - val_loss: 0.2016\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2024\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2005e-04 - val_loss: 0.2043\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2041\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2022\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0179e-04 - val_loss: 0.2017\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9073e-04 - val_loss: 0.2045\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2050\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2042\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2024\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7303e-04 - val_loss: 0.2019\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6342e-04 - val_loss: 0.2046\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4631e-04 - val_loss: 0.2020\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2028\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3809e-04 - val_loss: 0.2047\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2052\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2045\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2148e-04 - val_loss: 0.2021\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0101e-04 - val_loss: 0.2029\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1462e-04 - val_loss: 0.2048\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2054\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2046\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2027\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9853e-04 - val_loss: 0.2023\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7693e-04 - val_loss: 0.2030\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.0930e-06 - val_loss: 0.2025\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9990e-04 - val_loss: 0.2033\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5657e-04 - val_loss: 0.2028\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.7356e-04 - val_loss: 0.2035\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6055e-04 - val_loss: 0.2029\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.8304e-05 - val_loss: 0.2037\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.2773e-04 - val_loss: 0.2031\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3702e-05 - val_loss: 0.2014\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2010\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2020\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5731e-04 - val_loss: 0.2046\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3263e-04 - val_loss: 0.2022\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.5504e-04 - val_loss: 0.2018\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0491e-04 - val_loss: 0.2046\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2052\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2045\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2027\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.7526e-04 - val_loss: 0.2022\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.1040e-04 - val_loss: 0.2030\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9621e-06 - val_loss: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:59:12,284] Trial 30 finished with value: 0.00046622753143310547 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1950 - val_loss: 0.2480\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0295 - val_loss: 0.1464\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0675 - val_loss: 0.1329\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0689 - val_loss: 0.1577\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0391 - val_loss: 0.1961\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2419\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0444 - val_loss: 0.2585\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0583 - val_loss: 0.2549\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0536 - val_loss: 0.2371\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0340 - val_loss: 0.2065\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0086 - val_loss: 0.1861\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0111 - val_loss: 0.1790\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0182 - val_loss: 0.1805\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0166 - val_loss: 0.1885\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0084 - val_loss: 0.2014\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2068\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0097 - val_loss: 0.2060\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - val_loss: 0.2002\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.1905\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0077 - val_loss: 0.1867\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0117 - val_loss: 0.1877\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0108 - val_loss: 0.1928\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - val_loss: 0.2014\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2050\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.2043\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.1999\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1494e-04 - val_loss: 0.1924\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0069 - val_loss: 0.1894\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0100 - val_loss: 0.1902\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0093 - val_loss: 0.1943\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.2014\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.2037\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.1999\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8071e-05 - val_loss: 0.1933\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0066 - val_loss: 0.1907\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - val_loss: 0.1914\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.1951\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.2014\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2034\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8737e-04 - val_loss: 0.1998\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2764e-04 - val_loss: 0.2025\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2020\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.1988\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.1987\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2015\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.4882e-04 - val_loss: 0.2012\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8882e-04 - val_loss: 0.1981\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.1981\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2009\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2566e-04 - val_loss: 0.2007\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7325e-05 - val_loss: 0.2032\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.2027\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.1995\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.1994\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6467e-04 - val_loss: 0.1987\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.1987\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2013\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5425e-04 - val_loss: 0.2011\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6099e-04 - val_loss: 0.1981\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.1982\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2009\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9412e-05 - val_loss: 0.2060\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.2079\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.2070\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.2036\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.1979\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.1953\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.1957\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0054 - val_loss: 0.1987\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2039\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2060\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2054\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.2022\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8976e-04 - val_loss: 0.1968\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.1946\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - val_loss: 0.1951\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.1981\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2033\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2055\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2049\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2020\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0397e-04 - val_loss: 0.1968\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.1947\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0069 - val_loss: 0.1952\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.1982\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2034\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2055\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2050\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2022\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2363e-04 - val_loss: 0.1973\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 0.1955\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.1977\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2029\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.2629e-04 - val_loss: 0.2039\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2016\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4820e-04 - val_loss: 0.2027\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1745e-04 - val_loss: 0.2006\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2017\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1288e-04 - val_loss: 0.2057\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2063\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2039\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.1989\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.1972\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - val_loss: 0.1986\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2027\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6009e-04 - val_loss: 0.2035\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3200e-04 - val_loss: 0.2024\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.8516e-04 - val_loss: 0.2006\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2016\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8505e-04 - val_loss: 0.2052\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2057\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.2036\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.1990\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.1976\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.1989\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2027\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0919e-04 - val_loss: 0.2035\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0012 - val_loss: 0.2016\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5041e-04 - val_loss: 0.2025\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3495e-04 - val_loss: 0.2008\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2018\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3386e-04 - val_loss: 0.2052\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2057\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2037\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.1994\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.1980\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.1993\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.2029\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3513e-04 - val_loss: 0.2037\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2019\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5986e-04 - val_loss: 0.2028\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0185e-04 - val_loss: 0.2011\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1938e-04 - val_loss: 0.2054\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2059\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2039\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.1998\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1984\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.1997\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2032\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6085e-04 - val_loss: 0.2039\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2022\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0000e-04 - val_loss: 0.2031\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4270e-04 - val_loss: 0.2015\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.7314e-04 - val_loss: 0.2024\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3644e-05 - val_loss: 0.2056\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2061\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2042\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.2001\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.1988\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.2001\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - val_loss: 0.2035\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2042\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2026\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.8127e-05 - val_loss: 0.1987\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.1976\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - val_loss: 0.1989\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.2025\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9312e-05 - val_loss: 0.2080\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.2106\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.2107\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0081 - val_loss: 0.2084\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - val_loss: 0.2041\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.1979\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.1946\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - val_loss: 0.1940\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0085 - val_loss: 0.1958\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0067 - val_loss: 0.1997\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2055\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2084\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2087\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.2068\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2028\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6667e-04 - val_loss: 0.1969\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - val_loss: 0.1939\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0087 - val_loss: 0.1934\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0091 - val_loss: 0.1953\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0073 - val_loss: 0.1993\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2050\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2080\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0054 - val_loss: 0.2084\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - val_loss: 0.2066\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2028\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2159e-04 - val_loss: 0.1971\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.1942\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 0.1938\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0088 - val_loss: 0.1957\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0069 - val_loss: 0.1996\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.2053\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2083\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.2087\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0060 - val_loss: 0.2070\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.2032\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3702e-04 - val_loss: 0.1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:59:30,311] Trial 31 finished with value: 0.005022957921028137 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1697 - val_loss: 0.3354\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1294 - val_loss: 0.3199\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1143 - val_loss: 0.3031\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1005 - val_loss: 0.2905\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0880 - val_loss: 0.2822\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0779 - val_loss: 0.2719\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0674 - val_loss: 0.2606\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0562 - val_loss: 0.2491\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0445 - val_loss: 0.2367\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0316 - val_loss: 0.2226\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0175 - val_loss: 0.2098\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.1954\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.1891\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0144 - val_loss: 0.1879\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0154 - val_loss: 0.1914\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0117 - val_loss: 0.1999\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2109\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0078 - val_loss: 0.2159\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0128 - val_loss: 0.2162\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0131 - val_loss: 0.2129\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0098 - val_loss: 0.2068\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.1985\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.1942\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - val_loss: 0.1934\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0097 - val_loss: 0.1955\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0076 - val_loss: 0.2001\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2068\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2101\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.2105\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0073 - val_loss: 0.2083\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2039\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9183e-04 - val_loss: 0.1975\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.1943\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0089 - val_loss: 0.1938\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0094 - val_loss: 0.1957\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0075 - val_loss: 0.1997\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2056\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.2086\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.2090\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.2071\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2032\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2930e-05 - val_loss: 0.1975\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - val_loss: 0.1946\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.1942\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0090 - val_loss: 0.1960\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - val_loss: 0.1998\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2053\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.2082\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.2086\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.2068\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.2031\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0336e-05 - val_loss: 0.2019\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3191e-04 - val_loss: 0.2059\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2066\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2050\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2016\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2006\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2017\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2048\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2055\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2041\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5023e-04 - val_loss: 0.2008\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.1999\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2011\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2050\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8868e-04 - val_loss: 0.2004\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1996\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2008\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5535e-04 - val_loss: 0.2047\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6397e-04 - val_loss: 0.2003\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1994\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2007\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2038\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1965e-04 - val_loss: 0.2046\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6418e-04 - val_loss: 0.2002\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.1994\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2006\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6592e-04 - val_loss: 0.2045\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3052e-04 - val_loss: 0.2002\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.1994\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2006\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5574e-04 - val_loss: 0.2045\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3186e-04 - val_loss: 0.2002\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.1994\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2007\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6857e-04 - val_loss: 0.2045\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5181e-04 - val_loss: 0.2003\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1995\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2007\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2038\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9366e-04 - val_loss: 0.2046\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8148e-04 - val_loss: 0.2003\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.1995\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2008\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2530e-04 - val_loss: 0.2046\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1632e-04 - val_loss: 0.2004\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.1996\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2008\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6023e-04 - val_loss: 0.2046\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5369e-04 - val_loss: 0.2004\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.1996\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2009\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9693e-04 - val_loss: 0.2047\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9238e-04 - val_loss: 0.2005\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1997\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.2009\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3439e-04 - val_loss: 0.2047\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3157e-04 - val_loss: 0.2005\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.1998\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2010\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7218e-04 - val_loss: 0.2047\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7096e-04 - val_loss: 0.2006\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1998\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2010\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2040\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1001e-04 - val_loss: 0.2048\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1030e-04 - val_loss: 0.2006\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.1999\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.2011\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2040\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.4783e-04 - val_loss: 0.2048\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4948e-04 - val_loss: 0.2007\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.1999\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2011\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2041\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.8547e-04 - val_loss: 0.2048\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8843e-04 - val_loss: 0.2007\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2012\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.2299e-04 - val_loss: 0.2049\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2723e-04 - val_loss: 0.2008\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2012\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.6029e-04 - val_loss: 0.2049\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6578e-04 - val_loss: 0.2008\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2001\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.2012\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9747e-04 - val_loss: 0.2049\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0420e-04 - val_loss: 0.2009\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2001\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2013\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2050\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4236e-04 - val_loss: 0.2009\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2002\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.2013\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2042\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8031e-04 - val_loss: 0.2010\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.2002\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2014\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2039\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.1810e-04 - val_loss: 0.2010\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2003\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2014\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2043\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2039\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.5574e-04 - val_loss: 0.2011\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2015\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2044\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2051\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 12:59:47,948] Trial 32 finished with value: 0.0007932782173156738 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1369 - val_loss: 0.2382\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.2453\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0392 - val_loss: 0.2350\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0239 - val_loss: 0.1936\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0215 - val_loss: 0.1823\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0284 - val_loss: 0.1961\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0110 - val_loss: 0.2223\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0168 - val_loss: 0.2309\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0251 - val_loss: 0.2275\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0213 - val_loss: 0.2154\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0087 - val_loss: 0.1997\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0082 - val_loss: 0.1934\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0139 - val_loss: 0.1957\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0117 - val_loss: 0.2041\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2193\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0106 - val_loss: 0.2262\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0162 - val_loss: 0.2246\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0155 - val_loss: 0.2164\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0096 - val_loss: 0.2062\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3133e-04 - val_loss: 0.1963\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0101 - val_loss: 0.1930\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0135 - val_loss: 0.1955\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0119 - val_loss: 0.2058\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2214\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0143 - val_loss: 0.2245\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0180 - val_loss: 0.2211\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0147 - val_loss: 0.2125\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0063 - val_loss: 0.1998\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.1942\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0112 - val_loss: 0.1935\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0115 - val_loss: 0.1961\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0089 - val_loss: 0.2012\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.2081\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2113\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.2114\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0061 - val_loss: 0.2089\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2034\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2015\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2026\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2064\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2049\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5408e-04 - val_loss: 0.2057\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8971e-04 - val_loss: 0.2038\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9132e-04 - val_loss: 0.2082\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.2087\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2065\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2003\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2016\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2054\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0209e-04 - val_loss: 0.2061\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2042\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1910e-04 - val_loss: 0.2051\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6325e-05 - val_loss: 0.2033\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4722e-04 - val_loss: 0.2077\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2082\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - val_loss: 0.2061\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2017\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2002\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2015\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2052\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5269e-04 - val_loss: 0.2059\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2041\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0894e-04 - val_loss: 0.2050\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.0050e-05 - val_loss: 0.2032\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.0202e-04 - val_loss: 0.2076\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2081\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2060\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2002\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.2015\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2051\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2368e-04 - val_loss: 0.2059\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1338e-04 - val_loss: 0.2049\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5374e-04 - val_loss: 0.2032\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0064e-04 - val_loss: 0.2075\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2080\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2060\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2003\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2015\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2051\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1910e-04 - val_loss: 0.2059\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0049e-04 - val_loss: 0.2049\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5451e-04 - val_loss: 0.2032\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8696e-04 - val_loss: 0.2075\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2080\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - val_loss: 0.2060\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2004\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.2016\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2407e-04 - val_loss: 0.2059\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2041\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7900e-04 - val_loss: 0.2050\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6485e-04 - val_loss: 0.2033\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6435e-04 - val_loss: 0.2075\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2080\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2060\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2005\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - val_loss: 0.2017\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2052\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.4084e-04 - val_loss: 0.2059\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4584e-04 - val_loss: 0.2050\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8786e-04 - val_loss: 0.2033\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2043\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2905e-04 - val_loss: 0.2075\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2080\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2060\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2006\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2018\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2052\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.7341e-04 - val_loss: 0.2059\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2042\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9702e-04 - val_loss: 0.2050\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2750e-04 - val_loss: 0.2034\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.8003e-04 - val_loss: 0.2043\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.7263e-05 - val_loss: 0.2075\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2080\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2061\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2007\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2019\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2053\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.2463e-04 - val_loss: 0.2060\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0115e-05 - val_loss: 0.2051\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8593e-04 - val_loss: 0.2035\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.0042e-04 - val_loss: 0.2044\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2939e-05 - val_loss: 0.2029\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6542e-04 - val_loss: 0.2070\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2076\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2057\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2005\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2017\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2051\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3435e-04 - val_loss: 0.2058\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3123e-05 - val_loss: 0.2050\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7683e-04 - val_loss: 0.2035\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.6903e-04 - val_loss: 0.2044\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3308e-04 - val_loss: 0.2029\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.8534e-04 - val_loss: 0.2070\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2076\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2058\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2018\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2006\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2018\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2052\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.7899e-04 - val_loss: 0.2059\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2043\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1671e-04 - val_loss: 0.2006\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.1995\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2008\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2042\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9242e-05 - val_loss: 0.2051\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.3871e-04 - val_loss: 0.2036\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6355e-04 - val_loss: 0.2045\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4241e-04 - val_loss: 0.2030\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3730e-04 - val_loss: 0.2071\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2077\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2059\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2021\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2021\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2054\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2061\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2045\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4866e-04 - val_loss: 0.2009\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.1998\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2011\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5842e-04 - val_loss: 0.2053\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8333e-04 - val_loss: 0.2048\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1348e-04 - val_loss: 0.2033\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9995e-04 - val_loss: 0.2043\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4948e-04 - val_loss: 0.2029\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2296e-04 - val_loss: 0.2070\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2076\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2059\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:00:06,220] Trial 33 finished with value: 0.002973109483718872 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1470 - val_loss: 0.3471\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1440 - val_loss: 0.3461\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1430 - val_loss: 0.3451\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1420 - val_loss: 0.3441\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1411 - val_loss: 0.3431\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1400 - val_loss: 0.3421\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1390 - val_loss: 0.3411\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1380 - val_loss: 0.3401\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1370 - val_loss: 0.3391\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1360 - val_loss: 0.3381\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1350 - val_loss: 0.3371\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1340 - val_loss: 0.3361\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1330 - val_loss: 0.3351\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1320 - val_loss: 0.3341\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1310 - val_loss: 0.3331\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1300 - val_loss: 0.3321\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1290 - val_loss: 0.3311\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1280 - val_loss: 0.3301\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1270 - val_loss: 0.3291\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1260 - val_loss: 0.3281\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1250 - val_loss: 0.3271\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1240 - val_loss: 0.3261\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1230 - val_loss: 0.3251\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1220 - val_loss: 0.3241\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1210 - val_loss: 0.3231\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1200 - val_loss: 0.3221\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1190 - val_loss: 0.3211\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1180 - val_loss: 0.3201\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1170 - val_loss: 0.3191\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1160 - val_loss: 0.3181\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1150 - val_loss: 0.3171\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1140 - val_loss: 0.3161\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1130 - val_loss: 0.3151\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1120 - val_loss: 0.3141\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1110 - val_loss: 0.3131\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1100 - val_loss: 0.3121\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1090 - val_loss: 0.3111\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1080 - val_loss: 0.3101\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1070 - val_loss: 0.3091\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1060 - val_loss: 0.3081\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1050 - val_loss: 0.3071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1040 - val_loss: 0.3061\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1030 - val_loss: 0.3051\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1020 - val_loss: 0.3041\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1010 - val_loss: 0.3031\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1000 - val_loss: 0.3021\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0990 - val_loss: 0.3011\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0980 - val_loss: 0.3001\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0970 - val_loss: 0.2991\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0960 - val_loss: 0.2981\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0950 - val_loss: 0.2971\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0940 - val_loss: 0.2961\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0930 - val_loss: 0.2951\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0920 - val_loss: 0.2941\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0910 - val_loss: 0.2931\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0900 - val_loss: 0.2921\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0890 - val_loss: 0.2911\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0880 - val_loss: 0.2901\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0870 - val_loss: 0.2891\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0860 - val_loss: 0.2881\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0850 - val_loss: 0.2871\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0840 - val_loss: 0.2861\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0830 - val_loss: 0.2851\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0820 - val_loss: 0.2841\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0810 - val_loss: 0.2831\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0800 - val_loss: 0.2821\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0790 - val_loss: 0.2811\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0780 - val_loss: 0.2801\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0770 - val_loss: 0.2791\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0760 - val_loss: 0.2781\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0750 - val_loss: 0.2771\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0740 - val_loss: 0.2761\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0730 - val_loss: 0.2751\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0720 - val_loss: 0.2741\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0710 - val_loss: 0.2731\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0700 - val_loss: 0.2721\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0690 - val_loss: 0.2711\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0680 - val_loss: 0.2701\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0670 - val_loss: 0.2691\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0660 - val_loss: 0.2681\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0650 - val_loss: 0.2671\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0640 - val_loss: 0.2661\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0630 - val_loss: 0.2651\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0620 - val_loss: 0.2641\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0610 - val_loss: 0.2631\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0600 - val_loss: 0.2621\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0590 - val_loss: 0.2611\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0580 - val_loss: 0.2601\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0570 - val_loss: 0.2591\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0560 - val_loss: 0.2581\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0550 - val_loss: 0.2571\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0540 - val_loss: 0.2561\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0530 - val_loss: 0.2551\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0520 - val_loss: 0.2541\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0510 - val_loss: 0.2531\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0500 - val_loss: 0.2521\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0490 - val_loss: 0.2511\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0480 - val_loss: 0.2501\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0470 - val_loss: 0.2491\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0460 - val_loss: 0.2481\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0450 - val_loss: 0.2471\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0440 - val_loss: 0.2461\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0430 - val_loss: 0.2451\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0420 - val_loss: 0.2441\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.2431\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0400 - val_loss: 0.2421\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0390 - val_loss: 0.2411\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0380 - val_loss: 0.2401\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0370 - val_loss: 0.2391\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0360 - val_loss: 0.2381\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0350 - val_loss: 0.2371\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0340 - val_loss: 0.2361\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0330 - val_loss: 0.2351\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0320 - val_loss: 0.2341\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0310 - val_loss: 0.2331\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0300 - val_loss: 0.2321\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0290 - val_loss: 0.2311\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0280 - val_loss: 0.2301\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0270 - val_loss: 0.2291\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0260 - val_loss: 0.2281\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0250 - val_loss: 0.2271\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0240 - val_loss: 0.2261\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0230 - val_loss: 0.2251\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0220 - val_loss: 0.2241\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0210 - val_loss: 0.2231\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0200 - val_loss: 0.2221\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0190 - val_loss: 0.2211\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0180 - val_loss: 0.2201\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0170 - val_loss: 0.2191\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.2181\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0150 - val_loss: 0.2171\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0140 - val_loss: 0.2161\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0130 - val_loss: 0.2151\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0120 - val_loss: 0.2141\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0110 - val_loss: 0.2131\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0100 - val_loss: 0.2121\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - val_loss: 0.2111\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0080 - val_loss: 0.2101\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.2091\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.2081\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.2071\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2061\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.6893e-04 - val_loss: 0.2031\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1069e-05 - val_loss: 0.2023\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3107e-04 - val_loss: 0.2017\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2007\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2007\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2011\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.4731e-04 - val_loss: 0.2027\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5568e-04 - val_loss: 0.2032\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6784e-05 - val_loss: 0.2036\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7500e-04 - val_loss: 0.2039\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.2441e-04 - val_loss: 0.2040\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4886e-04 - val_loss: 0.2040\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6087e-04 - val_loss: 0.2039\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7169e-04 - val_loss: 0.2037\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9141e-04 - val_loss: 0.2035\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.2917e-04 - val_loss: 0.2031\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8545e-06 - val_loss: 0.2029\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0927e-04 - val_loss: 0.2029\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9145e-04 - val_loss: 0.2029\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6540e-04 - val_loss: 0.2030\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4196e-04 - val_loss: 0.2032\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.9126e-05 - val_loss: 0.2033\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5911e-04 - val_loss: 0.2033\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4010e-04 - val_loss: 0.2032\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2992e-05 - val_loss: 0.2030\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8241e-04 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6727e-04 - val_loss: 0.2029\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4365e-04 - val_loss: 0.2030\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2238e-04 - val_loss: 0.2032\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6755e-05 - val_loss: 0.2033\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7498e-04 - val_loss: 0.2033\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5439e-04 - val_loss: 0.2032\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5852e-05 - val_loss: 0.2030\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7083e-04 - val_loss: 0.2029\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5685e-04 - val_loss: 0.2029\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3426e-04 - val_loss: 0.2030\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1393e-04 - val_loss: 0.2032\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.4354e-05 - val_loss: 0.2033\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8182e-04 - val_loss: 0.2033\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6055e-04 - val_loss: 0.2032\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1395e-05 - val_loss: 0.2030\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6585e-04 - val_loss: 0.2029\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5237e-04 - val_loss: 0.2029\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3022e-04 - val_loss: 0.2030\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1030e-04 - val_loss: 0.2032\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7632e-05 - val_loss: 0.2033\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8477e-04 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6320e-04 - val_loss: 0.2032\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.3780e-05 - val_loss: 0.2030\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:00:24,418] Trial 34 finished with value: 0.00016370415687561035 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1442 - val_loss: 0.3039\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0900 - val_loss: 0.2690\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0627 - val_loss: 0.2439\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0395 - val_loss: 0.2211\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - val_loss: 0.1990\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - val_loss: 0.1893\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0141 - val_loss: 0.1875\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0156 - val_loss: 0.1902\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0127 - val_loss: 0.1956\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0073 - val_loss: 0.2026\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7416e-04 - val_loss: 0.2106\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - val_loss: 0.2149\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0122 - val_loss: 0.2163\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0136 - val_loss: 0.2156\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0128 - val_loss: 0.2132\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0104 - val_loss: 0.2097\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0068 - val_loss: 0.2052\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.1999\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.1967\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0063 - val_loss: 0.1953\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0077 - val_loss: 0.1954\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0076 - val_loss: 0.1968\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.1993\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2026\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0539e-04 - val_loss: 0.2068\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2093\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.2104\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0073 - val_loss: 0.2103\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0072 - val_loss: 0.2091\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.2070\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.2040\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4967e-04 - val_loss: 0.2003\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1980\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.1970\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0061 - val_loss: 0.1973\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.1986\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.2008\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2038\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1841e-04 - val_loss: 0.2055\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2060\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2054\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2038\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8179e-04 - val_loss: 0.2014\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2002\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2002\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2012\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2032\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4779e-05 - val_loss: 0.2039\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5932e-04 - val_loss: 0.2035\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9673e-04 - val_loss: 0.2022\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.4424e-04 - val_loss: 0.2020\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8771e-04 - val_loss: 0.2046\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2052\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2047\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5634e-04 - val_loss: 0.2010\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.1999\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2011\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2030\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9929e-05 - val_loss: 0.2058\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2073\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.2076\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.2070\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2054\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5458e-04 - val_loss: 0.2018\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2027\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6349e-04 - val_loss: 0.2045\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2048\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1234e-04 - val_loss: 0.2012\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2002\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2004\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.2015\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2035\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3493e-04 - val_loss: 0.2042\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6074e-04 - val_loss: 0.2027\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7113e-04 - val_loss: 0.2026\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8898e-04 - val_loss: 0.2035\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9615e-04 - val_loss: 0.2033\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0388e-04 - val_loss: 0.2022\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5911e-04 - val_loss: 0.2021\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2030\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.0095e-05 - val_loss: 0.2049\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2055\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2052\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2038\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2560e-04 - val_loss: 0.2017\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2007\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - val_loss: 0.2008\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2019\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2039\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7185e-04 - val_loss: 0.2047\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8946e-05 - val_loss: 0.2011\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2002\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2004\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0044e-04 - val_loss: 0.2045\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2617e-05 - val_loss: 0.2030\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1742e-04 - val_loss: 0.2039\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9697e-04 - val_loss: 0.2038\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.4051e-04 - val_loss: 0.2026\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8058e-04 - val_loss: 0.2026\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0695e-04 - val_loss: 0.2036\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5182e-04 - val_loss: 0.2035\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3449e-04 - val_loss: 0.2024\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5194e-04 - val_loss: 0.2024\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.4658e-04 - val_loss: 0.2034\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4119e-04 - val_loss: 0.2033\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4952e-04 - val_loss: 0.2022\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.1398e-04 - val_loss: 0.2022\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.8774e-04 - val_loss: 0.2032\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1887e-04 - val_loss: 0.2032\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4107e-05 - val_loss: 0.2021\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2022\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.6422e-04 - val_loss: 0.2032\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4568e-05 - val_loss: 0.2031\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0599e-06 - val_loss: 0.2040\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1229e-04 - val_loss: 0.2039\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6513e-04 - val_loss: 0.2028\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4474e-04 - val_loss: 0.2028\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6393e-04 - val_loss: 0.2037\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9867e-04 - val_loss: 0.2036\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8752e-04 - val_loss: 0.2025\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9092e-04 - val_loss: 0.2025\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8088e-04 - val_loss: 0.2035\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0863e-04 - val_loss: 0.2034\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2108e-04 - val_loss: 0.2024\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.3649e-04 - val_loss: 0.2024\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.0725e-04 - val_loss: 0.2034\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9978e-04 - val_loss: 0.2033\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2772e-04 - val_loss: 0.2023\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1594e-04 - val_loss: 0.2023\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7412e-04 - val_loss: 0.2034\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4427e-04 - val_loss: 0.2033\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8239e-04 - val_loss: 0.2023\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5199e-04 - val_loss: 0.2023\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0195e-04 - val_loss: 0.2033\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2373e-04 - val_loss: 0.2033\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6853e-04 - val_loss: 0.2023\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5956e-04 - val_loss: 0.2023\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.0410e-04 - val_loss: 0.2033\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2610e-04 - val_loss: 0.2033\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7533e-04 - val_loss: 0.2023\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.4846e-04 - val_loss: 0.2023\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.8948e-04 - val_loss: 0.2034\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4350e-04 - val_loss: 0.2033\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9567e-04 - val_loss: 0.2023\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2514e-04 - val_loss: 0.2024\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6382e-04 - val_loss: 0.2034\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7083e-04 - val_loss: 0.2033\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2486e-04 - val_loss: 0.2023\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9373e-04 - val_loss: 0.2024\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3090e-04 - val_loss: 0.2034\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0459e-04 - val_loss: 0.2034\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5991e-04 - val_loss: 0.2024\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.5710e-04 - val_loss: 0.2024\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9329e-04 - val_loss: 0.2035\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4259e-04 - val_loss: 0.2034\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9872e-04 - val_loss: 0.2024\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1703e-04 - val_loss: 0.2025\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5260e-04 - val_loss: 0.2035\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8333e-04 - val_loss: 0.2035\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4001e-04 - val_loss: 0.2024\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7471e-04 - val_loss: 0.2025\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0992e-04 - val_loss: 0.2035\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2586e-04 - val_loss: 0.2035\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8292e-04 - val_loss: 0.2025\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3097e-04 - val_loss: 0.2026\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6595e-04 - val_loss: 0.2036\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6949e-04 - val_loss: 0.2035\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2683e-04 - val_loss: 0.2025\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8629e-04 - val_loss: 0.2026\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2109e-04 - val_loss: 0.2036\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1393e-04 - val_loss: 0.2036\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7138e-04 - val_loss: 0.2026\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4103e-04 - val_loss: 0.2026\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7578e-04 - val_loss: 0.2037\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5881e-04 - val_loss: 0.2036\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1637e-04 - val_loss: 0.2026\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9540e-04 - val_loss: 0.2027\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3006e-04 - val_loss: 0.2037\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.0394e-04 - val_loss: 0.2037\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6164e-04 - val_loss: 0.2027\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4951e-04 - val_loss: 0.2027\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.8417e-04 - val_loss: 0.2038\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4929e-04 - val_loss: 0.2037\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0700e-04 - val_loss: 0.2027\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0349e-04 - val_loss: 0.2028\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3815e-04 - val_loss: 0.2038\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:00:41,724] Trial 35 finished with value: 0.0006947219371795654 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1521 - val_loss: 0.3602\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1650 - val_loss: 0.3324\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1267 - val_loss: 0.3098\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1081 - val_loss: 0.3006\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0966 - val_loss: 0.2869\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0836 - val_loss: 0.2741\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0712 - val_loss: 0.2578\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0547 - val_loss: 0.2446\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0419 - val_loss: 0.2331\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - val_loss: 0.2177\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0148 - val_loss: 0.1997\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.1895\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0129 - val_loss: 0.1825\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0193 - val_loss: 0.1863\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0160 - val_loss: 0.1901\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0122 - val_loss: 0.1963\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0061 - val_loss: 0.2045\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2087\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.2097\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0072 - val_loss: 0.2080\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.2040\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.1981\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.1952\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0076 - val_loss: 0.1950\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0079 - val_loss: 0.1971\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2012\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2069\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2099\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0070 - val_loss: 0.2104\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0075 - val_loss: 0.2088\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0059 - val_loss: 0.2053\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2001\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.1975\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.1973\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.1990\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2026\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0738e-04 - val_loss: 0.2078\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.2105\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0075 - val_loss: 0.2109\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0079 - val_loss: 0.2094\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.2060\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2011\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.1987\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.1984\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2034\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.7022e-04 - val_loss: 0.2046\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5169e-04 - val_loss: 0.2010\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2005\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2020\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2061\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2024\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.0632e-04 - val_loss: 0.2017\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0133e-05 - val_loss: 0.2061\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - val_loss: 0.2070\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - val_loss: 0.2059\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.2031\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.1544e-05 - val_loss: 0.1988\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0043 - val_loss: 0.1967\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0064 - val_loss: 0.1967\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0064 - val_loss: 0.1985\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0046 - val_loss: 0.2020\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2070\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - val_loss: 0.2096\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0065 - val_loss: 0.2101\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0071 - val_loss: 0.2088\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - val_loss: 0.2058\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.2013\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.1991\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 0.1989\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2006\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2038\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.6440e-04 - val_loss: 0.2050\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2017\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2027\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7022e-04 - val_loss: 0.2057\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2067\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2058\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2032\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0671e-04 - val_loss: 0.1990\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.1971\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.1972\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.1990\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.2024\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3455e-04 - val_loss: 0.2073\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2099\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0068 - val_loss: 0.2104\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0074 - val_loss: 0.2092\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - val_loss: 0.2063\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2020\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.1999\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.1997\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2013\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2045\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2056\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2049\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2025\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6829e-04 - val_loss: 0.2021\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8239e-04 - val_loss: 0.2035\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9162e-04 - val_loss: 0.2030\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1590e-04 - val_loss: 0.2042\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8651e-04 - val_loss: 0.2014\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2011\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2026\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9855e-04 - val_loss: 0.2056\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2067\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2058\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2034\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1546e-04 - val_loss: 0.1994\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.1976\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.1977\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.1996\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2029\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2590e-04 - val_loss: 0.2077\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.2103\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0072 - val_loss: 0.2108\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0078 - val_loss: 0.2097\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.2069\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2027\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7505e-04 - val_loss: 0.2006\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2005\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2021\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.9972e-04 - val_loss: 0.2052\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2063\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2056\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2033\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2185e-04 - val_loss: 0.1995\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.1978\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - val_loss: 0.1979\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.1998\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2032\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0820e-04 - val_loss: 0.2045\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.5299e-04 - val_loss: 0.2019\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1822e-05 - val_loss: 0.2028\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6865e-04 - val_loss: 0.2042\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5592e-04 - val_loss: 0.2016\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2014\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1627e-04 - val_loss: 0.2060\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2071\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2063\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2040\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.3418e-04 - val_loss: 0.2002\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.1985\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.1987\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2005\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1226e-04 - val_loss: 0.2051\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2046\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2025\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1008e-04 - val_loss: 0.2022\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4597e-04 - val_loss: 0.2037\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1837e-04 - val_loss: 0.2033\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6189e-04 - val_loss: 0.2013\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2012\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2028\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8330e-04 - val_loss: 0.2059\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2070\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2063\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2040\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6312e-04 - val_loss: 0.2003\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.1987\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.1988\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.2007\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2040\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.0353e-04 - val_loss: 0.2053\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2048\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4310e-04 - val_loss: 0.2025\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5976e-04 - val_loss: 0.2040\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.0612e-04 - val_loss: 0.2036\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6686e-04 - val_loss: 0.2017\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2016\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0499e-05 - val_loss: 0.2029\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8963e-04 - val_loss: 0.2043\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7535e-04 - val_loss: 0.2020\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0327e-04 - val_loss: 0.2031\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5435e-05 - val_loss: 0.2012\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2012\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2028\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9705e-04 - val_loss: 0.2059\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2070\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.2064\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2042\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:00:58,452] Trial 36 finished with value: 0.0025077909231185913 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1440 - val_loss: 0.3132\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1062 - val_loss: 0.2829\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0779 - val_loss: 0.2514\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0492 - val_loss: 0.2293\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0250 - val_loss: 0.2119\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0066 - val_loss: 0.1947\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0105 - val_loss: 0.1880\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - val_loss: 0.1866\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0165 - val_loss: 0.1880\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0152 - val_loss: 0.1923\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0110 - val_loss: 0.1978\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0065 - val_loss: 0.2041\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.9461e-04 - val_loss: 0.2116\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.2155\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0114 - val_loss: 0.2167\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0126 - val_loss: 0.2156\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0116 - val_loss: 0.2128\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0089 - val_loss: 0.2086\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2032\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9041e-04 - val_loss: 0.2003\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.1993\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2001\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2023\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2057\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2073\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2073\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2059\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2033\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1091e-04 - val_loss: 0.2023\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4650e-04 - val_loss: 0.2046\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9523e-04 - val_loss: 0.2015\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2008\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2014\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.5103e-05 - val_loss: 0.2038\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8135e-04 - val_loss: 0.2028\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5051e-04 - val_loss: 0.2033\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6898e-05 - val_loss: 0.2024\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.6212e-04 - val_loss: 0.2029\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5396e-04 - val_loss: 0.2047\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2050\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2039\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.5088e-04 - val_loss: 0.2017\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2010\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2017\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7949e-04 - val_loss: 0.2040\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.8621e-04 - val_loss: 0.2030\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1750e-04 - val_loss: 0.2035\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4003e-04 - val_loss: 0.2026\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1655e-04 - val_loss: 0.2031\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1806e-04 - val_loss: 0.2049\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6710e-04 - val_loss: 0.2020\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2019\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0995e-04 - val_loss: 0.2042\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.1185e-04 - val_loss: 0.2033\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9252e-05 - val_loss: 0.2012\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2006\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2013\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2033\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3048e-06 - val_loss: 0.2037\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7161e-04 - val_loss: 0.2029\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5974e-04 - val_loss: 0.2034\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4460e-04 - val_loss: 0.2026\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5261e-04 - val_loss: 0.2031\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1754e-04 - val_loss: 0.2049\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2052\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.5955e-04 - val_loss: 0.2021\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2021\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.0593e-04 - val_loss: 0.2044\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.5533e-04 - val_loss: 0.2015\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2009\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2016\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9501e-04 - val_loss: 0.2040\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6714e-04 - val_loss: 0.2032\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.8071e-05 - val_loss: 0.2037\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.5998e-04 - val_loss: 0.2029\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2334e-04 - val_loss: 0.2035\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1383e-04 - val_loss: 0.2027\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4362e-04 - val_loss: 0.2033\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7107e-05 - val_loss: 0.2025\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1934e-04 - val_loss: 0.2031\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3956e-04 - val_loss: 0.2049\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2052\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2043\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2022\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2016\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2023\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.4958e-04 - val_loss: 0.2042\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.0756e-04 - val_loss: 0.2046\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0035e-04 - val_loss: 0.2018\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9864e-04 - val_loss: 0.2043\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7922e-04 - val_loss: 0.2016\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2010\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2018\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0439e-04 - val_loss: 0.2043\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2035\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3200e-04 - val_loss: 0.2015\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2010\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2018\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2418e-04 - val_loss: 0.2043\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2035\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7706e-04 - val_loss: 0.2016\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2011\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.0439e-04 - val_loss: 0.2044\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7096e-04 - val_loss: 0.2017\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2020\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1655e-04 - val_loss: 0.2045\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9065e-04 - val_loss: 0.2018\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2014\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.4540e-04 - val_loss: 0.2046\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.2372e-04 - val_loss: 0.2020\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2015\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5315e-04 - val_loss: 0.2042\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.8287e-04 - val_loss: 0.2048\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2040\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6367e-04 - val_loss: 0.2021\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2024\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.0684e-04 - val_loss: 0.2044\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0708e-04 - val_loss: 0.2023\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7463e-04 - val_loss: 0.2018\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.5826e-04 - val_loss: 0.2045\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2050\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.2462e-04 - val_loss: 0.2019\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0874e-04 - val_loss: 0.2047\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2026\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.7419e-04 - val_loss: 0.2021\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5894e-04 - val_loss: 0.2048\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2053\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2046\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2381e-04 - val_loss: 0.2022\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9590e-04 - val_loss: 0.2030\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0936e-04 - val_loss: 0.2049\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2055\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2047\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2029\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7377e-04 - val_loss: 0.2024\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.4469e-04 - val_loss: 0.2032\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0111e-05 - val_loss: 0.2051\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2056\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2049\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2422e-04 - val_loss: 0.2025\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.9393e-04 - val_loss: 0.2033\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.8617e-05 - val_loss: 0.2028\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.1012e-04 - val_loss: 0.2036\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4434e-04 - val_loss: 0.2031\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7785e-04 - val_loss: 0.2038\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.5391e-04 - val_loss: 0.2033\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2711e-05 - val_loss: 0.2016\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2012\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2022\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2042\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.6260e-04 - val_loss: 0.2048\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.6415e-04 - val_loss: 0.2024\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9875e-04 - val_loss: 0.2021\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2029\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2987e-04 - val_loss: 0.2049\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2054\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:01:15,199] Trial 37 finished with value: 0.002209097146987915 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1369 - val_loss: 0.2671\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0454 - val_loss: 0.1552\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0737 - val_loss: 0.1685\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0435 - val_loss: 0.1815\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0243 - val_loss: 0.2007\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - val_loss: 0.2265\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0214 - val_loss: 0.2276\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0217 - val_loss: 0.2178\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0116 - val_loss: 0.2119\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - val_loss: 0.1979\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0093 - val_loss: 0.1976\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0093 - val_loss: 0.1983\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0070 - val_loss: 0.2025\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2098\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.2126\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0077 - val_loss: 0.2118\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.2079\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2014\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.1988\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0058 - val_loss: 0.1995\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.2030\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2090\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.2115\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0070 - val_loss: 0.2109\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0065 - val_loss: 0.2077\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.2022\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2006\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2039\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.4237e-04 - val_loss: 0.2093\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2116\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.2112\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.2083\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2031\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2011\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2017\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2048\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7514e-04 - val_loss: 0.2050\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6099e-04 - val_loss: 0.2028\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.4884e-04 - val_loss: 0.2062\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2063\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2040\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0355e-04 - val_loss: 0.2044\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6603e-04 - val_loss: 0.2023\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2057\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2059\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5787e-04 - val_loss: 0.2041\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3376e-05 - val_loss: 0.2021\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2056\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2058\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9548e-04 - val_loss: 0.2041\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6463e-05 - val_loss: 0.2021\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2027\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2056\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2058\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2093e-04 - val_loss: 0.2041\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2106e-04 - val_loss: 0.2022\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2056\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2059\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2038\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.8796e-04 - val_loss: 0.2042\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.5852e-04 - val_loss: 0.2023\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2058\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2060\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2039\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4840e-05 - val_loss: 0.2044\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.2309e-04 - val_loss: 0.2025\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.9499e-04 - val_loss: 0.2059\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2062\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2041\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5344e-04 - val_loss: 0.1999\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.1984\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0055 - val_loss: 0.1995\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.2027\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2080\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2103\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.2102\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0063 - val_loss: 0.2078\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2034\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.3505e-04 - val_loss: 0.2017\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.2025\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2055\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2059\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4196e-04 - val_loss: 0.2000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.1987\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - val_loss: 0.1998\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2030\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5424e-04 - val_loss: 0.2082\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2106\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0068 - val_loss: 0.2105\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - val_loss: 0.2083\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - val_loss: 0.2040\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.6871e-04 - val_loss: 0.1979\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0058 - val_loss: 0.1947\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0090 - val_loss: 0.1940\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0096 - val_loss: 0.1957\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - val_loss: 0.1995\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2050\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2078\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2081\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2062\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2024\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2011\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2021\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2052\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2042\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9184e-04 - val_loss: 0.2006\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.1995\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2007\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2039\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4949e-04 - val_loss: 0.2047\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4991e-04 - val_loss: 0.2040\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7863e-04 - val_loss: 0.2026\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.1140e-04 - val_loss: 0.2035\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4676e-05 - val_loss: 0.2064\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2069\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - val_loss: 0.2053\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2016\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2005\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2016\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2048\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2055\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6708e-04 - val_loss: 0.2005\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.1995\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2007\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2040\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0153e-04 - val_loss: 0.2048\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2034\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3579e-05 - val_loss: 0.2043\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6571e-04 - val_loss: 0.2029\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7119e-04 - val_loss: 0.2038\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3820e-04 - val_loss: 0.2025\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5363e-04 - val_loss: 0.2035\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6359e-06 - val_loss: 0.2064\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2070\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2054\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2019\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2019\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2051\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - val_loss: 0.2043\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.8133e-04 - val_loss: 0.2009\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2012\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2045\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9948e-04 - val_loss: 0.2053\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3882e-04 - val_loss: 0.2006\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.1997\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2010\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2042\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9046e-04 - val_loss: 0.2051\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1632e-04 - val_loss: 0.2005\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.1996\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2009\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2042\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9022e-04 - val_loss: 0.2051\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6216e-04 - val_loss: 0.2005\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.1997\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2010\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2053\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8368e-04 - val_loss: 0.2008\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.1999\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2013\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2047\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2056\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2043\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.6567e-04 - val_loss: 0.2011\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2002\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2016\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2049\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2046\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2005\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2019\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2061\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:01:31,299] Trial 38 finished with value: 0.0011739879846572876 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1524 - val_loss: 0.3471\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1440 - val_loss: 0.3461\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1430 - val_loss: 0.3451\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1420 - val_loss: 0.3441\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1410 - val_loss: 0.3431\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1400 - val_loss: 0.3421\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1390 - val_loss: 0.3411\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1380 - val_loss: 0.3401\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1370 - val_loss: 0.3391\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1360 - val_loss: 0.3381\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1350 - val_loss: 0.3371\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1340 - val_loss: 0.3361\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1330 - val_loss: 0.3351\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1320 - val_loss: 0.3341\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1310 - val_loss: 0.3331\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1300 - val_loss: 0.3321\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1290 - val_loss: 0.3311\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1280 - val_loss: 0.3301\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1270 - val_loss: 0.3291\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1260 - val_loss: 0.3281\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1250 - val_loss: 0.3271\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1240 - val_loss: 0.3261\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1230 - val_loss: 0.3251\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1220 - val_loss: 0.3241\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1210 - val_loss: 0.3231\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1200 - val_loss: 0.3221\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1190 - val_loss: 0.3211\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1180 - val_loss: 0.3201\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1170 - val_loss: 0.3191\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1160 - val_loss: 0.3181\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1150 - val_loss: 0.3171\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1140 - val_loss: 0.3161\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1130 - val_loss: 0.3151\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1120 - val_loss: 0.3141\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1110 - val_loss: 0.3131\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1100 - val_loss: 0.3121\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1090 - val_loss: 0.3111\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1080 - val_loss: 0.3101\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1070 - val_loss: 0.3091\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1060 - val_loss: 0.3081\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1050 - val_loss: 0.3071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1040 - val_loss: 0.3061\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1030 - val_loss: 0.3051\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1020 - val_loss: 0.3041\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1010 - val_loss: 0.3031\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1000 - val_loss: 0.3021\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0990 - val_loss: 0.3011\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0980 - val_loss: 0.3001\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0970 - val_loss: 0.2991\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0960 - val_loss: 0.2981\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0950 - val_loss: 0.2971\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0940 - val_loss: 0.2961\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0930 - val_loss: 0.2951\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0920 - val_loss: 0.2941\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0910 - val_loss: 0.2931\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0900 - val_loss: 0.2921\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0890 - val_loss: 0.2911\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0880 - val_loss: 0.2901\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0870 - val_loss: 0.2891\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0860 - val_loss: 0.2881\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0850 - val_loss: 0.2871\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0840 - val_loss: 0.2861\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0830 - val_loss: 0.2851\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0820 - val_loss: 0.2841\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0810 - val_loss: 0.2831\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0800 - val_loss: 0.2821\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0790 - val_loss: 0.2811\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0780 - val_loss: 0.2801\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0770 - val_loss: 0.2791\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0760 - val_loss: 0.2781\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0750 - val_loss: 0.2771\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0740 - val_loss: 0.2761\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0730 - val_loss: 0.2751\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0720 - val_loss: 0.2741\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0710 - val_loss: 0.2731\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0700 - val_loss: 0.2721\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0690 - val_loss: 0.2711\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0680 - val_loss: 0.2701\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0670 - val_loss: 0.2691\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0660 - val_loss: 0.2681\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0650 - val_loss: 0.2671\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0640 - val_loss: 0.2661\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0630 - val_loss: 0.2651\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0620 - val_loss: 0.2641\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0610 - val_loss: 0.2631\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0600 - val_loss: 0.2621\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0590 - val_loss: 0.2611\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0580 - val_loss: 0.2601\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0570 - val_loss: 0.2591\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0560 - val_loss: 0.2581\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0550 - val_loss: 0.2571\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0540 - val_loss: 0.2561\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0530 - val_loss: 0.2551\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0520 - val_loss: 0.2541\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0510 - val_loss: 0.2531\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0500 - val_loss: 0.2521\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0490 - val_loss: 0.2511\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0480 - val_loss: 0.2501\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0470 - val_loss: 0.2491\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0460 - val_loss: 0.2481\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0450 - val_loss: 0.2471\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0440 - val_loss: 0.2461\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0430 - val_loss: 0.2451\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0420 - val_loss: 0.2441\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0410 - val_loss: 0.2431\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0400 - val_loss: 0.2421\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0390 - val_loss: 0.2411\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0380 - val_loss: 0.2401\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0370 - val_loss: 0.2391\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0360 - val_loss: 0.2381\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0350 - val_loss: 0.2371\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0340 - val_loss: 0.2361\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0330 - val_loss: 0.2351\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0320 - val_loss: 0.2341\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0310 - val_loss: 0.2331\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0300 - val_loss: 0.2321\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0290 - val_loss: 0.2311\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0280 - val_loss: 0.2301\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0270 - val_loss: 0.2291\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0260 - val_loss: 0.2281\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0250 - val_loss: 0.2271\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0240 - val_loss: 0.2261\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0230 - val_loss: 0.2251\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0220 - val_loss: 0.2241\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0210 - val_loss: 0.2231\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0200 - val_loss: 0.2221\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0190 - val_loss: 0.2211\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0180 - val_loss: 0.2201\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0170 - val_loss: 0.2191\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0160 - val_loss: 0.2181\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0150 - val_loss: 0.2171\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0140 - val_loss: 0.2161\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0130 - val_loss: 0.2151\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0120 - val_loss: 0.2141\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0110 - val_loss: 0.2131\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0100 - val_loss: 0.2121\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0090 - val_loss: 0.2111\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0080 - val_loss: 0.2101\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - val_loss: 0.2091\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0060 - val_loss: 0.2081\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - val_loss: 0.2071\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2061\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6893e-04 - val_loss: 0.2031\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1069e-05 - val_loss: 0.2023\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.3107e-04 - val_loss: 0.2017\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - val_loss: 0.2007\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - val_loss: 0.2007\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2011\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4731e-04 - val_loss: 0.2027\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.5568e-04 - val_loss: 0.2032\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6784e-05 - val_loss: 0.2036\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7500e-04 - val_loss: 0.2039\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.2441e-04 - val_loss: 0.2040\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.4886e-04 - val_loss: 0.2040\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6087e-04 - val_loss: 0.2039\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.7169e-04 - val_loss: 0.2037\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9141e-04 - val_loss: 0.2035\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2917e-04 - val_loss: 0.2031\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.8545e-06 - val_loss: 0.2029\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.0927e-04 - val_loss: 0.2029\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.9145e-04 - val_loss: 0.2029\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6540e-04 - val_loss: 0.2030\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4196e-04 - val_loss: 0.2032\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9126e-05 - val_loss: 0.2033\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5911e-04 - val_loss: 0.2033\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4010e-04 - val_loss: 0.2032\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2992e-05 - val_loss: 0.2030\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8241e-04 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6727e-04 - val_loss: 0.2029\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4365e-04 - val_loss: 0.2030\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2238e-04 - val_loss: 0.2032\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6755e-05 - val_loss: 0.2033\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7498e-04 - val_loss: 0.2033\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.5439e-04 - val_loss: 0.2032\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.5852e-05 - val_loss: 0.2030\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7083e-04 - val_loss: 0.2029\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5685e-04 - val_loss: 0.2029\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3426e-04 - val_loss: 0.2030\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1393e-04 - val_loss: 0.2032\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4354e-05 - val_loss: 0.2033\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8182e-04 - val_loss: 0.2033\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6055e-04 - val_loss: 0.2032\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1395e-05 - val_loss: 0.2030\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6585e-04 - val_loss: 0.2029\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5237e-04 - val_loss: 0.2029\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3022e-04 - val_loss: 0.2030\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1030e-04 - val_loss: 0.2032\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.7632e-05 - val_loss: 0.2033\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8477e-04 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6320e-04 - val_loss: 0.2032\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3780e-05 - val_loss: 0.2030\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:01:48,528] Trial 39 finished with value: 0.00016370415687561035 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1784 - val_loss: 0.3652\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1681 - val_loss: 0.3667\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1638 - val_loss: 0.3606\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1572 - val_loss: 0.3531\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1495 - val_loss: 0.3391\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1359 - val_loss: 0.3264\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1235 - val_loss: 0.3224\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1186 - val_loss: 0.3173\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1135 - val_loss: 0.3113\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1073 - val_loss: 0.3050\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1011 - val_loss: 0.2972\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0932 - val_loss: 0.2931\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0906 - val_loss: 0.2904\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0877 - val_loss: 0.2864\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0838 - val_loss: 0.2814\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0788 - val_loss: 0.2764\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0736 - val_loss: 0.2715\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0689 - val_loss: 0.2664\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0637 - val_loss: 0.2609\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0581 - val_loss: 0.2553\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0523 - val_loss: 0.2494\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0464 - val_loss: 0.2432\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0402 - val_loss: 0.2368\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0338 - val_loss: 0.2306\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0274 - val_loss: 0.2239\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0205 - val_loss: 0.2166\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0134 - val_loss: 0.2090\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - val_loss: 0.2012\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.1955\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0078 - val_loss: 0.1920\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0113 - val_loss: 0.1902\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0130 - val_loss: 0.1900\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0133 - val_loss: 0.1908\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0125 - val_loss: 0.1927\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - val_loss: 0.1955\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0082 - val_loss: 0.2001\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - val_loss: 0.2055\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2079\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - val_loss: 0.2080\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0047 - val_loss: 0.2062\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.2031\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3694e-04 - val_loss: 0.2022\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.5937e-04 - val_loss: 0.2032\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0035e-07 - val_loss: 0.2047\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.2054\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2055\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2044\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.1590e-04 - val_loss: 0.2023\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6322e-04 - val_loss: 0.2024\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4966e-04 - val_loss: 0.2032\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3809e-05 - val_loss: 0.2032\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6668e-05 - val_loss: 0.2026\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0023e-04 - val_loss: 0.2026\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.1254e-04 - val_loss: 0.2034\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5088e-04 - val_loss: 0.2034\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.5418e-04 - val_loss: 0.2027\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2413e-04 - val_loss: 0.2028\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5246e-04 - val_loss: 0.2035\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.9177e-04 - val_loss: 0.2035\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.8289e-04 - val_loss: 0.2029\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0214e-04 - val_loss: 0.2029\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.4055e-04 - val_loss: 0.2036\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9110e-04 - val_loss: 0.2036\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7451e-04 - val_loss: 0.2029\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.1435e-04 - val_loss: 0.2030\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5925e-04 - val_loss: 0.2037\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.6401e-04 - val_loss: 0.2037\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.4249e-04 - val_loss: 0.2030\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4855e-04 - val_loss: 0.2031\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.7618e-05 - val_loss: 0.2038\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.1996e-04 - val_loss: 0.2038\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.9524e-04 - val_loss: 0.2031\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.6932e-05 - val_loss: 0.2031\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.8712e-05 - val_loss: 0.2038\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6495e-04 - val_loss: 0.2038\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3822e-04 - val_loss: 0.2031\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.4494e-05 - val_loss: 0.2031\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.0466e-06 - val_loss: 0.2039\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.0286e-04 - val_loss: 0.2038\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7481e-04 - val_loss: 0.2031\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8060e-05 - val_loss: 0.2032\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.7224e-05 - val_loss: 0.2026\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0150e-04 - val_loss: 0.2027\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.9670e-04 - val_loss: 0.2034\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.6719e-04 - val_loss: 0.2034\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.8634e-04 - val_loss: 0.2028\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6433e-04 - val_loss: 0.2029\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.8083e-04 - val_loss: 0.2036\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.6261e-04 - val_loss: 0.2036\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.6463e-04 - val_loss: 0.2030\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.0032e-04 - val_loss: 0.2030\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3076e-04 - val_loss: 0.2038\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9916e-04 - val_loss: 0.2037\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.8997e-04 - val_loss: 0.2031\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.4206e-05 - val_loss: 0.2031\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.3842e-05 - val_loss: 0.2039\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.9715e-04 - val_loss: 0.2038\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.8066e-04 - val_loss: 0.2032\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6194e-07 - val_loss: 0.2019\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 0.2014\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0018 - val_loss: 0.2016\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - val_loss: 0.2025\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.4436e-04 - val_loss: 0.2040\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.1654e-04 - val_loss: 0.2046\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2045\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.5260e-04 - val_loss: 0.2025\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.7410e-04 - val_loss: 0.2020\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2021\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2030\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.6256e-04 - val_loss: 0.2044\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2050\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.2042\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - val_loss: 0.2028\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.2932e-04 - val_loss: 0.2023\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.7519e-04 - val_loss: 0.2025\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9830e-04 - val_loss: 0.2033\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2769e-04 - val_loss: 0.2034\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.0538e-04 - val_loss: 0.2028\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.8956e-04 - val_loss: 0.2029\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.5894e-04 - val_loss: 0.2037\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.2369e-04 - val_loss: 0.2037\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6414e-04 - val_loss: 0.2031\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.2898e-05 - val_loss: 0.2032\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.7417e-05 - val_loss: 0.2026\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3747e-04 - val_loss: 0.2028\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8855e-04 - val_loss: 0.2036\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1072e-04 - val_loss: 0.2036\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6597e-04 - val_loss: 0.2030\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4788e-04 - val_loss: 0.2031\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.5539e-05 - val_loss: 0.2039\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.2955e-04 - val_loss: 0.2039\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.5528e-04 - val_loss: 0.2033\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1593e-04 - val_loss: 0.2020\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.0892e-04 - val_loss: 0.2042\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2048\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2041\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.5887e-04 - val_loss: 0.2028\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.4706e-04 - val_loss: 0.2023\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5922e-04 - val_loss: 0.2025\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5327e-04 - val_loss: 0.2034\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9749e-04 - val_loss: 0.2035\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.9887e-04 - val_loss: 0.2029\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.7333e-04 - val_loss: 0.2030\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2375e-04 - val_loss: 0.2038\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.7440e-04 - val_loss: 0.2039\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3037e-04 - val_loss: 0.2033\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1890e-04 - val_loss: 0.2021\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2019\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2151e-04 - val_loss: 0.2043\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2050\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2050\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.9370e-04 - val_loss: 0.2025\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9539e-04 - val_loss: 0.2027\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8138e-04 - val_loss: 0.2035\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7523e-04 - val_loss: 0.2036\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.8326e-04 - val_loss: 0.2031\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.1569e-05 - val_loss: 0.2032\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.3254e-05 - val_loss: 0.2027\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.5075e-04 - val_loss: 0.2029\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.5795e-04 - val_loss: 0.2037\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7863e-04 - val_loss: 0.2038\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6957e-04 - val_loss: 0.2032\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.0227e-05 - val_loss: 0.2021\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2017\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.5250e-04 - val_loss: 0.2044\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2051\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8369e-05 - val_loss: 0.2026\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.3819e-04 - val_loss: 0.2028\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1473e-04 - val_loss: 0.2037\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.4900e-04 - val_loss: 0.2038\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6479e-04 - val_loss: 0.2033\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0832e-04 - val_loss: 0.2021\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2017\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.6516e-04 - val_loss: 0.2045\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2052\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2045\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.3073e-05 - val_loss: 0.2014\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.2003\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2008\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:02:04,596] Trial 40 finished with value: 0.002384498715400696 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1466 - val_loss: 0.3180\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1101 - val_loss: 0.2691\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0593 - val_loss: 0.2338\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0283 - val_loss: 0.2021\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.1939\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0072 - val_loss: 0.1966\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2042\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2054\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2021\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0098e-04 - val_loss: 0.1956\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - val_loss: 0.1938\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0078 - val_loss: 0.1956\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - val_loss: 0.2002\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2070\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2101\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0079 - val_loss: 0.2101\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0078 - val_loss: 0.2076\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.2030\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.0283e-04 - val_loss: 0.1966\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.1933\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0089 - val_loss: 0.1927\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0096 - val_loss: 0.1944\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.1979\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2032\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6763e-04 - val_loss: 0.2057\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2061\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2044\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2010\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.1998\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2007\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1707e-04 - val_loss: 0.2039\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5606e-04 - val_loss: 0.2031\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.3465e-04 - val_loss: 0.2019\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.5235e-04 - val_loss: 0.2025\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9602e-04 - val_loss: 0.2049\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.2053\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.2038\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - val_loss: 0.2007\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - val_loss: 0.1997\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2006\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2032\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1555e-04 - val_loss: 0.2037\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.4979e-04 - val_loss: 0.2025\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2297e-04 - val_loss: 0.2031\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8490e-04 - val_loss: 0.2019\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.1653e-04 - val_loss: 0.2026\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4936e-04 - val_loss: 0.2049\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2053\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2039\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2009\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.1999\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.2008\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - val_loss: 0.2033\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.0248e-04 - val_loss: 0.2039\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.9725e-04 - val_loss: 0.2032\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1237e-04 - val_loss: 0.2021\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6076e-04 - val_loss: 0.2027\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.3713e-05 - val_loss: 0.2051\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - val_loss: 0.2054\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - val_loss: 0.2041\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2011\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2002\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - val_loss: 0.2010\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.9267e-04 - val_loss: 0.2041\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.2029\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.4373e-06 - val_loss: 0.2000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.1992\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - val_loss: 0.2002\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - val_loss: 0.2028\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.9800e-05 - val_loss: 0.2068\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0040 - val_loss: 0.2088\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0059 - val_loss: 0.2088\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - val_loss: 0.2072\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - val_loss: 0.2040\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - val_loss: 0.1994\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - val_loss: 0.1970\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0058 - val_loss: 0.1966\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0063 - val_loss: 0.1979\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2008\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - val_loss: 0.2050\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2072\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - val_loss: 0.2075\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - val_loss: 0.2060\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 0.2030\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5211e-04 - val_loss: 0.1987\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - val_loss: 0.1964\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0064 - val_loss: 0.1961\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0068 - val_loss: 0.1975\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - val_loss: 0.2005\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2048\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2070\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - val_loss: 0.2073\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0044 - val_loss: 0.2060\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - val_loss: 0.2031\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.0918e-04 - val_loss: 0.1989\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.1967\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.1965\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0065 - val_loss: 0.1979\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0050 - val_loss: 0.2008\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - val_loss: 0.2051\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - val_loss: 0.2073\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.2077\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - val_loss: 0.2064\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - val_loss: 0.2036\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.2245e-04 - val_loss: 0.1994\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - val_loss: 0.1973\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0057 - val_loss: 0.1970\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0059 - val_loss: 0.1985\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - val_loss: 0.2014\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2056\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - val_loss: 0.2078\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0049 - val_loss: 0.2082\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0052 - val_loss: 0.2069\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - val_loss: 0.2041\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 0.1979\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0050 - val_loss: 0.1977\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0053 - val_loss: 0.1991\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.2020\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.8583e-04 - val_loss: 0.2062\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2084\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - val_loss: 0.2087\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0057 - val_loss: 0.2074\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - val_loss: 0.2047\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2006\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.1986\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.1983\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - val_loss: 0.1997\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - val_loss: 0.2026\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7962e-04 - val_loss: 0.2068\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.2089\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0059 - val_loss: 0.2093\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0063 - val_loss: 0.2080\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2053\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2013\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.1992\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - val_loss: 0.1990\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0040 - val_loss: 0.2004\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2032\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.2824e-04 - val_loss: 0.2042\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2035\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.7699e-04 - val_loss: 0.2013\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2021\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.4832e-04 - val_loss: 0.2047\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2055\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2047\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.0764e-04 - val_loss: 0.2019\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6508e-06 - val_loss: 0.2056\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2063\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - val_loss: 0.2054\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - val_loss: 0.2031\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.3255e-05 - val_loss: 0.1994\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - val_loss: 0.1976\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.1976\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - val_loss: 0.1992\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.2022\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.1789e-04 - val_loss: 0.2064\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - val_loss: 0.2087\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - val_loss: 0.2092\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0062 - val_loss: 0.2081\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - val_loss: 0.2055\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - val_loss: 0.2017\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.1998\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 0.1996\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - val_loss: 0.2011\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2039\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.9562e-04 - val_loss: 0.2049\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2043\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.7425e-04 - val_loss: 0.2018\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4946e-05 - val_loss: 0.2057\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - val_loss: 0.2065\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - val_loss: 0.2057\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - val_loss: 0.2035\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.3973e-04 - val_loss: 0.1999\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - val_loss: 0.1982\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - val_loss: 0.1983\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - val_loss: 0.1999\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - val_loss: 0.2029\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2830e-04 - val_loss: 0.2071\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - val_loss: 0.2094\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0064 - val_loss: 0.2099\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069 - val_loss: 0.2088\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0058 - val_loss: 0.2064\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - val_loss: 0.2026\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.1705e-04 - val_loss: 0.2008\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - val_loss: 0.2006\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - val_loss: 0.2021\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.6852e-04 - val_loss: 0.2049\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2059\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - val_loss: 0.2053\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:02:20,790] Trial 41 finished with value: 0.00014099478721618652 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1380 - val_loss: 0.2799\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0527 - val_loss: 0.2075\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.1988\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.2130\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0109 - val_loss: 0.2143\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0115 - val_loss: 0.2074\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1960\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0073 - val_loss: 0.1921\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0113 - val_loss: 0.1932\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0101 - val_loss: 0.1981\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.2056\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2086\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.2080\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2045\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.6636e-04 - val_loss: 0.1988\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.1965\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - val_loss: 0.1970\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0065 - val_loss: 0.1999\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.2047\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2067\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.2062\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2036\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1131e-04 - val_loss: 0.1992\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.1974\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.1979\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.2003\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2044\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5318e-04 - val_loss: 0.2061\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2057\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2035\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7265e-05 - val_loss: 0.1996\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.1980\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0054 - val_loss: 0.1984\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - val_loss: 0.2007\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2045\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2061\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2058\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2037\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0820e-04 - val_loss: 0.2000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.1985\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.1989\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2011\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2048\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2063\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2060\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2040\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8341e-04 - val_loss: 0.2005\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.1990\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.1995\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2016\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2052\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2067\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2064\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2044\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2010\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.1995\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - val_loss: 0.2000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2020\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2056\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2071\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2068\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2049\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2015\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2001\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2005\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2025\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.3619e-04 - val_loss: 0.2060\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2075\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.2072\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - val_loss: 0.2053\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2020\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2006\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2010\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2030\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.2826e-04 - val_loss: 0.2065\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2079\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2076\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2058\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2025\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7750e-04 - val_loss: 0.2011\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2016\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2035\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.8138e-04 - val_loss: 0.2037\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5952e-04 - val_loss: 0.2023\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.8644e-04 - val_loss: 0.2026\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7790e-04 - val_loss: 0.2045\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1434e-04 - val_loss: 0.2033\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5079e-05 - val_loss: 0.2019\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2023\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2042\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.1919e-04 - val_loss: 0.2043\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.1801e-04 - val_loss: 0.2031\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4623e-04 - val_loss: 0.2050\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2050\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.2866e-04 - val_loss: 0.2005\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - val_loss: 0.1994\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.2001\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2023\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2058\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2074\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - val_loss: 0.2073\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - val_loss: 0.2056\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2025\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7015e-04 - val_loss: 0.2013\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2018\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2038\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6955e-04 - val_loss: 0.2041\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.2505e-04 - val_loss: 0.2027\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1981e-04 - val_loss: 0.2031\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.5198e-04 - val_loss: 0.2050\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2052\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2037\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6133e-04 - val_loss: 0.2008\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - val_loss: 0.1998\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - val_loss: 0.2005\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2027\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.3179e-04 - val_loss: 0.2062\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - val_loss: 0.2077\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - val_loss: 0.2076\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.2060\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2031\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2848e-04 - val_loss: 0.2020\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.7076e-04 - val_loss: 0.2045\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 0.2047\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.1838e-04 - val_loss: 0.2007\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.1998\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2006\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.2028\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.1717e-04 - val_loss: 0.2062\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.2077\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - val_loss: 0.2063\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2023\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2515e-04 - val_loss: 0.2019\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.5904e-04 - val_loss: 0.2043\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6834e-04 - val_loss: 0.2010\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - val_loss: 0.2010\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2033\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.8968e-04 - val_loss: 0.2030\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5967e-05 - val_loss: 0.2007\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2007\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - val_loss: 0.2029\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.5222e-05 - val_loss: 0.2069\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.2084\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.2078\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - val_loss: 0.2054\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2014\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.1996\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.2000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.2021\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.6260e-04 - val_loss: 0.2059\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.2074\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - val_loss: 0.2070\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.2049\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2012\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.1997\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2001\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.7042e-04 - val_loss: 0.2058\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - val_loss: 0.2073\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.2070\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0038 - val_loss: 0.2050\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2015\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2001\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.2005\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - val_loss: 0.2025\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.8587e-04 - val_loss: 0.2060\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2075\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.2072\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.2053\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2005\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - val_loss: 0.2009\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2029\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.7624e-04 - val_loss: 0.2064\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2078\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - val_loss: 0.2075\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0043 - val_loss: 0.2056\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - val_loss: 0.2023\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5814e-04 - val_loss: 0.2010\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2014\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2034\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7390e-04 - val_loss: 0.2035\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.4443e-04 - val_loss: 0.2021\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.0258e-04 - val_loss: 0.2043\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2044\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.5605e-04 - val_loss: 0.2031\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2307e-04 - val_loss: 0.2049\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2049\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5832e-04 - val_loss: 0.2004\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:02:37,694] Trial 42 finished with value: 0.003913864493370056 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1454 - val_loss: 0.3089\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1049 - val_loss: 0.2787\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0750 - val_loss: 0.2479\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0440 - val_loss: 0.2211\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0198 - val_loss: 0.1992\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1915\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0114 - val_loss: 0.1916\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0116 - val_loss: 0.1979\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.2084\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.2110\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0071 - val_loss: 0.2083\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.2024\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2014\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2041\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2033\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0321e-04 - val_loss: 0.1997\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.1996\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2026\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6658e-04 - val_loss: 0.2026\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5326e-04 - val_loss: 0.2003\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1368e-04 - val_loss: 0.2027\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6810e-04 - val_loss: 0.2005\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2006\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6666e-05 - val_loss: 0.2025\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7231e-05 - val_loss: 0.2044\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.4068e-04 - val_loss: 0.2017\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.2535e-04 - val_loss: 0.2036\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1632e-04 - val_loss: 0.2033\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5252e-04 - val_loss: 0.2012\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2030\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3610e-04 - val_loss: 0.2028\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2626e-04 - val_loss: 0.2008\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2027\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6550e-05 - val_loss: 0.2061\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2074\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2068\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2044\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.1988\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.1990\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2010\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2045\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2059\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2054\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2033\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2528e-04 - val_loss: 0.1996\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.1980\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - val_loss: 0.1984\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - val_loss: 0.2004\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2039\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2053\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2049\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9668e-05 - val_loss: 0.2027\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8632e-04 - val_loss: 0.2043\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.8193e-04 - val_loss: 0.2020\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.4897e-04 - val_loss: 0.2036\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.8775e-04 - val_loss: 0.2034\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6565e-04 - val_loss: 0.2015\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4781e-04 - val_loss: 0.2030\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.3284e-05 - val_loss: 0.2012\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9206e-05 - val_loss: 0.2061\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - val_loss: 0.2073\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2068\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2046\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.1993\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.1996\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2015\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2048\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2062\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2057\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.2037\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1400e-04 - val_loss: 0.2002\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.1987\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.1990\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2009\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2044\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2058\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2054\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2034\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2804e-04 - val_loss: 0.2000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.1985\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.1989\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.2009\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2057\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2054\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2034\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1974e-04 - val_loss: 0.2000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.1986\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - val_loss: 0.1990\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2010\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2058\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2055\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2035\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3477e-04 - val_loss: 0.2002\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1988\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1992\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2011\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2045\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2060\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2056\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2037\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.0557e-04 - val_loss: 0.2004\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.1990\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.1994\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2013\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2047\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2058\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2039\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.0227e-04 - val_loss: 0.2006\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.1992\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.1996\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.2016\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2064\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2060\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2042\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2008\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.1995\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.1999\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2018\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - val_loss: 0.2052\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2066\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2063\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2044\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.1997\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2001\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2020\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2054\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2068\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - val_loss: 0.2065\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - val_loss: 0.2046\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.2000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.2003\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2023\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7988e-04 - val_loss: 0.2056\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - val_loss: 0.2070\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.2067\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - val_loss: 0.2048\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - val_loss: 0.2016\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - val_loss: 0.2002\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0028 - val_loss: 0.2006\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - val_loss: 0.2025\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.4596e-04 - val_loss: 0.2058\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2072\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - val_loss: 0.2069\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.2051\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - val_loss: 0.2018\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2005\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2008\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2028\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1148e-04 - val_loss: 0.2060\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.2074\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0044 - val_loss: 0.2071\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.2053\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2021\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2007\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - val_loss: 0.2011\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2030\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6741e-05 - val_loss: 0.2063\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - val_loss: 0.2077\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - val_loss: 0.2073\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2055\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2023\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.7848e-04 - val_loss: 0.2010\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2013\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5794e-04 - val_loss: 0.2034\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0288e-04 - val_loss: 0.2020\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2022\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.5226e-04 - val_loss: 0.2040\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.5573e-04 - val_loss: 0.2041\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7053e-04 - val_loss: 0.2028\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.5721e-04 - val_loss: 0.2046\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2046\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.6315e-05 - val_loss: 0.2032\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4642e-04 - val_loss: 0.2018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.5750e-04 - val_loss: 0.2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:02:55,692] Trial 43 finished with value: 0.0008670836687088013 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1479 - val_loss: 0.3797\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1880 - val_loss: 0.3192\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1147 - val_loss: 0.3086\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1027 - val_loss: 0.3014\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0977 - val_loss: 0.2916\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0869 - val_loss: 0.2845\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0784 - val_loss: 0.2725\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0664 - val_loss: 0.2582\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0536 - val_loss: 0.2476\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0431 - val_loss: 0.2362\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0321 - val_loss: 0.2241\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0236 - val_loss: 0.2130\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0117 - val_loss: 0.2101\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.2043\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1944e-04 - val_loss: 0.2105\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.2105\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.2055\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7013e-04 - val_loss: 0.1965\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0086 - val_loss: 0.1931\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0120 - val_loss: 0.1941\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 0.1992\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - val_loss: 0.2078\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.2114\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - val_loss: 0.2106\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - val_loss: 0.2060\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - val_loss: 0.1982\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0067 - val_loss: 0.1949\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - val_loss: 0.1955\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0095 - val_loss: 0.1994\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.2063\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2091\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.2081\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2041\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.4887e-04 - val_loss: 0.2037\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2065\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2058\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0010 - val_loss: 0.2021\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2019\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2047\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2797e-05 - val_loss: 0.2103\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0055 - val_loss: 0.2122\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0074 - val_loss: 0.2109\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.2069\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2004\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1974\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - val_loss: 0.1977\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0069 - val_loss: 0.2007\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.2062\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2083\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2074\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2038\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5611e-04 - val_loss: 0.2034\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2058\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5236e-04 - val_loss: 0.2019\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2017\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2041\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4170e-04 - val_loss: 0.2090\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2107\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.2095\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - val_loss: 0.2059\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2001\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.1975\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.1977\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.2005\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.2055\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2075\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2067\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2035\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.2070e-04 - val_loss: 0.2031\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2053\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.8868e-04 - val_loss: 0.2047\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5553e-04 - val_loss: 0.2017\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2016\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2039\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8928e-04 - val_loss: 0.2084\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.2100\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - val_loss: 0.2090\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2056\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2002\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.1978\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - val_loss: 0.1980\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - val_loss: 0.2006\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2054\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2073\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2065\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2035\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9626e-04 - val_loss: 0.2032\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.1714e-04 - val_loss: 0.2053\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2048\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6303e-04 - val_loss: 0.2020\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2018\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - val_loss: 0.2040\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0688e-05 - val_loss: 0.2083\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.2099\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0057 - val_loss: 0.2089\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - val_loss: 0.2058\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2006\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.1983\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.1985\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.2011\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2056\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2074\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2068\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2039\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1824e-04 - val_loss: 0.2036\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1249e-04 - val_loss: 0.2056\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2023\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.2044\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3564e-04 - val_loss: 0.2041\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9689e-05 - val_loss: 0.2015\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2015\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9440e-04 - val_loss: 0.2079\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2094\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.2086\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.2057\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.1986\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - val_loss: 0.1989\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - val_loss: 0.2014\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2058\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.2076\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2070\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2043\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7880e-04 - val_loss: 0.1996\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.1977\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.1981\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2007\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2051\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2070\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2065\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2039\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1275e-05 - val_loss: 0.1994\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.1975\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.1980\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2006\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - val_loss: 0.2051\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2069\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2065\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2040\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7336e-04 - val_loss: 0.1996\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1978\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - val_loss: 0.1983\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.2009\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2053\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2071\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2067\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2043\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0618e-04 - val_loss: 0.2000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.1982\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.1987\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.2013\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2056\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2075\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2071\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2047\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.4485e-04 - val_loss: 0.2005\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.1988\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - val_loss: 0.1993\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2018\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2061\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2079\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.2075\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2051\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2010\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1993\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.1998\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2023\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2065\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2083\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.2079\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2056\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2016\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.1999\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2004\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2029\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0425e-04 - val_loss: 0.2070\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.2087\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2084\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.2061\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2022\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2005\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.2010\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2034\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3617e-04 - val_loss: 0.2075\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.2092\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0055 - val_loss: 0.2088\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0052 - val_loss: 0.2066\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2027\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.1012e-04 - val_loss: 0.2011\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2016\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2039\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0321e-04 - val_loss: 0.2041\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.0254e-04 - val_loss: 0.2024\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2027\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5776e-04 - val_loss: 0.2049\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:03:14,530] Trial 44 finished with value: 0.001346871256828308 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1576 - val_loss: 0.3210\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1027 - val_loss: 0.2634\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0468 - val_loss: 0.2172\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.1768\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0346 - val_loss: 0.1682\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0378 - val_loss: 0.1674\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0377 - val_loss: 0.1723\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0324 - val_loss: 0.1805\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0240 - val_loss: 0.1910\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0133 - val_loss: 0.2022\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2155\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0107 - val_loss: 0.2225\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0176 - val_loss: 0.2246\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0198 - val_loss: 0.2231\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0184 - val_loss: 0.2187\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0142 - val_loss: 0.2123\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - val_loss: 0.2042\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0961e-04 - val_loss: 0.1949\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0090 - val_loss: 0.1894\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0143 - val_loss: 0.1871\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - val_loss: 0.1876\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0159 - val_loss: 0.1902\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0133 - val_loss: 0.1946\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0089 - val_loss: 0.2005\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2075\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2118\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0083 - val_loss: 0.2138\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0103 - val_loss: 0.2138\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0103 - val_loss: 0.2121\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0086 - val_loss: 0.2089\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - val_loss: 0.2043\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.5333e-04 - val_loss: 0.1984\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.1949\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - val_loss: 0.1935\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0099 - val_loss: 0.1940\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0094 - val_loss: 0.1961\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0073 - val_loss: 0.1997\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.2045\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2071\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.2079\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.2071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - val_loss: 0.2047\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2009\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.1992\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.1992\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.2008\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2039\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7469e-04 - val_loss: 0.2050\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2045\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4341e-04 - val_loss: 0.2022\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2035\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2627e-04 - val_loss: 0.2032\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4149e-04 - val_loss: 0.2044\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9358e-04 - val_loss: 0.2039\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4383e-04 - val_loss: 0.2020\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4253e-04 - val_loss: 0.2060\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2069\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2063\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2041\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.9903e-04 - val_loss: 0.2006\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1990\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.1991\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2009\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2039\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4790e-04 - val_loss: 0.2052\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2028\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1779e-04 - val_loss: 0.2026\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1778e-04 - val_loss: 0.2039\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5288e-04 - val_loss: 0.2036\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4028e-04 - val_loss: 0.2018\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1499e-04 - val_loss: 0.2060\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2071\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2065\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2044\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2010\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.1995\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.1996\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2014\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2045\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2057\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2053\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.6925e-05 - val_loss: 0.2001\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.1988\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.1991\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.2009\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2041\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3490e-04 - val_loss: 0.2054\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2051\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2033\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3894e-05 - val_loss: 0.2032\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9202e-04 - val_loss: 0.2046\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3573e-04 - val_loss: 0.2026\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6978e-04 - val_loss: 0.2041\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3397e-04 - val_loss: 0.2039\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.5742e-04 - val_loss: 0.2022\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2022\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3012e-04 - val_loss: 0.2037\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9287e-04 - val_loss: 0.2020\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6129e-04 - val_loss: 0.2035\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4992e-04 - val_loss: 0.2019\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2019\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8127e-04 - val_loss: 0.2034\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.6799e-05 - val_loss: 0.2018\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2019\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5937e-04 - val_loss: 0.2034\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6056e-05 - val_loss: 0.2018\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2019\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7574e-04 - val_loss: 0.2035\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.9763e-05 - val_loss: 0.2019\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1717e-04 - val_loss: 0.2035\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4603e-04 - val_loss: 0.2019\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7506e-04 - val_loss: 0.2036\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0716e-04 - val_loss: 0.2020\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2021\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4378e-04 - val_loss: 0.2036\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7795e-04 - val_loss: 0.2020\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - val_loss: 0.2038\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1956e-04 - val_loss: 0.2037\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5515e-04 - val_loss: 0.2021\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0001e-04 - val_loss: 0.2038\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3650e-04 - val_loss: 0.2022\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8350e-04 - val_loss: 0.2039\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2063e-04 - val_loss: 0.2023\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.5537e-04 - val_loss: 0.2040\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6899e-04 - val_loss: 0.2040\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0652e-04 - val_loss: 0.2024\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.7431e-04 - val_loss: 0.2025\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6795e-04 - val_loss: 0.2041\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5570e-04 - val_loss: 0.2040\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.9359e-04 - val_loss: 0.2025\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.8608e-04 - val_loss: 0.2026\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7954e-04 - val_loss: 0.2042\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.4332e-04 - val_loss: 0.2041\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8143e-04 - val_loss: 0.2026\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9709e-04 - val_loss: 0.2027\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9053e-04 - val_loss: 0.2043\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3149e-04 - val_loss: 0.2042\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6977e-04 - val_loss: 0.2026\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0772e-04 - val_loss: 0.2027\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0111e-04 - val_loss: 0.2044\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2043\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5834e-04 - val_loss: 0.2027\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1803e-04 - val_loss: 0.2028\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1141e-04 - val_loss: 0.2045\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2044\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2028\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2816e-04 - val_loss: 0.2029\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2154e-04 - val_loss: 0.2045\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3814e-04 - val_loss: 0.2030\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.3160e-04 - val_loss: 0.2046\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2046\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4811e-04 - val_loss: 0.2031\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4164e-04 - val_loss: 0.2047\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5803e-04 - val_loss: 0.2032\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5159e-04 - val_loss: 0.2048\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2048\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6797e-04 - val_loss: 0.2033\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1542e-05 - val_loss: 0.2049\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2048\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7844e-05 - val_loss: 0.2034\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8506e-05 - val_loss: 0.2019\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2039\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8718e-04 - val_loss: 0.2040\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3589e-04 - val_loss: 0.2025\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.3892e-04 - val_loss: 0.2027\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4318e-04 - val_loss: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:03:33,214] Trial 45 finished with value: 0.0010537952184677124 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1480 - val_loss: 0.3048\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0967 - val_loss: 0.2432\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0291 - val_loss: 0.1727\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0391 - val_loss: 0.1578\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0435 - val_loss: 0.1700\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0296 - val_loss: 0.1930\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.2211\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0219 - val_loss: 0.2329\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0332 - val_loss: 0.2335\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0332 - val_loss: 0.2269\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0259 - val_loss: 0.2154\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0138 - val_loss: 0.2011\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.1942\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.1929\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0095 - val_loss: 0.1958\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - val_loss: 0.2017\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.8667e-04 - val_loss: 0.2102\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0075 - val_loss: 0.2140\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0112 - val_loss: 0.2145\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0116 - val_loss: 0.2120\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0091 - val_loss: 0.2072\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.2003\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.1969\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.1964\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0067 - val_loss: 0.1984\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2026\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6316e-04 - val_loss: 0.2084\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.2114\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - val_loss: 0.2119\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.2102\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - val_loss: 0.2066\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2014\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.1988\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.1985\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.2003\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2038\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5129e-04 - val_loss: 0.2050\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2016\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.2011\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2025\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1293e-04 - val_loss: 0.2057\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2067\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2057\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2031\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1023e-05 - val_loss: 0.2025\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0304e-04 - val_loss: 0.2038\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9904e-04 - val_loss: 0.2032\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1734e-05 - val_loss: 0.2009\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2005\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2020\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2062\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2053\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2029\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5657e-04 - val_loss: 0.2024\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3943e-04 - val_loss: 0.2037\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7679e-04 - val_loss: 0.2031\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6093e-05 - val_loss: 0.2009\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2006\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2021\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2052\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2062\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.2054\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.2894e-05 - val_loss: 0.2025\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4951e-04 - val_loss: 0.2039\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.5966e-04 - val_loss: 0.2033\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2207e-04 - val_loss: 0.2011\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2023\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.5141e-04 - val_loss: 0.2054\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2064\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2056\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2033\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6913e-04 - val_loss: 0.1994\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.1976\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.1978\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.1996\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2029\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2964e-04 - val_loss: 0.2076\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2101\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0071 - val_loss: 0.2107\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0077 - val_loss: 0.2096\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - val_loss: 0.2070\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2029\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5962e-04 - val_loss: 0.2009\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2008\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2024\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9126e-04 - val_loss: 0.2054\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2065\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2059\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.2038\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8261e-04 - val_loss: 0.2013\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2066\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2044\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5522e-04 - val_loss: 0.1970\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069 - val_loss: 0.1960\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0077 - val_loss: 0.2000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2071\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - val_loss: 0.2092\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0056 - val_loss: 0.2074\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.2022\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2010\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2032\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2428e-04 - val_loss: 0.2082\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - val_loss: 0.2095\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0060 - val_loss: 0.2076\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2029\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7489e-04 - val_loss: 0.2017\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2512e-05 - val_loss: 0.2022\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.2752e-04 - val_loss: 0.2027\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.6620e-04 - val_loss: 0.2043\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.9163e-04 - val_loss: 0.2030\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1886e-04 - val_loss: 0.2046\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4605e-04 - val_loss: 0.2048\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0214e-05 - val_loss: 0.1996\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.1988\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0046 - val_loss: 0.2008\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2052\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2064\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2050\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2011\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2003\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2020\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2061\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2073\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2058\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2020\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2011\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2027\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3547e-04 - val_loss: 0.2067\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.2078\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2063\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2026\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0147e-04 - val_loss: 0.2016\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5178e-04 - val_loss: 0.2070\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2080\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2066\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2029\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0650e-04 - val_loss: 0.2020\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.9880e-04 - val_loss: 0.2026\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7063e-04 - val_loss: 0.2040\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8921e-04 - val_loss: 0.2030\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2037e-04 - val_loss: 0.2044\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6030e-05 - val_loss: 0.2001\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.1995\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2013\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2051\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2063\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2010\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2026\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.7146e-04 - val_loss: 0.2063\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2074\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - val_loss: 0.2061\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2028\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6095e-04 - val_loss: 0.2020\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4514e-04 - val_loss: 0.2026\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1615e-04 - val_loss: 0.2040\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1779e-04 - val_loss: 0.2031\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9450e-04 - val_loss: 0.2045\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2035\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2985e-04 - val_loss: 0.2005\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.1999\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2016\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2053\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2065\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2054\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2022\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2030\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.5126e-04 - val_loss: 0.2066\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2076\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2064\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2032\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1013e-04 - val_loss: 0.2024\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.6820e-04 - val_loss: 0.2039\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8460e-04 - val_loss: 0.2031\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3755e-04 - val_loss: 0.2044\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7505e-04 - val_loss: 0.2007\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2002\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.2018\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2055\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2066\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2055\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2025\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9352e-04 - val_loss: 0.2018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3940e-05 - val_loss: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:03:52,520] Trial 46 finished with value: 0.0006552189588546753 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1677 - val_loss: 0.3490\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1491 - val_loss: 0.3498\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1564 - val_loss: 0.3451\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1420 - val_loss: 0.3441\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1410 - val_loss: 0.3431\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1400 - val_loss: 0.3421\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1390 - val_loss: 0.3421\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1388 - val_loss: 0.3401\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1370 - val_loss: 0.3391\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1360 - val_loss: 0.3381\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1350 - val_loss: 0.3371\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1340 - val_loss: 0.3361\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1330 - val_loss: 0.3351\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1320 - val_loss: 0.3341\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1310 - val_loss: 0.3331\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1300 - val_loss: 0.3321\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1290 - val_loss: 0.3311\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1280 - val_loss: 0.3301\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1270 - val_loss: 0.3291\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1260 - val_loss: 0.3281\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1250 - val_loss: 0.3271\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1240 - val_loss: 0.3261\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1230 - val_loss: 0.3251\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1220 - val_loss: 0.3241\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1210 - val_loss: 0.3231\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1200 - val_loss: 0.3221\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1190 - val_loss: 0.3211\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1180 - val_loss: 0.3201\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1170 - val_loss: 0.3191\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1160 - val_loss: 0.3181\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1150 - val_loss: 0.3171\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1140 - val_loss: 0.3161\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1130 - val_loss: 0.3151\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1120 - val_loss: 0.3141\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1110 - val_loss: 0.3131\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1100 - val_loss: 0.3121\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1090 - val_loss: 0.3111\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1080 - val_loss: 0.3101\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1070 - val_loss: 0.3091\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1060 - val_loss: 0.3081\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1050 - val_loss: 0.3071\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1040 - val_loss: 0.3061\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1030 - val_loss: 0.3051\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1020 - val_loss: 0.3041\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1010 - val_loss: 0.3031\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1000 - val_loss: 0.3021\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0990 - val_loss: 0.3011\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0980 - val_loss: 0.3001\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0970 - val_loss: 0.2991\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0960 - val_loss: 0.2981\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0950 - val_loss: 0.2971\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0940 - val_loss: 0.2961\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0930 - val_loss: 0.2951\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0920 - val_loss: 0.2941\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0910 - val_loss: 0.2931\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0900 - val_loss: 0.2921\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0890 - val_loss: 0.2911\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0880 - val_loss: 0.2901\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0870 - val_loss: 0.2891\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0860 - val_loss: 0.2881\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0850 - val_loss: 0.2871\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0840 - val_loss: 0.2861\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0830 - val_loss: 0.2851\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0820 - val_loss: 0.2841\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0810 - val_loss: 0.2831\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0800 - val_loss: 0.2821\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0790 - val_loss: 0.2811\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0780 - val_loss: 0.2801\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0770 - val_loss: 0.2791\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0760 - val_loss: 0.2781\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0750 - val_loss: 0.2771\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0740 - val_loss: 0.2761\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0730 - val_loss: 0.2751\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0720 - val_loss: 0.2741\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0710 - val_loss: 0.2731\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0700 - val_loss: 0.2721\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0690 - val_loss: 0.2711\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0680 - val_loss: 0.2701\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0670 - val_loss: 0.2691\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0660 - val_loss: 0.2681\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0650 - val_loss: 0.2671\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0640 - val_loss: 0.2661\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0630 - val_loss: 0.2651\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0620 - val_loss: 0.2641\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0610 - val_loss: 0.2631\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0600 - val_loss: 0.2621\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0590 - val_loss: 0.2611\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0580 - val_loss: 0.2601\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0570 - val_loss: 0.2591\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0560 - val_loss: 0.2581\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0550 - val_loss: 0.2571\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0540 - val_loss: 0.2561\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0530 - val_loss: 0.2551\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0520 - val_loss: 0.2541\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0510 - val_loss: 0.2531\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0500 - val_loss: 0.2521\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0490 - val_loss: 0.2511\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0480 - val_loss: 0.2501\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0470 - val_loss: 0.2491\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0460 - val_loss: 0.2481\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0450 - val_loss: 0.2471\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0440 - val_loss: 0.2461\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0430 - val_loss: 0.2451\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0420 - val_loss: 0.2441\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.2431\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0400 - val_loss: 0.2421\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0390 - val_loss: 0.2411\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0380 - val_loss: 0.2401\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0370 - val_loss: 0.2391\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0360 - val_loss: 0.2381\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0350 - val_loss: 0.2371\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0340 - val_loss: 0.2361\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0330 - val_loss: 0.2351\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - val_loss: 0.2341\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0310 - val_loss: 0.2331\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0300 - val_loss: 0.2321\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0290 - val_loss: 0.2311\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0280 - val_loss: 0.2301\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0270 - val_loss: 0.2291\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0260 - val_loss: 0.2281\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0250 - val_loss: 0.2271\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0240 - val_loss: 0.2261\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0230 - val_loss: 0.2251\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0220 - val_loss: 0.2241\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0210 - val_loss: 0.2231\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0200 - val_loss: 0.2221\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0190 - val_loss: 0.2211\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0180 - val_loss: 0.2201\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0170 - val_loss: 0.2191\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0160 - val_loss: 0.2181\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0150 - val_loss: 0.2171\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0140 - val_loss: 0.2161\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0130 - val_loss: 0.2151\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0120 - val_loss: 0.2141\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0110 - val_loss: 0.2131\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0100 - val_loss: 0.2121\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0090 - val_loss: 0.2111\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.2101\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0070 - val_loss: 0.2091\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.2081\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - val_loss: 0.2071\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2061\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6893e-04 - val_loss: 0.2031\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1069e-05 - val_loss: 0.2023\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3107e-04 - val_loss: 0.2017\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2007\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2007\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2011\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.4731e-04 - val_loss: 0.2027\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5568e-04 - val_loss: 0.2032\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.6784e-05 - val_loss: 0.2036\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7500e-04 - val_loss: 0.2039\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.2441e-04 - val_loss: 0.2040\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.4886e-04 - val_loss: 0.2040\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.6087e-04 - val_loss: 0.2039\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7169e-04 - val_loss: 0.2037\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9141e-04 - val_loss: 0.2035\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2917e-04 - val_loss: 0.2031\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8545e-06 - val_loss: 0.2029\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0927e-04 - val_loss: 0.2029\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9145e-04 - val_loss: 0.2029\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6540e-04 - val_loss: 0.2030\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4196e-04 - val_loss: 0.2032\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9126e-05 - val_loss: 0.2033\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5911e-04 - val_loss: 0.2033\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4010e-04 - val_loss: 0.2032\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2992e-05 - val_loss: 0.2030\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8241e-04 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6727e-04 - val_loss: 0.2029\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4365e-04 - val_loss: 0.2030\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2238e-04 - val_loss: 0.2032\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6755e-05 - val_loss: 0.2033\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7498e-04 - val_loss: 0.2033\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5439e-04 - val_loss: 0.2032\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5852e-05 - val_loss: 0.2030\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7083e-04 - val_loss: 0.2029\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.5685e-04 - val_loss: 0.2029\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3426e-04 - val_loss: 0.2030\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1393e-04 - val_loss: 0.2032\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4354e-05 - val_loss: 0.2033\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8182e-04 - val_loss: 0.2033\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6055e-04 - val_loss: 0.2032\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1395e-05 - val_loss: 0.2030\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6585e-04 - val_loss: 0.2029\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5237e-04 - val_loss: 0.2029\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3022e-04 - val_loss: 0.2030\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1030e-04 - val_loss: 0.2032\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.7632e-05 - val_loss: 0.2033\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8477e-04 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6320e-04 - val_loss: 0.2032\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.3780e-05 - val_loss: 0.2030\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:04:11,488] Trial 47 finished with value: 0.00016370415687561035 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1551 - val_loss: 0.3556\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1553 - val_loss: 0.3553\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1522 - val_loss: 0.3488\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1424 - val_loss: 0.3230\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1152 - val_loss: 0.3065\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1078 - val_loss: 0.2906\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0916 - val_loss: 0.2739\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0686 - val_loss: 0.2628\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0578 - val_loss: 0.2490\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0440 - val_loss: 0.2314\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0270 - val_loss: 0.2132\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0093 - val_loss: 0.1953\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0075 - val_loss: 0.1877\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0129 - val_loss: 0.1936\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0070 - val_loss: 0.2045\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.2070\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0061 - val_loss: 0.2035\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.1953\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1931\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0080 - val_loss: 0.1958\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - val_loss: 0.2024\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2011\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.5932e-04 - val_loss: 0.2026\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2016\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3681e-04 - val_loss: 0.1992\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2008\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.2312e-04 - val_loss: 0.2057\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - val_loss: 0.2066\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0051 - val_loss: 0.2039\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.1980\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.1962\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.1980\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2030\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2017\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4918e-04 - val_loss: 0.1964\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.1950\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - val_loss: 0.1968\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.2017\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0665e-05 - val_loss: 0.2029\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2008\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.4971e-04 - val_loss: 0.2021\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.9828e-04 - val_loss: 0.2001\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2014\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4837e-04 - val_loss: 0.2057\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2065\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - val_loss: 0.2041\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.1990\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.1975\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - val_loss: 0.1991\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2035\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2045\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2024\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.7708e-04 - val_loss: 0.1976\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.1963\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0054 - val_loss: 0.1981\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2026\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1917e-04 - val_loss: 0.2037\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0587e-05 - val_loss: 0.2030\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2011\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0117e-04 - val_loss: 0.2024\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2775e-04 - val_loss: 0.2006\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.3180e-05 - val_loss: 0.2003\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2016\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.8798e-04 - val_loss: 0.2056\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2064\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2043\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.1996\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.1983\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.1998\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2040\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2050\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2031\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.1986\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.1974\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.1991\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2034\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2026\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2042e-04 - val_loss: 0.1983\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.1972\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.1989\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2032\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2043\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5881e-04 - val_loss: 0.1983\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.1972\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.1990\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2032\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2043\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7441e-04 - val_loss: 0.1985\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.1974\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.1991\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2033\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2044\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2028\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6650e-04 - val_loss: 0.1987\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.1977\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.1994\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2035\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8310e-04 - val_loss: 0.1989\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.1979\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.1996\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2037\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2047\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2032\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9812e-04 - val_loss: 0.1992\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.1982\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1998\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2049\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2033\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9967e-04 - val_loss: 0.1994\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.1984\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2040\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2050\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2034\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.8325e-04 - val_loss: 0.1995\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1985\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.2001\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2041\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2036\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.1997\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1987\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2003\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2042\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2052\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2036\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.1998\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.1988\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2004\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2042\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2052\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2037\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.1999\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1989\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2005\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2053\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2038\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1990\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2005\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2053\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2038\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1990\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2053\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.2038\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2001\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.1991\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2053\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2001\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1991\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2053\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2001\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.1991\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2053\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2001\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.1991\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2053\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2038\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2001\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - val_loss: 0.1991\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2053\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2038\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.9432e-04 - val_loss: 0.2001\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1991\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.2043\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2052\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2037\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.4515e-04 - val_loss: 0.2001\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.1991\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:04:30,112] Trial 48 finished with value: 0.0022009313106536865 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1411 - val_loss: 0.3149\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0991 - val_loss: 0.2254\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - val_loss: 0.1392\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0725 - val_loss: 0.1226\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0842 - val_loss: 0.1313\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0745 - val_loss: 0.1498\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0553 - val_loss: 0.1732\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0311 - val_loss: 0.1985\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2239\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0212 - val_loss: 0.2378\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0350 - val_loss: 0.2427\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0383 - val_loss: 0.2362\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0325 - val_loss: 0.2245\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0213 - val_loss: 0.2106\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0078 - val_loss: 0.1963\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0062 - val_loss: 0.1890\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0135 - val_loss: 0.1864\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0161 - val_loss: 0.1873\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0151 - val_loss: 0.1910\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0113 - val_loss: 0.1970\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2049\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2093\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0072 - val_loss: 0.2107\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - val_loss: 0.2095\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0074 - val_loss: 0.2062\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 0.2009\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.1985\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.1987\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - val_loss: 0.2007\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0933e-04 - val_loss: 0.2049\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0051 - val_loss: 0.2072\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0072 - val_loss: 0.2067\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0067 - val_loss: 0.2038\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.1996\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.1981\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.1985\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2005\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1734e-04 - val_loss: 0.2008\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.8404e-04 - val_loss: 0.1992\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.1994\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.2047e-04 - val_loss: 0.2019\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2021\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2002\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2494e-05 - val_loss: 0.2005\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.6658e-04 - val_loss: 0.1988\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.1993\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.8221e-04 - val_loss: 0.2018\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2003\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1650e-04 - val_loss: 0.2006\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.5314e-04 - val_loss: 0.1990\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.1995\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6378e-04 - val_loss: 0.2020\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2023\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9949e-05 - val_loss: 0.1971\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.1959\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - val_loss: 0.1968\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.1996\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.4388e-04 - val_loss: 0.2040\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2061\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - val_loss: 0.2061\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.2043\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2008\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1213e-05 - val_loss: 0.1958\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - val_loss: 0.1932\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.1928\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - val_loss: 0.1943\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0064 - val_loss: 0.1976\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2023\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2047\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2051\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2038\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2008\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5645e-04 - val_loss: 0.1999\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1899e-04 - val_loss: 0.2034\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2028\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.1993\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2025\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.6995e-04 - val_loss: 0.1999\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.1992\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2003\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.2365e-04 - val_loss: 0.2000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.1994\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2005\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2003\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.1997\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2008\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.6732e-04 - val_loss: 0.2034\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2041\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2031\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2007\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2001\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2011\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8226e-04 - val_loss: 0.2037\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2035\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2011\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1839e-04 - val_loss: 0.2005\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7347e-04 - val_loss: 0.2041\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2048\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2039\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2014\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0242e-04 - val_loss: 0.2009\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9053e-05 - val_loss: 0.2045\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2052\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2042\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2018\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8758e-04 - val_loss: 0.2012\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7440e-04 - val_loss: 0.2023\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5231e-04 - val_loss: 0.2017\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7353e-04 - val_loss: 0.2027\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1308e-04 - val_loss: 0.2020\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4242e-05 - val_loss: 0.2030\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1001e-04 - val_loss: 0.2023\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2732e-04 - val_loss: 0.2001\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.1997\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2009\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2045\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2037\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2014\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1333e-04 - val_loss: 0.2009\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2031e-05 - val_loss: 0.2046\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2054\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2045\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2022\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1079e-05 - val_loss: 0.1986\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.1968\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.1969\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.1985\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2015\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.4883e-04 - val_loss: 0.2058\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2081\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.2086\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.2076\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - val_loss: 0.2051\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2014\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.7035e-04 - val_loss: 0.1996\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.1995\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2009\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2048\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2042\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7230e-04 - val_loss: 0.2019\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9520e-04 - val_loss: 0.2031\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1877e-04 - val_loss: 0.2027\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1140e-04 - val_loss: 0.2008\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2006\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8297e-04 - val_loss: 0.2047\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2057\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2051\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2030\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8243e-04 - val_loss: 0.1996\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1981\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.1982\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.1999\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2029\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9104e-04 - val_loss: 0.2041\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0488e-04 - val_loss: 0.2017\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9042e-04 - val_loss: 0.2030\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3307e-04 - val_loss: 0.2027\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3822e-04 - val_loss: 0.2009\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2023\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8525e-04 - val_loss: 0.2051\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2061\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.2055\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2035\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2002\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.1987\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.1989\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2006\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2045\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3758e-05 - val_loss: 0.1995\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.1981\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.1984\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:04:48,601] Trial 49 finished with value: 0.002293422818183899 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.1503 - val_loss: 0.3223\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1098 - val_loss: 0.2853\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0788 - val_loss: 0.2590\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0559 - val_loss: 0.2324\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0301 - val_loss: 0.2059\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.1801\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0216 - val_loss: 0.1693\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0321 - val_loss: 0.1670\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0345 - val_loss: 0.1699\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0317 - val_loss: 0.1764\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0252 - val_loss: 0.1859\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0158 - val_loss: 0.1975\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0044 - val_loss: 0.2104\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0083 - val_loss: 0.2177\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0154 - val_loss: 0.2209\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0185 - val_loss: 0.2211\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0186 - val_loss: 0.2189\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0163 - val_loss: 0.2147\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0120 - val_loss: 0.2088\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0061 - val_loss: 0.2015\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 0.1973\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0055 - val_loss: 0.1958\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0070 - val_loss: 0.1966\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0063 - val_loss: 0.1992\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.2034\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9348e-04 - val_loss: 0.2053\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0023 - val_loss: 0.2051\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0022 - val_loss: 0.2032\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3204e-04 - val_loss: 0.1997\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - val_loss: 0.1983\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0046 - val_loss: 0.1989\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - val_loss: 0.2012\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2049\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 0.2065\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.2063\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - val_loss: 0.2045\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 0.1999\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0031 - val_loss: 0.2004\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.2025\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.0451e-04 - val_loss: 0.2059\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2074\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0044 - val_loss: 0.2072\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0042 - val_loss: 0.2055\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - val_loss: 0.2024\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5556e-04 - val_loss: 0.2011\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0019 - val_loss: 0.2016\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.1908e-04 - val_loss: 0.2038\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.3707e-04 - val_loss: 0.2024\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9815e-04 - val_loss: 0.2028\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6314e-04 - val_loss: 0.2046\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0016 - val_loss: 0.2047\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0017 - val_loss: 0.2033\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.9178e-04 - val_loss: 0.2005\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.1996\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - val_loss: 0.2002\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0028 - val_loss: 0.2024\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.7329e-04 - val_loss: 0.2058\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2073\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0043 - val_loss: 0.2073\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - val_loss: 0.2057\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0027 - val_loss: 0.2029\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.6990e-04 - val_loss: 0.2018\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 0.2023\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.3093e-04 - val_loss: 0.2043\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.8259e-04 - val_loss: 0.2008\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0023 - val_loss: 0.1999\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0031 - val_loss: 0.2007\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - val_loss: 0.2028\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2437e-04 - val_loss: 0.2062\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0032 - val_loss: 0.2078\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0047 - val_loss: 0.2078\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0047 - val_loss: 0.2064\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - val_loss: 0.2037\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.8888e-04 - val_loss: 0.1997\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - val_loss: 0.1977\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - val_loss: 0.1973\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1984\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - val_loss: 0.2009\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0021 - val_loss: 0.2046\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - val_loss: 0.2065\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2067\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 0.2056\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0025 - val_loss: 0.2031\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.4987e-05 - val_loss: 0.1995\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - val_loss: 0.1976\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0055 - val_loss: 0.1974\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0057 - val_loss: 0.1987\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - val_loss: 0.2012\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2068\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.2071\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0041 - val_loss: 0.2061\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - val_loss: 0.2038\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.6911e-04 - val_loss: 0.2003\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.1985\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0046 - val_loss: 0.1983\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - val_loss: 0.1996\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - val_loss: 0.2021\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.6716e-04 - val_loss: 0.2057\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.2076\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - val_loss: 0.2080\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0049 - val_loss: 0.2070\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.2047\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.2013\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0018 - val_loss: 0.1996\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0035 - val_loss: 0.1995\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - val_loss: 0.2007\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2032\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.1364e-05 - val_loss: 0.2040\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.1232e-04 - val_loss: 0.2035\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.4630e-04 - val_loss: 0.2016\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 0.2023\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.6467e-04 - val_loss: 0.2046\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0015 - val_loss: 0.2054\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - val_loss: 0.2047\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2028\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.4884e-04 - val_loss: 0.2024\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.5442e-04 - val_loss: 0.2033\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1586e-04 - val_loss: 0.2029\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.4208e-04 - val_loss: 0.2038\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.7596e-04 - val_loss: 0.2033\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7585e-04 - val_loss: 0.2015\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 0.2012\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2023\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7696e-04 - val_loss: 0.2046\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2054\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2048\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3237e-04 - val_loss: 0.2025\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0929e-04 - val_loss: 0.2035\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.7652e-04 - val_loss: 0.2031\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7399e-05 - val_loss: 0.2040\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7258e-04 - val_loss: 0.2035\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.9269e-04 - val_loss: 0.2017\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1282e-04 - val_loss: 0.2049\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2057\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2050\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2032\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3807e-05 - val_loss: 0.2002\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1988\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.1989\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.2003\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2029\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1693e-04 - val_loss: 0.2065\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2085\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.2089\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0058 - val_loss: 0.2081\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2061\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2029\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9929e-04 - val_loss: 0.2014\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2013\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2026\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5534e-04 - val_loss: 0.2050\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2058\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2054\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2036\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1454e-04 - val_loss: 0.2008\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.1995\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.1997\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2011\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2037\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0691e-04 - val_loss: 0.2048\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2044\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2028\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7241e-04 - val_loss: 0.2027\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1483e-04 - val_loss: 0.2039\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.4363e-04 - val_loss: 0.2036\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0330e-04 - val_loss: 0.2021\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9695e-04 - val_loss: 0.2021\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7160e-04 - val_loss: 0.2031\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0531e-06 - val_loss: 0.2042\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.5184e-04 - val_loss: 0.2024\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.6723e-04 - val_loss: 0.2024\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5178e-04 - val_loss: 0.2036\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5507e-04 - val_loss: 0.2034\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6195e-04 - val_loss: 0.2019\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4718e-05 - val_loss: 0.2030\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9942e-05 - val_loss: 0.2042\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0593e-04 - val_loss: 0.2024\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8720e-04 - val_loss: 0.2024\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.5155e-04 - val_loss: 0.2036\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7036e-04 - val_loss: 0.2034\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9382e-04 - val_loss: 0.2020\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1654e-04 - val_loss: 0.2031\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7256e-05 - val_loss: 0.2043\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:05:11,431] Trial 50 finished with value: 0.0009046047925949097 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1320 - val_loss: 0.2738\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0506 - val_loss: 0.2119\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.1742\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0312 - val_loss: 0.1674\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0355 - val_loss: 0.1741\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0285 - val_loss: 0.1851\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0178 - val_loss: 0.1966\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0065 - val_loss: 0.2080\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0048 - val_loss: 0.2135\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0102 - val_loss: 0.2150\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0117 - val_loss: 0.2138\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0105 - val_loss: 0.2106\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - val_loss: 0.2059\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0026 - val_loss: 0.2001\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0032 - val_loss: 0.1969\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0063 - val_loss: 0.1959\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - val_loss: 0.1967\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0066 - val_loss: 0.1989\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0044 - val_loss: 0.2023\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.6129e-04 - val_loss: 0.2067\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2091\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - val_loss: 0.2100\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0067 - val_loss: 0.2094\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0061 - val_loss: 0.2075\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - val_loss: 0.2046\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.2006\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1984\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0047 - val_loss: 0.1978\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - val_loss: 0.1984\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.2003\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.2032\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.5251e-06 - val_loss: 0.2069\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.2091\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0059 - val_loss: 0.2099\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0067 - val_loss: 0.2094\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0062 - val_loss: 0.2078\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0046 - val_loss: 0.2052\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - val_loss: 0.2016\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 0.1996\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - val_loss: 0.1990\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0041 - val_loss: 0.1997\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - val_loss: 0.2014\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.9048e-04 - val_loss: 0.2054\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 0.2055\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0023 - val_loss: 0.2043\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 0.2014\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7509e-04 - val_loss: 0.2036\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1521e-04 - val_loss: 0.2027\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.1083e-04 - val_loss: 0.2030\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0036e-04 - val_loss: 0.2044\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.4954e-04 - val_loss: 0.2015\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0024 - val_loss: 0.2013\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0019 - val_loss: 0.2029\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.8023e-04 - val_loss: 0.2054\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 0.2066\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0035 - val_loss: 0.2066\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.2054\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - val_loss: 0.2032\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9962e-05 - val_loss: 0.2001\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1985\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0047 - val_loss: 0.1981\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - val_loss: 0.1989\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - val_loss: 0.2008\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 0.2037\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.1691e-04 - val_loss: 0.2051\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0019 - val_loss: 0.2052\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.9857e-04 - val_loss: 0.2016\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 0.2021\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.3138e-04 - val_loss: 0.2040\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.4040e-04 - val_loss: 0.2032\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6427e-07 - val_loss: 0.2035\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6326e-04 - val_loss: 0.2027\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.2967e-04 - val_loss: 0.2031\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0847e-05 - val_loss: 0.2046\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 0.2048\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2039\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.7203e-04 - val_loss: 0.2020\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.2019\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 0.2035\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.8810e-04 - val_loss: 0.2039\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.3239e-04 - val_loss: 0.2031\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.4133e-05 - val_loss: 0.2035\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1826e-04 - val_loss: 0.2027\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.4630e-04 - val_loss: 0.2031\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4886e-05 - val_loss: 0.2046\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.3368e-04 - val_loss: 0.2021\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.0399e-04 - val_loss: 0.2040\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5756e-04 - val_loss: 0.2032\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.2063e-05 - val_loss: 0.2014\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 0.2009\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - val_loss: 0.2015\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.4852e-05 - val_loss: 0.2036\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.5867e-04 - val_loss: 0.2029\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.8305e-04 - val_loss: 0.2033\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6525e-04 - val_loss: 0.2026\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.4634e-04 - val_loss: 0.2031\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.0065e-05 - val_loss: 0.2046\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.8842e-04 - val_loss: 0.2022\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.9936e-04 - val_loss: 0.2016\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.8787e-04 - val_loss: 0.2038\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6277e-04 - val_loss: 0.2042\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0010 - val_loss: 0.2034\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5989e-04 - val_loss: 0.2016\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2011\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 0.2018\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.9717e-04 - val_loss: 0.2039\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.1980e-04 - val_loss: 0.2032\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.7454e-06 - val_loss: 0.2036\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.4526e-04 - val_loss: 0.2029\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5600e-04 - val_loss: 0.2034\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2520e-04 - val_loss: 0.2027\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5308e-04 - val_loss: 0.2032\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9338e-05 - val_loss: 0.2026\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.1035e-04 - val_loss: 0.2031\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0733e-05 - val_loss: 0.2046\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - val_loss: 0.2050\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0018 - val_loss: 0.2041\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.7412e-04 - val_loss: 0.2023\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.7769e-04 - val_loss: 0.2017\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.2023\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.1609e-04 - val_loss: 0.2040\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.4980e-04 - val_loss: 0.2044\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.8494e-04 - val_loss: 0.2019\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - val_loss: 0.2014\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0018 - val_loss: 0.2020\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7521e-04 - val_loss: 0.2042\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - val_loss: 0.2035\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.8884e-04 - val_loss: 0.2017\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - val_loss: 0.2019\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9311e-04 - val_loss: 0.2041\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.4573e-04 - val_loss: 0.2034\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.4867e-04 - val_loss: 0.2017\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0019 - val_loss: 0.2019\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.1333e-04 - val_loss: 0.2041\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.7696e-04 - val_loss: 0.2035\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.9133e-04 - val_loss: 0.2017\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0014 - val_loss: 0.2013\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8772e-04 - val_loss: 0.2042\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.7779e-04 - val_loss: 0.2018\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 0.2014\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2021\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.9076e-04 - val_loss: 0.2043\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.8740e-04 - val_loss: 0.2019\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2015\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 0.2022\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.4090e-04 - val_loss: 0.2040\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.0886e-04 - val_loss: 0.2044\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.0911e-04 - val_loss: 0.2021\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0015 - val_loss: 0.2023\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.1301e-04 - val_loss: 0.2041\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.3481e-04 - val_loss: 0.2046\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.3712e-04 - val_loss: 0.2022\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.6697e-04 - val_loss: 0.2018\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 0.2025\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.8061e-04 - val_loss: 0.2042\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 0.2047\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - val_loss: 0.2040\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.6828e-04 - val_loss: 0.2023\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8.3254e-04 - val_loss: 0.2019\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.4605e-04 - val_loss: 0.2044\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2048\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0010 - val_loss: 0.2025\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9676e-04 - val_loss: 0.2020\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:05:32,652] Trial 51 finished with value: 0.001126110553741455 and parameters: {}. Best is trial 23 with value: 9.453296661376953e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1452 - val_loss: 0.2956\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0744 - val_loss: 0.2213\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0087 - val_loss: 0.1588\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0475 - val_loss: 0.1478\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0545 - val_loss: 0.1565\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0451 - val_loss: 0.1730\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0285 - val_loss: 0.1936\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0082 - val_loss: 0.2163\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0141 - val_loss: 0.2270\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0245 - val_loss: 0.2297\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0271 - val_loss: 0.2271\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0244 - val_loss: 0.2208\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0181 - val_loss: 0.2120\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - val_loss: 0.2012\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0015 - val_loss: 0.1956\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0071 - val_loss: 0.1941\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - val_loss: 0.1958\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0069 - val_loss: 0.2002\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.2066\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.2096\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - val_loss: 0.2098\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.2074\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - val_loss: 0.2030\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.2275e-05 - val_loss: 0.1968\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0063 - val_loss: 0.1935\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0095 - val_loss: 0.1930\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - val_loss: 0.1947\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0083 - val_loss: 0.1984\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0046 - val_loss: 0.2038\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.8405e-04 - val_loss: 0.2065\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.2068\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.2051\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0020 - val_loss: 0.2015\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0016 - val_loss: 0.2003\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - val_loss: 0.2012\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.6059e-04 - val_loss: 0.2046\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9843e-05 - val_loss: 0.2000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.1990\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - val_loss: 0.2000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0031 - val_loss: 0.2028\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5639e-04 - val_loss: 0.2072\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.2093\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - val_loss: 0.2093\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0062 - val_loss: 0.2075\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0044 - val_loss: 0.2040\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3052e-04 - val_loss: 0.1992\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0040 - val_loss: 0.1966\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0066 - val_loss: 0.1961\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0071 - val_loss: 0.1974\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - val_loss: 0.2004\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - val_loss: 0.2070\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.2073\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - val_loss: 0.2058\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - val_loss: 0.2028\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.7582e-04 - val_loss: 0.2018\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - val_loss: 0.2026\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.0174e-04 - val_loss: 0.2050\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2054\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - val_loss: 0.2042\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0010 - val_loss: 0.2014\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0018 - val_loss: 0.2006\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.2015\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.1301e-04 - val_loss: 0.2046\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.6800e-04 - val_loss: 0.2008\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - val_loss: 0.2000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - val_loss: 0.2010\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0022 - val_loss: 0.2036\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.8756e-04 - val_loss: 0.2042\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0010 - val_loss: 0.2031\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.2827e-05 - val_loss: 0.2038\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.4959e-04 - val_loss: 0.2028\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6840e-04 - val_loss: 0.2035\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4839e-04 - val_loss: 0.2026\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3577e-04 - val_loss: 0.2033\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0872e-04 - val_loss: 0.2023\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.4804e-04 - val_loss: 0.2031\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1241e-05 - val_loss: 0.2054\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2059\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0027 - val_loss: 0.2047\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0012 - val_loss: 0.2012\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.0644e-04 - val_loss: 0.2014\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.2017\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4675e-04 - val_loss: 0.2048\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.4334e-04 - val_loss: 0.2012\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0020 - val_loss: 0.2006\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.4710e-04 - val_loss: 0.2047\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.0676e-04 - val_loss: 0.2012\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0020 - val_loss: 0.2006\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - val_loss: 0.2016\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2041\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9628e-04 - val_loss: 0.2048\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.9062e-04 - val_loss: 0.2014\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - val_loss: 0.2007\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2017\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 0.2042\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0010 - val_loss: 0.2049\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - val_loss: 0.2039\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.3825e-04 - val_loss: 0.2015\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 0.2009\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0023 - val_loss: 0.2019\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 0.2051\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.1918e-04 - val_loss: 0.2017\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0015 - val_loss: 0.2011\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0021 - val_loss: 0.2021\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0014 - val_loss: 0.2053\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - val_loss: 0.2014\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.5628e-04 - val_loss: 0.2048\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 0.2055\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - val_loss: 0.2045\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2022\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0010 - val_loss: 0.2016\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.3291e-04 - val_loss: 0.2050\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - val_loss: 0.2057\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2047\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - val_loss: 0.2024\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.1398e-04 - val_loss: 0.2018\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.0802e-04 - val_loss: 0.2052\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0020 - val_loss: 0.2058\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0027 - val_loss: 0.2049\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0017 - val_loss: 0.2026\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8676e-04 - val_loss: 0.2020\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8357e-04 - val_loss: 0.2053\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0022 - val_loss: 0.2059\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - val_loss: 0.2050\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.6082e-04 - val_loss: 0.2021\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.4123e-04 - val_loss: 0.2031\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9399e-05 - val_loss: 0.2025\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7711e-04 - val_loss: 0.2034\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6637e-04 - val_loss: 0.2027\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.7904e-04 - val_loss: 0.2036\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.1803e-04 - val_loss: 0.2026\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6623e-04 - val_loss: 0.2035\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4.3836e-04 - val_loss: 0.2025\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.0636e-04 - val_loss: 0.2034\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.8956e-04 - val_loss: 0.2025\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0719e-04 - val_loss: 0.2034\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.7961e-04 - val_loss: 0.2026\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9071e-04 - val_loss: 0.2034\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.8762e-04 - val_loss: 0.2026\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6580e-04 - val_loss: 0.2035\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.0488e-04 - val_loss: 0.2026\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.3704e-04 - val_loss: 0.2035\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.2683e-04 - val_loss: 0.2027\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.0689e-04 - val_loss: 0.2035\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.5088e-04 - val_loss: 0.2027\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.7664e-04 - val_loss: 0.2035\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.7567e-04 - val_loss: 0.2027\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.4709e-04 - val_loss: 0.2036\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.0031e-04 - val_loss: 0.2028\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1866e-04 - val_loss: 0.2036\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.2433e-04 - val_loss: 0.2028\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.9148e-04 - val_loss: 0.2036\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.4751e-04 - val_loss: 0.2028\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.6557e-04 - val_loss: 0.2036\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.6984e-04 - val_loss: 0.2028\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4092e-04 - val_loss: 0.2037\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9126e-04 - val_loss: 0.2029\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.1741e-04 - val_loss: 0.2038\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.1178e-04 - val_loss: 0.2030\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9494e-04 - val_loss: 0.2038\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.3150e-04 - val_loss: 0.2031\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7343e-04 - val_loss: 0.2039\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5048e-04 - val_loss: 0.2031\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5281e-04 - val_loss: 0.2040\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.6887e-04 - val_loss: 0.2032\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3290e-04 - val_loss: 0.2040\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.8666e-04 - val_loss: 0.2033\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1365e-04 - val_loss: 0.2041\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.0395e-04 - val_loss: 0.2033\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.4905e-05 - val_loss: 0.2042\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.2081e-04 - val_loss: 0.2034\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.6696e-05 - val_loss: 0.2042\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.3729e-04 - val_loss: 0.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:05:51,258] Trial 52 finished with value: 5.8963894844055176e-05 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1532 - val_loss: 0.3352\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1231 - val_loss: 0.2597\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0454 - val_loss: 0.1977\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0111 - val_loss: 0.1983\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0059 - val_loss: 0.2228\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0199 - val_loss: 0.2244\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0203 - val_loss: 0.2110\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - val_loss: 0.1918\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0148 - val_loss: 0.1883\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0178 - val_loss: 0.1944\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0114 - val_loss: 0.2073\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2108\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2068\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9216e-04 - val_loss: 0.1973\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0089 - val_loss: 0.1944\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0116 - val_loss: 0.1969\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0090 - val_loss: 0.2040\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2152\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0092 - val_loss: 0.2202\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0142 - val_loss: 0.2199\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0139 - val_loss: 0.2152\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0092 - val_loss: 0.2067\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.8938e-04 - val_loss: 0.1954\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0102 - val_loss: 0.1894\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0160 - val_loss: 0.1878\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0174 - val_loss: 0.1899\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0153 - val_loss: 0.1952\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0100 - val_loss: 0.2033\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2139\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.2199\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0146 - val_loss: 0.2220\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0167 - val_loss: 0.2205\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0153 - val_loss: 0.2160\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0109 - val_loss: 0.2089\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.1997\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.1945\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0101 - val_loss: 0.1928\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0117 - val_loss: 0.1941\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0103 - val_loss: 0.1981\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0062 - val_loss: 0.2045\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0189e-04 - val_loss: 0.2074\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.2073\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2046\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0500e-04 - val_loss: 0.1994\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.1975\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0067 - val_loss: 0.1984\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - val_loss: 0.2018\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2075\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2100\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - val_loss: 0.2097\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - val_loss: 0.2068\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2017\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.1997\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.2004\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2035\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0954e-04 - val_loss: 0.2089\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2112\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0072 - val_loss: 0.2108\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - val_loss: 0.2079\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - val_loss: 0.2028\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - val_loss: 0.2008\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.2014\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2044\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7945e-04 - val_loss: 0.2047\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.5226e-04 - val_loss: 0.2025\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7297e-04 - val_loss: 0.2058\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2059\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2036\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6452e-04 - val_loss: 0.2040\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9798e-04 - val_loss: 0.2019\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2053\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2055\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2033\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7410e-04 - val_loss: 0.2037\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.5818e-05 - val_loss: 0.2065\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2066\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2042\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9634e-04 - val_loss: 0.1997\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.1981\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - val_loss: 0.1990\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.2023\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2076\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.2100\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0063 - val_loss: 0.2098\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - val_loss: 0.2072\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - val_loss: 0.2025\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - val_loss: 0.2006\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2014\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.0138e-04 - val_loss: 0.2047\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.2027\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.8868e-04 - val_loss: 0.2032\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6067e-04 - val_loss: 0.2061\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 0.2063\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0026 - val_loss: 0.2041\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0333e-04 - val_loss: 0.1997\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.1982\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - val_loss: 0.1992\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0045 - val_loss: 0.2024\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012 - val_loss: 0.2077\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - val_loss: 0.2101\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - val_loss: 0.2100\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0063 - val_loss: 0.2075\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.2029\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.3536e-04 - val_loss: 0.2011\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2018\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 0.2048\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 0.2052\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.7694e-04 - val_loss: 0.2038\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6367e-04 - val_loss: 0.2019\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 0.2026\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0010 - val_loss: 0.2055\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - val_loss: 0.2058\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2038\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2453e-04 - val_loss: 0.1996\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.1982\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - val_loss: 0.1993\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2026\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.9866e-04 - val_loss: 0.2078\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - val_loss: 0.2103\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - val_loss: 0.2102\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0066 - val_loss: 0.2078\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - val_loss: 0.2033\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.6084e-04 - val_loss: 0.2016\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 0.2023\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0012 - val_loss: 0.2053\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2057\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - val_loss: 0.2038\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5935e-04 - val_loss: 0.1997\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.1984\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0051 - val_loss: 0.1995\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - val_loss: 0.2028\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.2452e-04 - val_loss: 0.2081\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - val_loss: 0.2105\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - val_loss: 0.2104\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - val_loss: 0.2081\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0046 - val_loss: 0.2037\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9582e-04 - val_loss: 0.1975\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - val_loss: 0.1941\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0094 - val_loss: 0.1934\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0101 - val_loss: 0.1951\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0084 - val_loss: 0.1989\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - val_loss: 0.2046\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2074\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.2077\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0042 - val_loss: 0.2057\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0023 - val_loss: 0.2017\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2003\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.2013\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0021 - val_loss: 0.2045\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.8358e-05 - val_loss: 0.2042\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.0632e-04 - val_loss: 0.2026\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8383e-04 - val_loss: 0.2034\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.0244e-05 - val_loss: 0.2064\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.2068\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - val_loss: 0.2050\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 0.2011\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - val_loss: 0.1998\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - val_loss: 0.2009\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - val_loss: 0.2042\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.1405e-04 - val_loss: 0.2048\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1541e-04 - val_loss: 0.2040\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6371e-04 - val_loss: 0.2025\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.6430e-04 - val_loss: 0.2033\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0794e-04 - val_loss: 0.2063\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.2068\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - val_loss: 0.2050\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2012\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0023 - val_loss: 0.1999\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.2011\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 0.2043\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.9283e-04 - val_loss: 0.2050\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.4240e-06 - val_loss: 0.1998\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.1987\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.2033\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.6026e-05 - val_loss: 0.2086\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - val_loss: 0.2111\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - val_loss: 0.2112\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0078 - val_loss: 0.2091\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - val_loss: 0.2049\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - val_loss: 0.1990\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - val_loss: 0.1958\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0076 - val_loss: 0.1952\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0082 - val_loss: 0.1969\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0065 - val_loss: 0.2007\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.2062\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - val_loss: 0.2090\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0056 - val_loss: 0.2094\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - val_loss: 0.2075\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2036\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.5420e-04 - val_loss: 0.1979\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0054 - val_loss: 0.1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:06:10,274] Trial 53 finished with value: 0.00836893916130066 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1341 - val_loss: 0.1875\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0740 - val_loss: 0.1593\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0494 - val_loss: 0.2321\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0348 - val_loss: 0.2392\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0384 - val_loss: 0.2256\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0218 - val_loss: 0.1946\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0098 - val_loss: 0.1834\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0185 - val_loss: 0.1900\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0102 - val_loss: 0.2081\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0084 - val_loss: 0.2139\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0139 - val_loss: 0.2102\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0100 - val_loss: 0.1990\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.1966\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2039\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 0.2024\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.1933\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.1927\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.1992\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2695e-04 - val_loss: 0.1986\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5959e-04 - val_loss: 0.2041\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - val_loss: 0.2032\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.1967\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.1964\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2016\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2012\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.1957\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.1958\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2008\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2006\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.1959\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.1961\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2009\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2009\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.1963\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.1966\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2012\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2012\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.1970\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.1974\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2019\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.1980\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.1984\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2028\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.1991\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9541e-04 - val_loss: 0.1995\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7512e-04 - val_loss: 0.2037\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.2038\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.2002\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0212e-04 - val_loss: 0.1931\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.1906\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0089 - val_loss: 0.1922\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0073 - val_loss: 0.1975\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2056\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.2095\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0092 - val_loss: 0.2096\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0092 - val_loss: 0.2064\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.2004\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0099e-04 - val_loss: 0.1914\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - val_loss: 0.1868\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0130 - val_loss: 0.1862\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0136 - val_loss: 0.1892\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0107 - val_loss: 0.1952\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.2035\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2077\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.2087\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0079 - val_loss: 0.2069\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.2025\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.1958\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.1926\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - val_loss: 0.1925\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0081 - val_loss: 0.1952\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - val_loss: 0.2003\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9694e-04 - val_loss: 0.2072\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.2109\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0095 - val_loss: 0.2118\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0103 - val_loss: 0.2102\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.2065\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2008\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2206e-04 - val_loss: 0.1980\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.1979\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2002\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2061\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2053\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2023\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0773e-04 - val_loss: 0.1974\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.1952\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.1956\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.1982\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2027\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2040\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2014\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5900e-04 - val_loss: 0.2012\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5829e-04 - val_loss: 0.2032\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2029\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2004\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2003\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2024\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5920e-04 - val_loss: 0.2022\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9734e-04 - val_loss: 0.1998\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.1998\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7518e-04 - val_loss: 0.2018\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0236e-05 - val_loss: 0.2037\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6717e-04 - val_loss: 0.2009\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.4207e-04 - val_loss: 0.2029\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2027\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1152e-04 - val_loss: 0.2003\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2003\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2025\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9217e-04 - val_loss: 0.2023\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.9798e-04 - val_loss: 0.2000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2001\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2022\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3545e-04 - val_loss: 0.2021\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8372e-04 - val_loss: 0.1999\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.1999\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2021\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2341e-04 - val_loss: 0.2020\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.9450e-05 - val_loss: 0.1998\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.1999\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0558e-04 - val_loss: 0.2020\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9793e-05 - val_loss: 0.1999\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4886e-04 - val_loss: 0.2021\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5487e-04 - val_loss: 0.1999\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2001\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2023\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3130e-04 - val_loss: 0.2022\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4502e-04 - val_loss: 0.2001\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2002\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.3876e-04 - val_loss: 0.2023\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5740e-04 - val_loss: 0.2002\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2004\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6176e-04 - val_loss: 0.2025\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8348e-04 - val_loss: 0.2004\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2005\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2027\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9413e-04 - val_loss: 0.2026\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1777e-04 - val_loss: 0.2005\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2007\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.3183e-04 - val_loss: 0.2028\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.5667e-04 - val_loss: 0.2007\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.7221e-04 - val_loss: 0.2030\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.9768e-04 - val_loss: 0.2008\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - val_loss: 0.2010\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2032\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0010 - val_loss: 0.2010\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - val_loss: 0.2012\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.8879e-04 - val_loss: 0.2033\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 0.2012\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.8902e-04 - val_loss: 0.2013\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.4287e-04 - val_loss: 0.2035\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.4381e-04 - val_loss: 0.2015\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.9831e-04 - val_loss: 0.2037\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0015 - val_loss: 0.2015\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.0016e-04 - val_loss: 0.2016\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.5541e-04 - val_loss: 0.2038\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5836e-04 - val_loss: 0.2018\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.1430e-04 - val_loss: 0.2040\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2018\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.1854e-04 - val_loss: 0.2020\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7525e-04 - val_loss: 0.2041\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.8075e-04 - val_loss: 0.2021\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.8236e-05 - val_loss: 0.2043\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.5046e-05 - val_loss: 0.2023\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.6723e-05 - val_loss: 0.2004\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0014 - val_loss: 0.2030\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.3199e-04 - val_loss: 0.2031\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.9975e-04 - val_loss: 0.2012\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0010 - val_loss: 0.2014\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.5625e-04 - val_loss: 0.2037\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0015 - val_loss: 0.2017\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4.8073e-04 - val_loss: 0.2019\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:06:31,773] Trial 54 finished with value: 0.0002640038728713989 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.1642 - val_loss: 0.3415\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1466 - val_loss: 0.3176\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1137 - val_loss: 0.3119\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1114 - val_loss: 0.2975\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0934 - val_loss: 0.2798\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0753 - val_loss: 0.2581\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0535 - val_loss: 0.2397\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0358 - val_loss: 0.2208\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0162 - val_loss: 0.2004\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.1902\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0145 - val_loss: 0.1870\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0176 - val_loss: 0.1885\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0161 - val_loss: 0.1929\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0115 - val_loss: 0.1995\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.2078\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2121\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0075 - val_loss: 0.2132\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0087 - val_loss: 0.2118\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0073 - val_loss: 0.2082\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2029\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2004\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2002\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2021\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2057\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2070\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - val_loss: 0.2063\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8165e-05 - val_loss: 0.2034\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.7441e-04 - val_loss: 0.2049\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2044\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4467e-04 - val_loss: 0.2023\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2021\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1401e-04 - val_loss: 0.2066\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2077\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2070\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2047\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2010\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.1994\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.1995\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.2013\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2045\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.5638e-04 - val_loss: 0.2057\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2052\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4481e-04 - val_loss: 0.2030\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5803e-04 - val_loss: 0.2044\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.3105e-04 - val_loss: 0.2041\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0335e-04 - val_loss: 0.2022\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2021\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3858e-06 - val_loss: 0.2064\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2074\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2068\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2047\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.1997\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.1999\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2016\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2058\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2054\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1211e-06 - val_loss: 0.2033\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0580e-04 - val_loss: 0.2046\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2043\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2476e-04 - val_loss: 0.2025\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.6908e-04 - val_loss: 0.2024\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5584e-04 - val_loss: 0.2036\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2623e-04 - val_loss: 0.2019\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4730e-04 - val_loss: 0.2061\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2072\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2066\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2046\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.1999\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2001\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2017\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2047\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2059\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2037\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2379e-04 - val_loss: 0.2005\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.1992\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.1995\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2012\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2042\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9130e-04 - val_loss: 0.2055\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2051\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.4179e-05 - val_loss: 0.2032\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9127e-04 - val_loss: 0.2046\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2043\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1562e-04 - val_loss: 0.2026\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7526e-04 - val_loss: 0.2026\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.2916e-04 - val_loss: 0.2040\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8918e-04 - val_loss: 0.2038\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0056e-04 - val_loss: 0.2022\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1935e-04 - val_loss: 0.2035\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9961e-05 - val_loss: 0.2019\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2019\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5900e-05 - val_loss: 0.2062\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2072\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2067\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2048\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2017\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2003\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2005\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2021\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - val_loss: 0.2050\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2062\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2058\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2040\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6935e-04 - val_loss: 0.2010\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.1997\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2017\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2046\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2059\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2038\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5210e-04 - val_loss: 0.2008\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.1996\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.1999\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2016\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2058\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2038\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6843e-04 - val_loss: 0.2009\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.1996\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2017\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2046\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2059\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2056\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8308e-04 - val_loss: 0.2010\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.1998\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2001\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2018\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2047\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2060\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2057\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2040\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3802e-04 - val_loss: 0.2011\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.1999\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2003\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2020\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2061\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2058\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2042\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.0854e-04 - val_loss: 0.2013\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2001\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2005\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.2021\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2063\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2060\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2044\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2003\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2006\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2023\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.5890e-04 - val_loss: 0.2052\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2064\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2062\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2005\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2008\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2025\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7024e-04 - val_loss: 0.2054\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2066\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2063\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2047\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2019\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2007\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2010\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.2027\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8354e-04 - val_loss: 0.2055\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2067\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2065\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2049\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2020\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2012\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2028\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.9922e-04 - val_loss: 0.2057\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2069\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.2066\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.2050\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2022\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:06:55,026] Trial 55 finished with value: 0.0010215342044830322 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1333 - val_loss: 0.2335\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2427\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0441 - val_loss: 0.2186\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0179 - val_loss: 0.1703\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0310 - val_loss: 0.1603\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0380 - val_loss: 0.1733\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0229 - val_loss: 0.1983\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2066\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0110 - val_loss: 0.2031\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0067 - val_loss: 0.1913\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.1936\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9401e-04 - val_loss: 0.2070\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0137 - val_loss: 0.2086\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0153 - val_loss: 0.2013\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0073 - val_loss: 0.1874\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0078 - val_loss: 0.1830\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0129 - val_loss: 0.1859\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0101 - val_loss: 0.1947\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2084\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0131 - val_loss: 0.2145\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0193 - val_loss: 0.2143\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0190 - val_loss: 0.2090\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0132 - val_loss: 0.1994\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.1865\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0108 - val_loss: 0.1800\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0180 - val_loss: 0.1788\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0196 - val_loss: 0.1820\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0165 - val_loss: 0.1889\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0096 - val_loss: 0.1989\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1221e-04 - val_loss: 0.2038\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.2043\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.2012\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.1949\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.1930\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.1946\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.1994\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9900e-05 - val_loss: 0.2003\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.3925e-04 - val_loss: 0.1978\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.1989\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3717e-04 - val_loss: 0.2031\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2035\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2009\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.1955\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.1938\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.1953\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.1995\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8016e-04 - val_loss: 0.2063\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.2094\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0094 - val_loss: 0.2092\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0092 - val_loss: 0.2062\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.2007\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6979e-04 - val_loss: 0.1930\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0075 - val_loss: 0.1890\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0118 - val_loss: 0.1882\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0127 - val_loss: 0.1903\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0107 - val_loss: 0.1950\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.2019\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.5989e-04 - val_loss: 0.2053\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - val_loss: 0.2056\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2033\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.1985\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.1969\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.1981\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2018\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1809e-04 - val_loss: 0.2025\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2006\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5322e-04 - val_loss: 0.2014\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7281e-04 - val_loss: 0.1996\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2006\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4664e-04 - val_loss: 0.2040\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2044\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2024\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.1980\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.1966\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.1979\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2015\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4517e-04 - val_loss: 0.2022\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0399e-04 - val_loss: 0.2004\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.3590e-04 - val_loss: 0.2013\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.4536e-05 - val_loss: 0.2046\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2050\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2029\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.1986\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.1972\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.1985\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2020\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9739e-04 - val_loss: 0.2027\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8724e-04 - val_loss: 0.2018\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4214e-04 - val_loss: 0.2001\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2010\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4778e-04 - val_loss: 0.2043\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.2028\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.1986\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.1973\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.1985\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2020\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.0339e-04 - val_loss: 0.2028\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2010\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8806e-04 - val_loss: 0.2019\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5521e-04 - val_loss: 0.2003\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6697e-04 - val_loss: 0.2044\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2049\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2030\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.1989\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1976\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.1989\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2023\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8232e-04 - val_loss: 0.2030\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7304e-04 - val_loss: 0.2022\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.6404e-04 - val_loss: 0.2006\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3185e-04 - val_loss: 0.2047\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2052\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2033\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.1993\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.1980\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.1992\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2026\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.2763e-04 - val_loss: 0.2033\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0906e-04 - val_loss: 0.2025\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1627e-04 - val_loss: 0.2010\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.6673e-04 - val_loss: 0.2019\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3960e-05 - val_loss: 0.2004\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1624e-04 - val_loss: 0.2045\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2050\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.2032\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.1993\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.1981\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.1993\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2027\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2134e-04 - val_loss: 0.2034\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9844e-05 - val_loss: 0.2027\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8408e-04 - val_loss: 0.2011\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.5443e-04 - val_loss: 0.2021\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4962e-04 - val_loss: 0.2006\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6190e-04 - val_loss: 0.2047\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.2052\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2035\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.1996\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.1985\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.1997\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2037\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2021\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7436e-04 - val_loss: 0.1985\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.1974\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.1987\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2022\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5789e-04 - val_loss: 0.2030\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.9680e-04 - val_loss: 0.2015\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9096e-04 - val_loss: 0.2024\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1121e-04 - val_loss: 0.2010\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2020\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1095e-05 - val_loss: 0.2050\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2056\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2039\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2001\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.1990\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2001\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2041\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3723e-04 - val_loss: 0.1990\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.1980\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.1993\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2026\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3826e-04 - val_loss: 0.2034\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1851e-05 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9399e-04 - val_loss: 0.2015\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0081e-04 - val_loss: 0.2025\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3562e-04 - val_loss: 0.2011\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2021\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3304e-05 - val_loss: 0.2051\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2057\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2041\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2004\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.1993\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2005\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9632e-04 - val_loss: 0.1995\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.1985\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.1997\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2030\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.5311e-04 - val_loss: 0.2039\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5439e-04 - val_loss: 0.1990\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.1981\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.1994\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:07:13,160] Trial 56 finished with value: 0.000548824667930603 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1426 - val_loss: 0.2204\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0339 - val_loss: 0.2772\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0808 - val_loss: 0.2779\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0671 - val_loss: 0.2148\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3793e-05 - val_loss: 0.1996\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0113 - val_loss: 0.2193\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0094 - val_loss: 0.2150\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.1966\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0154 - val_loss: 0.1954\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - val_loss: 0.2086\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2349\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0225 - val_loss: 0.2444\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0316 - val_loss: 0.2410\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0288 - val_loss: 0.2279\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0170 - val_loss: 0.2075\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2003\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0097 - val_loss: 0.2000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0090 - val_loss: 0.2064\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2202\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0120 - val_loss: 0.2256\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0174 - val_loss: 0.2241\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0162 - val_loss: 0.2168\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0096 - val_loss: 0.2048\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2010\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.2048\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2161\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0096 - val_loss: 0.2147\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0104 - val_loss: 0.2105\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - val_loss: 0.2009\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.1981\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.2013\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2097\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.2119\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0082 - val_loss: 0.2088\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.2010\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.1989\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2019\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2094\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.2116\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.2090\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0055 - val_loss: 0.2021\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2004\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2032\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0768e-04 - val_loss: 0.2101\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0067 - val_loss: 0.2121\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0087 - val_loss: 0.2098\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - val_loss: 0.2036\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9181e-04 - val_loss: 0.1939\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0094 - val_loss: 0.1892\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0140 - val_loss: 0.1891\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0140 - val_loss: 0.1932\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0100 - val_loss: 0.2008\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2115\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.2173\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0137 - val_loss: 0.2188\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0151 - val_loss: 0.2164\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0128 - val_loss: 0.2107\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0071 - val_loss: 0.2020\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.1977\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1975\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.2009\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2074\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2098\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - val_loss: 0.2085\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2040\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.8536e-04 - val_loss: 0.1965\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0071 - val_loss: 0.1931\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0104 - val_loss: 0.1936\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0100 - val_loss: 0.1974\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0062 - val_loss: 0.2042\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2793e-04 - val_loss: 0.2070\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2062\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2022\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2049\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6622e-04 - val_loss: 0.2043\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0311e-04 - val_loss: 0.2006\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2004\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2036\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4119e-04 - val_loss: 0.2096\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.2118\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0078 - val_loss: 0.2107\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.2065\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.1995\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.1964\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0074 - val_loss: 0.1969\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0070 - val_loss: 0.2005\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2069\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2095\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0054 - val_loss: 0.2088\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.2050\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.5178e-04 - val_loss: 0.1984\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0055 - val_loss: 0.1957\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - val_loss: 0.1968\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.2031\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2292e-04 - val_loss: 0.2044\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2017\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.0637e-05 - val_loss: 0.2005\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2021\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2068\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2076\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2050\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.1993\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1983\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.2013\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2079\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2098\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.2078\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2023\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2011\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2035\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8424e-04 - val_loss: 0.2091\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.2107\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.2086\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2035\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0366e-04 - val_loss: 0.2022\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2043\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8415e-04 - val_loss: 0.2029\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9888e-04 - val_loss: 0.2049\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2165e-04 - val_loss: 0.2053\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2039\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3212e-04 - val_loss: 0.1997\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.1988\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2011\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2061\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2076\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.2060\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2017\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2008\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2028\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9849e-04 - val_loss: 0.2074\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2087\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.2071\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2029\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4793e-04 - val_loss: 0.2018\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9307e-04 - val_loss: 0.2026\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7100e-04 - val_loss: 0.2044\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.8030e-04 - val_loss: 0.2032\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4058e-04 - val_loss: 0.2049\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2037\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7308e-04 - val_loss: 0.2000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.1993\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2014\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2059\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2074\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2060\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2021\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2064e-04 - val_loss: 0.2075\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2087\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.2073\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2033\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2194e-04 - val_loss: 0.2024\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2042\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1645e-04 - val_loss: 0.2031\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7929e-04 - val_loss: 0.2048\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4684e-04 - val_loss: 0.2002\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.1996\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2017\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2075\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2062\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2025\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.2264e-04 - val_loss: 0.2017\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2918e-04 - val_loss: 0.2027\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.5094e-04 - val_loss: 0.2044\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8835e-04 - val_loss: 0.2035\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9504e-05 - val_loss: 0.2000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.1995\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2016\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2060\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2074\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2062\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2026\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5184e-04 - val_loss: 0.2018\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4734e-04 - val_loss: 0.2028\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9199e-04 - val_loss: 0.2046\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2222e-04 - val_loss: 0.2003\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.1998\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.2019\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2062\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.2076\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2064\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2029\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4610e-04 - val_loss: 0.2022\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2040\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5498e-04 - val_loss: 0.2032\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6532e-04 - val_loss: 0.2049\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2040\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4969e-04 - val_loss: 0.2007\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2002\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:07:31,551] Trial 57 finished with value: 0.0011862069368362427 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1360 - val_loss: 0.2566\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0183 - val_loss: 0.1495\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0677 - val_loss: 0.1347\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0708 - val_loss: 0.1506\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0527 - val_loss: 0.1767\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0262 - val_loss: 0.2064\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2151\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0129 - val_loss: 0.2110\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0087 - val_loss: 0.2032\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.3365e-04 - val_loss: 0.1923\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0101 - val_loss: 0.1881\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0142 - val_loss: 0.1889\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0135 - val_loss: 0.1933\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 0.2005\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2100\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.2150\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0124 - val_loss: 0.2163\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0137 - val_loss: 0.2145\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0119 - val_loss: 0.2103\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0076 - val_loss: 0.2041\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.1962\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0065 - val_loss: 0.1918\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0109 - val_loss: 0.1904\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0123 - val_loss: 0.1915\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0112 - val_loss: 0.1948\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - val_loss: 0.1998\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2064\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2101\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - val_loss: 0.2113\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.2104\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.2077\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2033\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0744e-04 - val_loss: 0.1974\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.1941\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0089 - val_loss: 0.1931\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0099 - val_loss: 0.1941\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0089 - val_loss: 0.1969\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - val_loss: 0.2013\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2071\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2104\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0073 - val_loss: 0.2115\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - val_loss: 0.2108\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0077 - val_loss: 0.2083\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.2044\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.1990\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - val_loss: 0.1960\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0071 - val_loss: 0.1951\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0081 - val_loss: 0.1961\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - val_loss: 0.1987\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2029\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.2715e-04 - val_loss: 0.2083\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.2114\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0082 - val_loss: 0.2125\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0093 - val_loss: 0.2118\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.2095\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - val_loss: 0.2057\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2006\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1977\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.1969\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.1978\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0054 - val_loss: 0.2003\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2042\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2061\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2061\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2014\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2002\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.2008\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2030\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4995e-04 - val_loss: 0.2066\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2082\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - val_loss: 0.2081\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2063\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2031\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7054e-05 - val_loss: 0.2018\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2023\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5987e-04 - val_loss: 0.2044\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6196e-05 - val_loss: 0.2003\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.1994\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.2001\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2024\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.9004e-04 - val_loss: 0.2060\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2077\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.2077\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.2060\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2029\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6388e-04 - val_loss: 0.2017\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2023\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0843e-04 - val_loss: 0.2043\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.8854e-05 - val_loss: 0.2005\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1996\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.2003\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2026\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7811e-04 - val_loss: 0.2062\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2079\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.2078\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2062\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2032\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0459e-05 - val_loss: 0.1989\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.1967\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0065 - val_loss: 0.1962\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - val_loss: 0.1973\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - val_loss: 0.1999\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2038\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8247e-04 - val_loss: 0.2057\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2059\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2046\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2009\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2016\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1853e-04 - val_loss: 0.2041\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.2509e-04 - val_loss: 0.2030\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1711e-04 - val_loss: 0.2035\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6298e-04 - val_loss: 0.2024\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.1012e-04 - val_loss: 0.2029\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6965e-04 - val_loss: 0.2049\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2052\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7440e-04 - val_loss: 0.2014\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2005\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2195e-04 - val_loss: 0.2039\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7517e-04 - val_loss: 0.2028\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0849e-04 - val_loss: 0.2033\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0823e-04 - val_loss: 0.2023\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.1735e-04 - val_loss: 0.2029\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4826e-04 - val_loss: 0.2049\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2052\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6802e-04 - val_loss: 0.2014\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2006\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2014\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9936e-04 - val_loss: 0.2040\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6438e-04 - val_loss: 0.2029\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9910e-04 - val_loss: 0.2035\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2648e-04 - val_loss: 0.2024\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8227e-04 - val_loss: 0.2030\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0674e-04 - val_loss: 0.2050\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2053\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2675e-04 - val_loss: 0.2016\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2015\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8435e-04 - val_loss: 0.2042\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5136e-04 - val_loss: 0.2031\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0274e-04 - val_loss: 0.2036\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2388e-04 - val_loss: 0.2026\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7663e-04 - val_loss: 0.2032\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5367e-07 - val_loss: 0.2052\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2055\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2010\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2018\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2039\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0159e-04 - val_loss: 0.2044\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2001e-04 - val_loss: 0.2009\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2002\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2011\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7246e-05 - val_loss: 0.2039\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.2956e-04 - val_loss: 0.2029\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4775e-04 - val_loss: 0.2035\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.3882e-04 - val_loss: 0.2025\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.9822e-04 - val_loss: 0.2031\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5117e-05 - val_loss: 0.2052\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2055\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2041\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6430e-04 - val_loss: 0.2046\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2932e-04 - val_loss: 0.2012\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5924e-04 - val_loss: 0.2041\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.0931e-04 - val_loss: 0.2032\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9770e-05 - val_loss: 0.2038\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4207e-04 - val_loss: 0.2028\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7910e-04 - val_loss: 0.2035\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4717e-04 - val_loss: 0.2026\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4315e-04 - val_loss: 0.2032\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1042e-05 - val_loss: 0.2024\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5430e-04 - val_loss: 0.2030\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7750e-04 - val_loss: 0.2051\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2055\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:07:49,990] Trial 58 finished with value: 0.0012162178754806519 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1476 - val_loss: 0.2381\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - val_loss: 0.0612\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1527 - val_loss: 0.0538\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1394 - val_loss: 0.1164\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0726 - val_loss: 0.1961\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0038 - val_loss: 0.2233\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0277 - val_loss: 0.2198\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0229 - val_loss: 0.1988\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.1668\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0307 - val_loss: 0.1545\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0431 - val_loss: 0.1568\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0411 - val_loss: 0.1699\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0282 - val_loss: 0.1912\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0072 - val_loss: 0.2186\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0197 - val_loss: 0.2320\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0323 - val_loss: 0.2361\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0361 - val_loss: 0.2331\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0330 - val_loss: 0.2243\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0241 - val_loss: 0.2105\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0102 - val_loss: 0.1923\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.1822\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0181 - val_loss: 0.1793\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0210 - val_loss: 0.1826\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0179 - val_loss: 0.1911\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0095 - val_loss: 0.2039\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2100\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0092 - val_loss: 0.2103\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0094 - val_loss: 0.2055\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.1963\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.1930\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - val_loss: 0.1950\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.2017\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4196e-04 - val_loss: 0.2029\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.1992\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2006\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5370e-04 - val_loss: 0.2065\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.2072\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.2033\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.1952\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.1925\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0088 - val_loss: 0.1946\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.2012\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2894e-04 - val_loss: 0.2114\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - val_loss: 0.2162\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0147 - val_loss: 0.2161\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0147 - val_loss: 0.2118\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0103 - val_loss: 0.2035\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.1917\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0097 - val_loss: 0.1855\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0159 - val_loss: 0.1843\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0170 - val_loss: 0.1878\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0136 - val_loss: 0.1952\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.2060\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2115\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0099 - val_loss: 0.2123\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0107 - val_loss: 0.2089\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - val_loss: 0.2017\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3228e-04 - val_loss: 0.1911\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0104 - val_loss: 0.1858\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0158 - val_loss: 0.1851\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0164 - val_loss: 0.1887\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0129 - val_loss: 0.1960\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.2065\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.2119\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0102 - val_loss: 0.2128\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0111 - val_loss: 0.2098\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0081 - val_loss: 0.2032\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.1933\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - val_loss: 0.1884\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0133 - val_loss: 0.1879\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0139 - val_loss: 0.1913\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0104 - val_loss: 0.1983\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2083\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - val_loss: 0.2135\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0116 - val_loss: 0.2144\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0125 - val_loss: 0.2114\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0096 - val_loss: 0.2051\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.1957\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.1909\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0109 - val_loss: 0.1904\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0114 - val_loss: 0.1937\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0082 - val_loss: 0.2004\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2100\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - val_loss: 0.2149\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0129 - val_loss: 0.2158\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0138 - val_loss: 0.2129\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0109 - val_loss: 0.2068\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.1976\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.1930\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0090 - val_loss: 0.1925\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0095 - val_loss: 0.1956\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - val_loss: 0.2020\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7509e-05 - val_loss: 0.2042\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2026\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7900e-04 - val_loss: 0.1976\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.1967\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.1994\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2054\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2073\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - val_loss: 0.2054\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2002\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.1990\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2015\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.5858e-04 - val_loss: 0.2073\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.2090\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.2070\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.2017\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3899e-04 - val_loss: 0.2004\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6335e-04 - val_loss: 0.2014\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0186e-04 - val_loss: 0.2037\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0927e-04 - val_loss: 0.1974\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.1966\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.1994\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2054\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2073\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.2055\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2004\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.1993\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2018\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2160e-04 - val_loss: 0.2076\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2093\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0071 - val_loss: 0.2073\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2021\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4731e-05 - val_loss: 0.2009\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5125e-04 - val_loss: 0.2042\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8919e-04 - val_loss: 0.1980\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.1972\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 0.2000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2059\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2078\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.2061\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2010\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2025\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5488e-04 - val_loss: 0.2013\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.4892e-04 - val_loss: 0.2036\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2023\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.2849e-05 - val_loss: 0.1977\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.1970\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.1998\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2057\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2077\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.2060\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2010\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2025\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9293e-04 - val_loss: 0.2014\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.7155e-04 - val_loss: 0.2038\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2025\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2212e-04 - val_loss: 0.1979\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - val_loss: 0.1972\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.2000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2060\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2079\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.2062\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2013\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.3797e-04 - val_loss: 0.2003\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2028\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6694e-04 - val_loss: 0.2017\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8274e-04 - val_loss: 0.2041\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2071e-04 - val_loss: 0.1982\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.1976\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.2004\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2063\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2082\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.2066\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.2017\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0219e-04 - val_loss: 0.2007\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.9966e-04 - val_loss: 0.2021\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4213e-04 - val_loss: 0.2044\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2032\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5889e-04 - val_loss: 0.1986\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.1980\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2007\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2066\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.2086\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.2069\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.2021\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5314e-04 - val_loss: 0.2011\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2024\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0520e-04 - val_loss: 0.1980\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.1974\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2003\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2063\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2083\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - val_loss: 0.2067\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - val_loss: 0.2019\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4398e-04 - val_loss: 0.2010\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0381e-05 - val_loss: 0.1981\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.1975\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:08:08,226] Trial 59 finished with value: 0.00482998788356781 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1437 - val_loss: 0.3066\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0921 - val_loss: 0.2572\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0497 - val_loss: 0.2229\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0183 - val_loss: 0.1941\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0095 - val_loss: 0.1846\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0184 - val_loss: 0.1845\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0183 - val_loss: 0.1898\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0133 - val_loss: 0.1985\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.2087\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.2080\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0050 - val_loss: 0.2007\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2009\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2063\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2066\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2028\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.0765e-04 - val_loss: 0.2051\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2021\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5538e-04 - val_loss: 0.2045\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.3682e-04 - val_loss: 0.2042\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2019\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5433e-04 - val_loss: 0.2052\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2039\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.1989\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.1982\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2013\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2062\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2050\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2011\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2008\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2032\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6718e-05 - val_loss: 0.2079\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2096\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.2086\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.2051\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.1987\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - val_loss: 0.1982\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - val_loss: 0.1988\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.2016\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2063\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2084\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.2082\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.2057\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.1999\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2005\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2031\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.5710e-05 - val_loss: 0.2034\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0276e-04 - val_loss: 0.2017\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2022\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.5509e-04 - val_loss: 0.2045\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2047\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2030\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.6964e-05 - val_loss: 0.2033\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.6308e-04 - val_loss: 0.2017\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2022\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.7211e-04 - val_loss: 0.2045\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4300e-05 - val_loss: 0.2033\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.9403e-04 - val_loss: 0.2018\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2023\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.8169e-04 - val_loss: 0.2045\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2047\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.9563e-05 - val_loss: 0.1998\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.1986\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - val_loss: 0.1995\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.2020\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2061\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2080\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2079\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 0.2060\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.2026\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7943e-04 - val_loss: 0.2013\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2019\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2042\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2030\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4534e-05 - val_loss: 0.2034\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3809e-04 - val_loss: 0.2021\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1145e-04 - val_loss: 0.2048\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.2050\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3587e-04 - val_loss: 0.2004\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1994\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2002\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2027\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.3906e-04 - val_loss: 0.2066\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2084\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.2083\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 0.2065\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2033\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5172e-04 - val_loss: 0.1986\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.1961\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0070 - val_loss: 0.1956\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0075 - val_loss: 0.1968\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - val_loss: 0.1997\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2039\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1226e-04 - val_loss: 0.2060\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2063\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2048\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2018\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2016\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2040\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.3093e-04 - val_loss: 0.2044\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.0591e-05 - val_loss: 0.2004\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1995\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2005\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2029\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8756e-04 - val_loss: 0.2068\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2086\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.2087\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.2071\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2040\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5476e-04 - val_loss: 0.1996\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.1973\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - val_loss: 0.1970\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.1986\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.2017\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2063\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2087\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - val_loss: 0.2091\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - val_loss: 0.2077\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.2047\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2003\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.1981\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - val_loss: 0.1978\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.1993\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2024\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9688e-04 - val_loss: 0.2068\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2091\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0059 - val_loss: 0.2094\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0063 - val_loss: 0.2081\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - val_loss: 0.2052\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2010\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.1988\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.1985\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.2000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2030\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4861e-04 - val_loss: 0.2073\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.2096\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0064 - val_loss: 0.2099\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.2086\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0055 - val_loss: 0.2058\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2017\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.1996\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.1993\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2008\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2037\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6410e-04 - val_loss: 0.2047\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.3843e-04 - val_loss: 0.2017\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2013\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2025\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1248e-04 - val_loss: 0.2053\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2061\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2053\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2029\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2680e-04 - val_loss: 0.2024\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4466e-04 - val_loss: 0.2036\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0890e-04 - val_loss: 0.2030\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6870e-04 - val_loss: 0.2041\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2632e-04 - val_loss: 0.2034\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0047e-04 - val_loss: 0.2013\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2022\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.0729e-04 - val_loss: 0.2050\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2059\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2051\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1559e-04 - val_loss: 0.2024\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8933e-04 - val_loss: 0.2035\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9263e-04 - val_loss: 0.2030\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4848e-04 - val_loss: 0.2041\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.6877e-04 - val_loss: 0.2035\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7332e-04 - val_loss: 0.2014\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2011\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2024\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6210e-04 - val_loss: 0.2052\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2061\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2053\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2030\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1453e-04 - val_loss: 0.2026\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7426e-04 - val_loss: 0.2038\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1181e-04 - val_loss: 0.2032\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.2850e-05 - val_loss: 0.2012\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2009\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.2023\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9148e-04 - val_loss: 0.2051\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2060\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2053\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2030\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9152e-05 - val_loss: 0.2026\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2924e-04 - val_loss: 0.2038\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7759e-04 - val_loss: 0.2033\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7327e-04 - val_loss: 0.2013\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:08:26,379] Trial 60 finished with value: 0.001874387264251709 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1516 - val_loss: 0.3602\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1618 - val_loss: 0.3572\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1537 - val_loss: 0.3496\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1456 - val_loss: 0.3403\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1351 - val_loss: 0.3190\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1141 - val_loss: 0.2983\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0933 - val_loss: 0.2786\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0739 - val_loss: 0.2609\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0566 - val_loss: 0.2453\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0411 - val_loss: 0.2321\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0280 - val_loss: 0.2192\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0151 - val_loss: 0.2058\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.1920\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0117 - val_loss: 0.1838\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0198 - val_loss: 0.1800\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0235 - val_loss: 0.1800\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0235 - val_loss: 0.1830\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0205 - val_loss: 0.1887\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0147 - val_loss: 0.1966\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0068 - val_loss: 0.2063\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2119\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - val_loss: 0.2140\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - val_loss: 0.2135\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0101 - val_loss: 0.2106\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0072 - val_loss: 0.2059\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - val_loss: 0.1995\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.1961\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0072 - val_loss: 0.1952\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0081 - val_loss: 0.1965\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0068 - val_loss: 0.1997\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0036 - val_loss: 0.2045\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2067\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - val_loss: 0.2069\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.2052\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.2018\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2006\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - val_loss: 0.2014\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.7383e-04 - val_loss: 0.2043\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.5363e-04 - val_loss: 0.2034\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7132e-04 - val_loss: 0.2022\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.9264e-04 - val_loss: 0.2028\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.9683e-04 - val_loss: 0.2050\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2053\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.5039e-04 - val_loss: 0.2010\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - val_loss: 0.2000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - val_loss: 0.2008\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.2032\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.5548e-05 - val_loss: 0.2037\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9012e-04 - val_loss: 0.2025\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.1527e-04 - val_loss: 0.2031\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.9846e-05 - val_loss: 0.2053\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2056\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - val_loss: 0.2042\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2014\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2004\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2012\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.4890e-04 - val_loss: 0.2041\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.4275e-04 - val_loss: 0.2029\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.3015e-04 - val_loss: 0.2035\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.3355e-04 - val_loss: 0.2024\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.7401e-04 - val_loss: 0.2030\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.5409e-04 - val_loss: 0.2051\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2055\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2042\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2014\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2006\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - val_loss: 0.2014\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0244e-04 - val_loss: 0.2042\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5363e-05 - val_loss: 0.2037\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5860e-04 - val_loss: 0.2026\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1036e-04 - val_loss: 0.2032\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1539e-04 - val_loss: 0.2022\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.0599e-04 - val_loss: 0.2029\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3851e-04 - val_loss: 0.2051\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2055\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2042\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2007\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2016\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2039\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8197e-04 - val_loss: 0.2044\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2197e-04 - val_loss: 0.2008\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2001\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2010\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2034\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.9010e-04 - val_loss: 0.2040\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.8952e-04 - val_loss: 0.2030\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2450e-04 - val_loss: 0.2036\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1852e-04 - val_loss: 0.2027\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5539e-04 - val_loss: 0.2033\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2271e-04 - val_loss: 0.2024\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1859e-04 - val_loss: 0.2031\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2144e-05 - val_loss: 0.2053\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2057\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2046\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2012\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2044\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.2762e-04 - val_loss: 0.2014\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2016\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2040\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.5622e-04 - val_loss: 0.2046\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7116e-04 - val_loss: 0.2012\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2005\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2015\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2039\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.7152e-04 - val_loss: 0.2045\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5116e-04 - val_loss: 0.2012\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2006\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2016\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4035e-04 - val_loss: 0.2046\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5459e-04 - val_loss: 0.2013\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2017\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2041\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.8877e-04 - val_loss: 0.2048\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.2165e-04 - val_loss: 0.2015\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2019\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2043\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.2064e-04 - val_loss: 0.2017\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.8841e-04 - val_loss: 0.2045\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2043\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.5798e-04 - val_loss: 0.2047\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2054\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2045\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.2487e-04 - val_loss: 0.2016\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2352e-04 - val_loss: 0.2049\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2056\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2047\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2024\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.8778e-04 - val_loss: 0.2019\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2028\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.8817e-04 - val_loss: 0.2052\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2058\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2049\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2027\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5106e-04 - val_loss: 0.2021\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2031\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3778e-05 - val_loss: 0.2054\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2060\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2051\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1592e-04 - val_loss: 0.2023\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7693e-04 - val_loss: 0.2033\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7875e-04 - val_loss: 0.2027\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1789e-04 - val_loss: 0.2036\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0162e-04 - val_loss: 0.2030\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2374e-04 - val_loss: 0.2039\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6652e-04 - val_loss: 0.2032\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1805e-04 - val_loss: 0.2012\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2008\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - val_loss: 0.2019\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2052\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2023\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.1615e-04 - val_loss: 0.2018\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3825e-04 - val_loss: 0.2052\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2059\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2051\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2030\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2518e-04 - val_loss: 0.2025\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.2673e-04 - val_loss: 0.2035\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6122e-04 - val_loss: 0.2029\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8521e-04 - val_loss: 0.2039\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.5801e-04 - val_loss: 0.2033\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7543e-04 - val_loss: 0.2013\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2010\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2022\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.5956e-04 - val_loss: 0.2046\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2054\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2047\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:08:45,011] Trial 61 finished with value: 0.0015813857316970825 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1391 - val_loss: 0.3162\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1028 - val_loss: 0.2404\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0353 - val_loss: 0.1821\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0235 - val_loss: 0.1676\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0347 - val_loss: 0.1740\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0270 - val_loss: 0.1895\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0112 - val_loss: 0.2088\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0085 - val_loss: 0.2169\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0162 - val_loss: 0.2170\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0158 - val_loss: 0.2119\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0103 - val_loss: 0.2032\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.1920\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0102 - val_loss: 0.1865\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0157 - val_loss: 0.1856\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0168 - val_loss: 0.1881\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0144 - val_loss: 0.1935\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - val_loss: 0.2011\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2104\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0074 - val_loss: 0.2157\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0126 - val_loss: 0.2178\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0146 - val_loss: 0.2171\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0139 - val_loss: 0.2141\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0108 - val_loss: 0.2091\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - val_loss: 0.2023\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 0.1985\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.1975\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - val_loss: 0.1989\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.2024\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2076\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2101\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0067 - val_loss: 0.2102\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - val_loss: 0.2082\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - val_loss: 0.2043\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.8818e-04 - val_loss: 0.1987\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.1958\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0076 - val_loss: 0.1953\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0081 - val_loss: 0.1969\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0065 - val_loss: 0.2004\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2055\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2081\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - val_loss: 0.2084\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 0.2067\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2032\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6019e-04 - val_loss: 0.2020\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2029\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0245e-04 - val_loss: 0.2058\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2063\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - val_loss: 0.2048\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2016\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2006\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2017\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.8029e-04 - val_loss: 0.2008\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.1999\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2011\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - val_loss: 0.2040\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.7249e-04 - val_loss: 0.2047\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 4.8354e-05 - val_loss: 0.2004\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.1996\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.2008\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2038\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2011e-04 - val_loss: 0.2045\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3755e-04 - val_loss: 0.2041\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6715e-04 - val_loss: 0.2029\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0581e-04 - val_loss: 0.2038\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.3559e-04 - val_loss: 0.2026\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0207e-04 - val_loss: 0.2035\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.8948e-05 - val_loss: 0.2024\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2033\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4544e-04 - val_loss: 0.2060\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2065\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2051\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2019\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2010\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - val_loss: 0.2020\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2049\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2055\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.0860e-04 - val_loss: 0.2012\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2003\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.2014\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2043\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.9534e-04 - val_loss: 0.2050\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7585e-04 - val_loss: 0.2008\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2011\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2040\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.3011e-04 - val_loss: 0.2048\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.7388e-04 - val_loss: 0.2006\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.1998\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2010\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1369e-04 - val_loss: 0.2047\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.1240e-05 - val_loss: 0.2006\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.1998\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2010\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7378e-04 - val_loss: 0.2046\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.9797e-05 - val_loss: 0.2005\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.1998\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2010\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7281e-04 - val_loss: 0.2046\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9423e-05 - val_loss: 0.2006\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1998\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2010\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9166e-04 - val_loss: 0.2046\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2035\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0487e-04 - val_loss: 0.2006\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.1999\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2010\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2071e-04 - val_loss: 0.2046\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3864e-04 - val_loss: 0.2006\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.1999\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2011\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5563e-04 - val_loss: 0.2046\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7740e-04 - val_loss: 0.2007\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.2011\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9463e-04 - val_loss: 0.2047\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.1988e-04 - val_loss: 0.2007\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.2011\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2040\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.3717e-04 - val_loss: 0.2047\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.6585e-04 - val_loss: 0.2008\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - val_loss: 0.2001\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2012\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2040\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8337e-04 - val_loss: 0.2047\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.1555e-04 - val_loss: 0.2008\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2001\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2013\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3363e-04 - val_loss: 0.2048\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6927e-04 - val_loss: 0.2009\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2002\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2013\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.8818e-04 - val_loss: 0.2048\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.2737e-04 - val_loss: 0.2010\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2003\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2014\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4743e-04 - val_loss: 0.2049\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9008e-04 - val_loss: 0.2010\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2003\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2014\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2042\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.1143e-04 - val_loss: 0.2049\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5744e-04 - val_loss: 0.2011\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2004\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.2015\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.8018e-04 - val_loss: 0.2050\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2039\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2947e-04 - val_loss: 0.2012\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0611e-04 - val_loss: 0.2013\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.2006\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2017\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.8711e-04 - val_loss: 0.2014\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2007\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2018\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2052\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.7221e-04 - val_loss: 0.2014\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2008\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - val_loss: 0.2018\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2045\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:09:03,189] Trial 62 finished with value: 0.0013002604246139526 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1642 - val_loss: 0.2831\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0689 - val_loss: 0.1953\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0100 - val_loss: 0.1963\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2296\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0368 - val_loss: 0.2287\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0339 - val_loss: 0.2110\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0141 - val_loss: 0.1848\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0141 - val_loss: 0.1760\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0239 - val_loss: 0.1788\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0213 - val_loss: 0.1894\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0105 - val_loss: 0.2054\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.2118\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0127 - val_loss: 0.2112\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0120 - val_loss: 0.2053\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.1950\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 0.1913\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0092 - val_loss: 0.1931\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0076 - val_loss: 0.1992\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2087\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.2127\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0122 - val_loss: 0.2124\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0117 - val_loss: 0.2082\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.2009\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5683e-04 - val_loss: 0.1981\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.1993\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2039\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2044\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2016\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4336e-04 - val_loss: 0.1957\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1938\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0078 - val_loss: 0.1954\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.2001\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2073\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.2106\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0090 - val_loss: 0.2106\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0089 - val_loss: 0.2075\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.2018\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5928e-06 - val_loss: 0.1997\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2052\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2028\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7088e-04 - val_loss: 0.1978\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.1962\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0058 - val_loss: 0.1976\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2017\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0974e-04 - val_loss: 0.2082\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.2112\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0092 - val_loss: 0.2111\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0091 - val_loss: 0.2083\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0063 - val_loss: 0.2031\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.1957\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0065 - val_loss: 0.1918\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0104 - val_loss: 0.1910\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0112 - val_loss: 0.1930\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0092 - val_loss: 0.1975\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0047 - val_loss: 0.2041\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2074\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - val_loss: 0.2078\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - val_loss: 0.2057\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2012\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.1997\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2009\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2045\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2034\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.1993\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.1980\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.1994\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2032\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0422e-04 - val_loss: 0.2041\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2024\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2219e-04 - val_loss: 0.1985\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.1974\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.1989\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2027\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4632e-04 - val_loss: 0.2036\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5646e-04 - val_loss: 0.2031\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6629e-04 - val_loss: 0.2016\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3725e-04 - val_loss: 0.2027\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3464e-04 - val_loss: 0.2012\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0615e-06 - val_loss: 0.2057\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2064\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2046\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2006\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.1994\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2008\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2043\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2052\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2035\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.1997\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.1987\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2001\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2037\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2031\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4898e-04 - val_loss: 0.1994\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.1984\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.1999\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - val_loss: 0.2036\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.8714e-04 - val_loss: 0.1994\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.1985\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2037\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2047\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2032\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.1500e-04 - val_loss: 0.1996\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.1987\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - val_loss: 0.2002\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2035\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.1999\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.1990\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.2005\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2052\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2038\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2003\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.1994\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2009\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2045\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2055\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2041\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2006\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.1997\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.2012\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2048\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2058\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2044\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2010\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2001\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2016\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.3120e-04 - val_loss: 0.2052\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2061\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2048\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2013\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2005\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2020\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.7928e-04 - val_loss: 0.2055\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2065\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2051\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2017\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2983e-04 - val_loss: 0.2009\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2584e-04 - val_loss: 0.2059\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2068\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2055\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2021\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7322e-04 - val_loss: 0.2012\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2755e-04 - val_loss: 0.2018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8136e-04 - val_loss: 0.2032\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1955e-04 - val_loss: 0.2022\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3276e-04 - val_loss: 0.2036\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6225e-05 - val_loss: 0.1995\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.1989\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2007\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2056\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2044\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2005\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2021\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9824e-04 - val_loss: 0.2057\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2068\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2055\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2023\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1959e-04 - val_loss: 0.2015\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2458e-04 - val_loss: 0.2022\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0567e-04 - val_loss: 0.2036\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2028\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4699e-04 - val_loss: 0.1998\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1993\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2010\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2048\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2060\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2049\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2018\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3365e-04 - val_loss: 0.2011\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2027\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0830e-04 - val_loss: 0.2020\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2940e-04 - val_loss: 0.2035\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.7577e-04 - val_loss: 0.2027\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7085e-05 - val_loss: 0.1998\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1994\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2012\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2062\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2051\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.2021\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.7872e-04 - val_loss: 0.2014\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1188e-04 - val_loss: 0.2023\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:09:17,375] Trial 63 finished with value: 0.00029571354389190674 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1290 - val_loss: 0.2697\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0406 - val_loss: 0.1611\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0538 - val_loss: 0.1856\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0084 - val_loss: 0.2494\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0541 - val_loss: 0.2582\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0594 - val_loss: 0.2409\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0407 - val_loss: 0.2127\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0125 - val_loss: 0.1790\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0230 - val_loss: 0.1636\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0374 - val_loss: 0.1629\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0375 - val_loss: 0.1729\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0280 - val_loss: 0.1896\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0119 - val_loss: 0.2108\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.2211\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0189 - val_loss: 0.2232\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0208 - val_loss: 0.2187\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0161 - val_loss: 0.2090\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.1951\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0078 - val_loss: 0.1885\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0146 - val_loss: 0.1878\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0153 - val_loss: 0.1921\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 0.2006\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2127\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0096 - val_loss: 0.2187\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0157 - val_loss: 0.2196\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0166 - val_loss: 0.2162\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0132 - val_loss: 0.2090\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.1985\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.1933\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0098 - val_loss: 0.1928\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0104 - val_loss: 0.1962\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.2032\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1870e-05 - val_loss: 0.2055\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6379e-04 - val_loss: 0.1987\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.1978\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0054 - val_loss: 0.2006\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2068\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2087\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.2068\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2017\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2006\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2032\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4969e-06 - val_loss: 0.2089\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.2106\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0075 - val_loss: 0.2087\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.2036\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2622e-04 - val_loss: 0.1955\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0077 - val_loss: 0.1917\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0115 - val_loss: 0.1918\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0114 - val_loss: 0.1953\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - val_loss: 0.2018\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2110\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0078 - val_loss: 0.2159\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0127 - val_loss: 0.2169\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0138 - val_loss: 0.2146\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0115 - val_loss: 0.2093\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.2011\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.1971\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.1969\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.1999\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2059\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2080\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.2066\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2022\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.5317e-04 - val_loss: 0.2015\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.5589e-04 - val_loss: 0.2031\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.3345e-05 - val_loss: 0.2055\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2003\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.1998\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.2025\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9663e-04 - val_loss: 0.2081\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2100\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0068 - val_loss: 0.2085\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.2040\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7032e-04 - val_loss: 0.1968\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.1935\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0097 - val_loss: 0.1938\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0094 - val_loss: 0.1971\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.2033\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4573e-04 - val_loss: 0.2057\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2048\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2003\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2030\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6126e-04 - val_loss: 0.2086\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.2105\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0073 - val_loss: 0.2091\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0059 - val_loss: 0.2047\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.1976\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.1944\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0088 - val_loss: 0.1947\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 0.1980\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.2041\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.1757e-04 - val_loss: 0.2065\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2055\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2016\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2012\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2038\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6753e-04 - val_loss: 0.2032\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4587e-06 - val_loss: 0.1995\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.1993\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2021\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2078\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.2098\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.2086\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.2044\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.1976\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0055 - val_loss: 0.1946\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0086 - val_loss: 0.1949\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.1983\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2043\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2067\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2059\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2021\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2017\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8123e-04 - val_loss: 0.2002\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2028\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2845e-04 - val_loss: 0.2084\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.2104\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0073 - val_loss: 0.2092\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.2052\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.1985\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.1955\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0077 - val_loss: 0.1958\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0073 - val_loss: 0.1992\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2051\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2075\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.2067\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2029\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3197e-04 - val_loss: 0.2025\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.0950e-04 - val_loss: 0.2052\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2046\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2011\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2009\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2037\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4595e-04 - val_loss: 0.2033\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0481e-04 - val_loss: 0.1999\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.1998\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2028\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9607e-04 - val_loss: 0.2083\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.2104\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - val_loss: 0.2093\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.2054\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.1989\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - val_loss: 0.1961\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0071 - val_loss: 0.1964\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - val_loss: 0.1997\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.2056\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2080\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2072\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.2036\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3890e-04 - val_loss: 0.1974\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - val_loss: 0.1947\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - val_loss: 0.1953\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0079 - val_loss: 0.1987\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2048\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2072\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2066\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2031\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3315e-05 - val_loss: 0.2028\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0565e-04 - val_loss: 0.2055\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2050\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2017\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2016\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2041\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.1691e-04 - val_loss: 0.2008\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2008\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2037\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.8766e-04 - val_loss: 0.2034\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0115e-04 - val_loss: 0.2003\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2004\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2033\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5993e-04 - val_loss: 0.2031\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5847e-05 - val_loss: 0.2057\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2053\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2020\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2047\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2043\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2011\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2011\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3323e-04 - val_loss: 0.2037\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4936e-04 - val_loss: 0.2006\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2006\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2036\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1154e-04 - val_loss: 0.2033\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7732e-04 - val_loss: 0.2002\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2003\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2033\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5967e-04 - val_loss: 0.2031\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1977e-05 - val_loss: 0.2058\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:09:36,575] Trial 64 finished with value: 0.002192869782447815 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.1366 - val_loss: 0.3055\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0870 - val_loss: 0.2119\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0120 - val_loss: 0.1665\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0335 - val_loss: 0.1650\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0260 - val_loss: 0.2069\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0225 - val_loss: 0.2062\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0167 - val_loss: 0.1811\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0143 - val_loss: 0.1750\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0208 - val_loss: 0.1826\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0132 - val_loss: 0.2002\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2052\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0088 - val_loss: 0.2000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.1867\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0108 - val_loss: 0.1834\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0143 - val_loss: 0.1885\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0093 - val_loss: 0.2003\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - val_loss: 0.1998\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.1899\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0089 - val_loss: 0.1874\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0115 - val_loss: 0.1915\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0075 - val_loss: 0.2010\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2037\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2004\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.1920\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0076 - val_loss: 0.1899\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0098 - val_loss: 0.1934\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.2017\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2011\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.1936\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0067 - val_loss: 0.1917\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0087 - val_loss: 0.1948\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0056 - val_loss: 0.2023\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2044\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2017\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.1948\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.1930\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0078 - val_loss: 0.1959\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2029\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2049\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2023\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.1958\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.1941\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.1968\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2034\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2053\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2029\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.1966\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.1950\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.1976\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2039\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2057\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.2034\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.1973\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1958\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.1983\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2044\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2061\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2038\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.1980\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.1965\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - val_loss: 0.1989\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2049\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.2065\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - val_loss: 0.2043\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.1986\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.1972\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.1995\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2053\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2069\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.2047\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.1992\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1978\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.2001\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2057\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2073\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.2051\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.1997\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.1983\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2006\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2061\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2076\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0055 - val_loss: 0.2055\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2002\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.1988\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2011\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2065\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.2080\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.2059\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2007\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.1993\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2015\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9191e-04 - val_loss: 0.2069\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.2083\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.2063\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2011\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.1998\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2020\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1848e-04 - val_loss: 0.2073\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - val_loss: 0.2087\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.2067\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2016\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.8057e-04 - val_loss: 0.2003\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2024\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3838e-05 - val_loss: 0.2076\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.2090\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - val_loss: 0.2070\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.2020\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1464e-04 - val_loss: 0.2007\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0302e-04 - val_loss: 0.2015\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7117e-04 - val_loss: 0.2021\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5574e-04 - val_loss: 0.2041\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4957e-05 - val_loss: 0.1980\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.1972\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.1996\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2051\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2068\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.2051\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2004\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.1993\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2016\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 9.8540e-04 - val_loss: 0.2069\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.2084\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.2066\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2018\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2004e-04 - val_loss: 0.2007\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2028\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0126e-04 - val_loss: 0.2016\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2037\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7765e-04 - val_loss: 0.2044\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2030\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4159e-04 - val_loss: 0.1986\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.1978\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2003\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2056\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2073\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2057\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2011\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2001\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2024\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1751e-04 - val_loss: 0.2075\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.2090\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.2073\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.2026\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.8215e-05 - val_loss: 0.2015\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.3600e-04 - val_loss: 0.2025\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6008e-04 - val_loss: 0.2045\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2032\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9832e-04 - val_loss: 0.1990\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.1983\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2007\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2060\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2077\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.2062\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2017\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2008\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2030\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4822e-04 - val_loss: 0.2020\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.1863e-04 - val_loss: 0.2041\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2749e-04 - val_loss: 0.1988\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.1982\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2007\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - val_loss: 0.2060\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2077\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - val_loss: 0.2062\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2019\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.5025e-04 - val_loss: 0.2010\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2032\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9352e-04 - val_loss: 0.2022\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.2868e-04 - val_loss: 0.2043\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2032\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6180e-04 - val_loss: 0.1991\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.1985\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2010\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2063\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2080\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.2065\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.2023\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8164e-04 - val_loss: 0.2014\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.6869e-04 - val_loss: 0.2026\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3329e-04 - val_loss: 0.2047\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6161e-04 - val_loss: 0.1996\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.1990\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2015\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2067\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2084\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.2070\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2027\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3843e-04 - val_loss: 0.2019\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2041\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:09:56,466] Trial 65 finished with value: 0.0002145618200302124 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.1703 - val_loss: 0.3576\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1536 - val_loss: 0.2940\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0858 - val_loss: 0.2546\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0495 - val_loss: 0.2192\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0171 - val_loss: 0.1917\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0095 - val_loss: 0.1821\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0187 - val_loss: 0.1815\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0192 - val_loss: 0.1858\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0147 - val_loss: 0.1935\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0069 - val_loss: 0.2035\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2082\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0079 - val_loss: 0.2090\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 0.2066\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0060 - val_loss: 0.2019\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.1955\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.1923\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0097 - val_loss: 0.1917\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0096 - val_loss: 0.1931\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0081 - val_loss: 0.1964\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.2013\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8771e-04 - val_loss: 0.2037\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2040\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2025\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.1993\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.1982\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.1991\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2016\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2456e-04 - val_loss: 0.2021\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9994e-04 - val_loss: 0.2008\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.3132e-04 - val_loss: 0.2014\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7460e-04 - val_loss: 0.2036\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2039\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2025\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6533e-04 - val_loss: 0.1995\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.1986\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.1994\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2017\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7658e-05 - val_loss: 0.2022\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8496e-04 - val_loss: 0.2010\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6126e-04 - val_loss: 0.2015\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1911e-04 - val_loss: 0.2036\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2039\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2026\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.9337e-04 - val_loss: 0.1997\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.1988\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.1996\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2019\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1668e-05 - val_loss: 0.2023\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6645e-04 - val_loss: 0.2012\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3861e-04 - val_loss: 0.2017\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1063e-04 - val_loss: 0.2037\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2027\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.7498e-04 - val_loss: 0.1999\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.1990\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.1998\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2020\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6911e-05 - val_loss: 0.2025\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7365e-04 - val_loss: 0.2013\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0481e-04 - val_loss: 0.2018\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8573e-04 - val_loss: 0.2039\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2028\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.8465e-04 - val_loss: 0.2001\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.1992\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.1999\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2022\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3524e-05 - val_loss: 0.2026\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0589e-04 - val_loss: 0.2015\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5260e-04 - val_loss: 0.2020\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3874e-04 - val_loss: 0.2040\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2030\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2393e-04 - val_loss: 0.2003\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.1994\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.2001\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2023\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2560e-04 - val_loss: 0.2028\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6531e-04 - val_loss: 0.2016\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7730e-04 - val_loss: 0.2021\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6966e-05 - val_loss: 0.2041\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9103e-04 - val_loss: 0.2005\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.1996\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2003\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2025\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1142e-04 - val_loss: 0.2029\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4915e-04 - val_loss: 0.2018\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8046e-04 - val_loss: 0.2023\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7061e-05 - val_loss: 0.2013\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2018\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7451e-04 - val_loss: 0.2038\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2029\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1755e-04 - val_loss: 0.2003\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.1995\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2002\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2024\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.2046e-05 - val_loss: 0.2029\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4225e-04 - val_loss: 0.2018\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5401e-04 - val_loss: 0.2023\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9385e-05 - val_loss: 0.2043\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2046\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2033\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6940e-04 - val_loss: 0.2007\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.1999\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2006\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6180e-04 - val_loss: 0.2032\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0436e-04 - val_loss: 0.2021\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9704e-04 - val_loss: 0.2026\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1233e-04 - val_loss: 0.2016\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.2847e-04 - val_loss: 0.2022\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6505e-04 - val_loss: 0.2042\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2045\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2033\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.3090e-04 - val_loss: 0.2007\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.1999\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2006\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2654e-04 - val_loss: 0.2032\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.8501e-04 - val_loss: 0.2022\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9200e-04 - val_loss: 0.2027\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2937e-04 - val_loss: 0.2017\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9080e-04 - val_loss: 0.2023\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1856e-04 - val_loss: 0.2043\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2034\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.0100e-04 - val_loss: 0.2008\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2008\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2978e-04 - val_loss: 0.2034\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.9124e-04 - val_loss: 0.2023\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7409e-04 - val_loss: 0.2029\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4887e-04 - val_loss: 0.2019\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6103e-04 - val_loss: 0.2024\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.8319e-05 - val_loss: 0.2044\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2047\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2036\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2010\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2002\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2010\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2031\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7565e-04 - val_loss: 0.2036\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2025\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1115e-05 - val_loss: 0.2031\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0053e-04 - val_loss: 0.2021\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0239e-04 - val_loss: 0.2026\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8530e-05 - val_loss: 0.2017\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.9006e-04 - val_loss: 0.2023\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7931e-04 - val_loss: 0.2043\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2047\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2035\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.3760e-04 - val_loss: 0.2010\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2002\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2010\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7551e-04 - val_loss: 0.2036\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6034e-05 - val_loss: 0.2002\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.1995\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2004\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2026\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0466e-06 - val_loss: 0.2032\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5113e-04 - val_loss: 0.2022\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2140e-04 - val_loss: 0.2028\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6572e-04 - val_loss: 0.2019\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6707e-04 - val_loss: 0.2025\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4438e-04 - val_loss: 0.2045\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2037\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2013\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2005\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2013\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8301e-04 - val_loss: 0.2039\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4208e-04 - val_loss: 0.2005\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.1998\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2007\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5523e-04 - val_loss: 0.2035\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9805e-04 - val_loss: 0.2025\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6308e-04 - val_loss: 0.2031\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2260e-04 - val_loss: 0.2022\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9973e-04 - val_loss: 0.2028\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2065e-04 - val_loss: 0.2019\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7033e-04 - val_loss: 0.2026\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2188e-04 - val_loss: 0.2046\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2050\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2039\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2007\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2015\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.4339e-04 - val_loss: 0.2041\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2031\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.3212e-04 - val_loss: 0.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:10:15,495] Trial 66 finished with value: 0.0019134432077407837 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1237 - val_loss: 0.1643\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0947 - val_loss: 0.1616\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0535 - val_loss: 0.2257\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0238 - val_loss: 0.2412\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0369 - val_loss: 0.2281\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0225 - val_loss: 0.1999\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0063 - val_loss: 0.1914\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0136 - val_loss: 0.1975\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0066 - val_loss: 0.2136\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0101 - val_loss: 0.2178\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0144 - val_loss: 0.2127\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - val_loss: 0.2004\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.1972\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.2017\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2123\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0090 - val_loss: 0.2152\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0119 - val_loss: 0.2117\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0084 - val_loss: 0.2028\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7351e-04 - val_loss: 0.2007\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - val_loss: 0.2043\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.6864e-04 - val_loss: 0.2022\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2056\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2037\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9246e-04 - val_loss: 0.1971\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0065 - val_loss: 0.1961\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - val_loss: 0.2000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.2081\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - val_loss: 0.2107\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0067 - val_loss: 0.2085\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.2021\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2008\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.2040\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.5965e-05 - val_loss: 0.2026\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2056\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.9748e-05 - val_loss: 0.1985\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0054 - val_loss: 0.1977\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0062 - val_loss: 0.2011\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2082\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0042 - val_loss: 0.2105\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - val_loss: 0.2086\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2030\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.3201e-04 - val_loss: 0.2019\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.8304e-04 - val_loss: 0.2036\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3790e-04 - val_loss: 0.2063\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2050\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.1993\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2024\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2090\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.2111\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0073 - val_loss: 0.2094\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0056 - val_loss: 0.2043\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6131e-04 - val_loss: 0.1960\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0078 - val_loss: 0.1922\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0116 - val_loss: 0.1925\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0113 - val_loss: 0.1964\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.2034\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5921e-04 - val_loss: 0.2132\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0093 - val_loss: 0.2184\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0145 - val_loss: 0.2197\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0159 - val_loss: 0.2176\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0138 - val_loss: 0.2125\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0087 - val_loss: 0.2046\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1007e-04 - val_loss: 0.1942\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0096 - val_loss: 0.1881\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0156 - val_loss: 0.1861\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0176 - val_loss: 0.1876\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0161 - val_loss: 0.1923\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0114 - val_loss: 0.1996\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2091\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.2146\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0107 - val_loss: 0.2164\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0126 - val_loss: 0.2152\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0114 - val_loss: 0.2113\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0075 - val_loss: 0.2049\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.1961\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0077 - val_loss: 0.1912\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0126 - val_loss: 0.1897\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0140 - val_loss: 0.1914\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0124 - val_loss: 0.1957\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0080 - val_loss: 0.2025\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2112\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0074 - val_loss: 0.2163\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0125 - val_loss: 0.2181\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0143 - val_loss: 0.2171\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0133 - val_loss: 0.2136\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0098 - val_loss: 0.2079\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.1999\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.1955\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - val_loss: 0.1942\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0095 - val_loss: 0.1958\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0080 - val_loss: 0.1998\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2060\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2090\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.2091\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - val_loss: 0.2066\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2019\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2002\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2012\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2046\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6990e-04 - val_loss: 0.2052\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4641e-04 - val_loss: 0.2039\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.6530e-04 - val_loss: 0.2020\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.5503e-04 - val_loss: 0.2061\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2065\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2044\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1652e-04 - val_loss: 0.2001\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.1986\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.1998\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2034\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1491e-04 - val_loss: 0.2090\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.2116\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0079 - val_loss: 0.2115\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0078 - val_loss: 0.2091\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0054 - val_loss: 0.2044\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.4413e-04 - val_loss: 0.1978\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.1943\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0093 - val_loss: 0.1936\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0100 - val_loss: 0.1954\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0082 - val_loss: 0.1994\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.2054\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2084\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.2088\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.2067\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2025\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2011\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2022\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2055\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2062\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2044\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.7341e-04 - val_loss: 0.2005\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.1994\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - val_loss: 0.2006\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2041\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.5542e-04 - val_loss: 0.2049\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1158e-04 - val_loss: 0.2042\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.6522e-04 - val_loss: 0.2027\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.2673e-04 - val_loss: 0.2036\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2100e-05 - val_loss: 0.2022\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3093e-04 - val_loss: 0.2063\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2069\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2052\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2013\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2002\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2031\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5086e-04 - val_loss: 0.2095\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.2113\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0079 - val_loss: 0.2093\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.2043\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.0072e-04 - val_loss: 0.1965\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.1930\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0104 - val_loss: 0.1929\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0105 - val_loss: 0.1959\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0075 - val_loss: 0.2014\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2091\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.2130\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0096 - val_loss: 0.2138\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0104 - val_loss: 0.2118\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.2074\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2009\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.1977\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.1974\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0060 - val_loss: 0.1997\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2041\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3851e-04 - val_loss: 0.2057\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2047\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2008\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2027\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3758e-04 - val_loss: 0.2067\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2080\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.2068\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2034\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0630e-05 - val_loss: 0.2027\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9049e-04 - val_loss: 0.2044\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.8577e-04 - val_loss: 0.2036\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.0688e-05 - val_loss: 0.2006\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2002\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2021\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2061\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2075\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2064\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2032\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0965e-04 - val_loss: 0.2026\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.3617e-04 - val_loss: 0.2043\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5994e-04 - val_loss: 0.2035\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4809e-05 - val_loss: 0.2006\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2003\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2022\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2062\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2075\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2065\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2034\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2235e-04 - val_loss: 0.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:10:34,307] Trial 67 finished with value: 0.0007132440805435181 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1676 - val_loss: 0.2239\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0120 - val_loss: 0.0995\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1112 - val_loss: 0.1111\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0860 - val_loss: 0.1657\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0264 - val_loss: 0.2403\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0451 - val_loss: 0.2514\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0546 - val_loss: 0.2483\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0505 - val_loss: 0.2373\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0387 - val_loss: 0.2235\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0227 - val_loss: 0.2094\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0081 - val_loss: 0.1931\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0081 - val_loss: 0.1842\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0171 - val_loss: 0.1810\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0204 - val_loss: 0.1823\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0193 - val_loss: 0.1867\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0152 - val_loss: 0.1933\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0088 - val_loss: 0.2018\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.0971e-04 - val_loss: 0.2117\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - val_loss: 0.2178\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0153 - val_loss: 0.2206\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0180 - val_loss: 0.2206\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0179 - val_loss: 0.2182\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0155 - val_loss: 0.2137\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0110 - val_loss: 0.2075\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.1996\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.1949\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0079 - val_loss: 0.1929\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0098 - val_loss: 0.1934\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0093 - val_loss: 0.1960\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0067 - val_loss: 0.2005\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2066\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - val_loss: 0.2099\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0071 - val_loss: 0.2108\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0080 - val_loss: 0.2096\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0068 - val_loss: 0.2065\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - val_loss: 0.2017\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.1993\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - val_loss: 0.1993\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2013\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - val_loss: 0.2065\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - val_loss: 0.2057\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.2031\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3615e-04 - val_loss: 0.1988\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - val_loss: 0.1968\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - val_loss: 0.1971\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - val_loss: 0.1993\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - val_loss: 0.2032\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.8061e-04 - val_loss: 0.2048\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2043\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.2019\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6144e-04 - val_loss: 0.2017\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.5309e-04 - val_loss: 0.2031\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8309e-04 - val_loss: 0.2008\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2007\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2025\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.4437e-04 - val_loss: 0.2061\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - val_loss: 0.2074\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - val_loss: 0.2067\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - val_loss: 0.2041\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.1998\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.1979\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.1981\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.2003\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2041\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2057\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.2051\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2027\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3712e-04 - val_loss: 0.2025\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7032e-04 - val_loss: 0.2042\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5537e-04 - val_loss: 0.2016\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2015\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0883e-04 - val_loss: 0.2030\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3101e-04 - val_loss: 0.2008\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2008\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2027\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7388e-04 - val_loss: 0.2063\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2076\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - val_loss: 0.2070\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2044\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2002\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.1984\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.1986\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.2008\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2046\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2062\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2057\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2033\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5601e-04 - val_loss: 0.1993\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.1976\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - val_loss: 0.1980\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0049 - val_loss: 0.2002\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2042\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2058\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2054\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2031\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2438e-04 - val_loss: 0.1992\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.1975\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.1979\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 0.2002\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2042\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2059\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2055\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2033\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6915e-04 - val_loss: 0.1994\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.1977\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.1982\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2005\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2045\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2061\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2058\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2036\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.7656e-04 - val_loss: 0.1997\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.1981\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.1986\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2009\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2048\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2065\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2061\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2040\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2001\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1985\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.1990\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2013\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2052\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2069\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2065\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0036 - val_loss: 0.2044\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2006\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - val_loss: 0.1990\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.1995\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2017\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2056\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2073\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2069\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2048\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2010\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.1995\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.1999\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2022\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.2734e-04 - val_loss: 0.2061\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2077\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2074\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2052\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2015\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.1999\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2004\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2026\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8552e-04 - val_loss: 0.2065\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2081\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.2078\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2057\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2019\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9830e-04 - val_loss: 0.2004\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2008\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2031\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5669e-04 - val_loss: 0.2033\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4423e-04 - val_loss: 0.2016\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2020\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.7106e-04 - val_loss: 0.2041\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2042\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2024\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8156e-04 - val_loss: 0.2027\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1970e-04 - val_loss: 0.2048\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2048\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5741e-05 - val_loss: 0.1996\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.1983\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.1990\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2015\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2055\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2073\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2071\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2052\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2016\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2002\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2008\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3743e-04 - val_loss: 0.2033\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0981e-04 - val_loss: 0.2018\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.4781e-04 - val_loss: 0.2044\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2045\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2028\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.1627e-05 - val_loss: 0.2032\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1400e-04 - val_loss: 0.2016\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.8488e-04 - val_loss: 0.2042\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2028\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6312e-04 - val_loss: 0.2031\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6005e-04 - val_loss: 0.2016\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.0738e-04 - val_loss: 0.2042\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2028\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5089e-04 - val_loss: 0.2031\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:10:53,341] Trial 68 finished with value: 0.00018155574798583984 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1234 - val_loss: 0.1892\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0618 - val_loss: 0.1914\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0168 - val_loss: 0.2737\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0715 - val_loss: 0.2655\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0613 - val_loss: 0.2433\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0370 - val_loss: 0.2084\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.1681\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0393 - val_loss: 0.1499\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0564 - val_loss: 0.1474\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0582 - val_loss: 0.1552\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0499 - val_loss: 0.1693\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0347 - val_loss: 0.1831\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0208 - val_loss: 0.2010\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2211\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0170 - val_loss: 0.2321\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0279 - val_loss: 0.2365\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0322 - val_loss: 0.2362\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0321 - val_loss: 0.2327\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0287 - val_loss: 0.2269\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0231 - val_loss: 0.2193\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0157 - val_loss: 0.2103\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - val_loss: 0.1998\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - val_loss: 0.1934\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0099 - val_loss: 0.1907\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0125 - val_loss: 0.1913\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0120 - val_loss: 0.1944\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0089 - val_loss: 0.1995\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.2062\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2098\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0065 - val_loss: 0.2109\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - val_loss: 0.2099\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - val_loss: 0.2070\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - val_loss: 0.2024\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.6874e-04 - val_loss: 0.2003\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2003\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2024\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2061\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2075\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - val_loss: 0.2069\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - val_loss: 0.2045\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2005\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.1987\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.1991\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - val_loss: 0.2012\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2049\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2065\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - val_loss: 0.2060\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2039\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.4382e-04 - val_loss: 0.2001\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.1986\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0049 - val_loss: 0.1990\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - val_loss: 0.2012\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2048\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2064\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - val_loss: 0.2061\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - val_loss: 0.2040\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6824e-04 - val_loss: 0.2004\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.1990\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.1994\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - val_loss: 0.2016\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2052\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2068\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - val_loss: 0.2064\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.2045\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.9628e-04 - val_loss: 0.2010\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.1995\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - val_loss: 0.2000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - val_loss: 0.2021\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2057\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2073\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0038 - val_loss: 0.2070\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - val_loss: 0.2050\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2015\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2001\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - val_loss: 0.2006\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.2027\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.4554e-04 - val_loss: 0.2062\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2078\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - val_loss: 0.2075\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2055\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2021\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2007\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2012\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - val_loss: 0.2033\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4581e-04 - val_loss: 0.2068\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2083\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2081\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.2061\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2027\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0317e-04 - val_loss: 0.2013\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2017\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4492e-04 - val_loss: 0.2040\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4006e-04 - val_loss: 0.2025\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9924e-04 - val_loss: 0.2028\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6616e-04 - val_loss: 0.2048\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6236e-04 - val_loss: 0.2035\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.6008e-05 - val_loss: 0.2021\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2025\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.9891e-04 - val_loss: 0.2045\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6854e-04 - val_loss: 0.2034\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6085e-05 - val_loss: 0.2053\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2053\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2037\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2896e-04 - val_loss: 0.2007\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.1995\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2002\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2025\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.8503e-04 - val_loss: 0.2062\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2079\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.2078\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2060\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2027\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.3594e-04 - val_loss: 0.2014\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2020\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.0675e-04 - val_loss: 0.2044\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.8193e-04 - val_loss: 0.2029\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6551e-04 - val_loss: 0.2033\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.9708e-05 - val_loss: 0.2053\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2055\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2040\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8961e-04 - val_loss: 0.2010\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.1999\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2029\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8120e-04 - val_loss: 0.2067\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.2084\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.2083\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0050 - val_loss: 0.2066\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2033\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7340e-05 - val_loss: 0.2021\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.5461e-04 - val_loss: 0.2048\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2051\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0668e-04 - val_loss: 0.2007\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.1998\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2030\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8904e-04 - val_loss: 0.2068\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2086\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.2085\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.2068\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2037\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1637e-04 - val_loss: 0.1992\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1968\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0067 - val_loss: 0.1963\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - val_loss: 0.1976\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.2003\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2045\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2066\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2068\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2054\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2025\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7243e-04 - val_loss: 0.2015\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0086e-04 - val_loss: 0.2011\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2002\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2012\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2036\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0984e-04 - val_loss: 0.2042\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.8903e-04 - val_loss: 0.2031\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3217e-04 - val_loss: 0.2037\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.0329e-04 - val_loss: 0.2026\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6788e-04 - val_loss: 0.2033\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3277e-05 - val_loss: 0.2023\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2030\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9908e-04 - val_loss: 0.2053\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2057\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2045\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2017\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.5598e-04 - val_loss: 0.2047\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7616e-04 - val_loss: 0.2009\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2002\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2011\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2037\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4812e-04 - val_loss: 0.2043\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.7314e-04 - val_loss: 0.2032\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.6768e-05 - val_loss: 0.2039\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7486e-04 - val_loss: 0.2029\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5379e-04 - val_loss: 0.2036\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5558e-04 - val_loss: 0.2026\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.3968e-04 - val_loss: 0.2033\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2783e-07 - val_loss: 0.2023\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.6790e-04 - val_loss: 0.2031\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0300e-04 - val_loss: 0.2054\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2059\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2047\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:11:11,677] Trial 69 finished with value: 0.0013646185398101807 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1507 - val_loss: 0.2730\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0436 - val_loss: 0.1684\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0533 - val_loss: 0.1640\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0420 - val_loss: 0.2038\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2131\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - val_loss: 0.2027\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 0.2053\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.0002e-04 - val_loss: 0.2174\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0121 - val_loss: 0.2184\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0129 - val_loss: 0.2110\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - val_loss: 0.1976\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0082 - val_loss: 0.1927\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0128 - val_loss: 0.1948\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0104 - val_loss: 0.2023\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.2138\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0090 - val_loss: 0.2187\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0139 - val_loss: 0.2182\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0135 - val_loss: 0.2134\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0087 - val_loss: 0.2052\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5709e-04 - val_loss: 0.1942\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0104 - val_loss: 0.1884\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0160 - val_loss: 0.1871\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0173 - val_loss: 0.1895\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0148 - val_loss: 0.1949\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0093 - val_loss: 0.2027\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2126\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0086 - val_loss: 0.2183\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0143 - val_loss: 0.2203\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0163 - val_loss: 0.2192\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0153 - val_loss: 0.2155\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0116 - val_loss: 0.2094\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0055 - val_loss: 0.2011\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.1966\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0072 - val_loss: 0.1953\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0085 - val_loss: 0.1968\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0070 - val_loss: 0.2007\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 0.2066\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2094\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - val_loss: 0.2094\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0057 - val_loss: 0.2070\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2025\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2008\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2017\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2054\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0110e-04 - val_loss: 0.2041\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2963e-04 - val_loss: 0.2024\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6271e-04 - val_loss: 0.2060\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2064\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.2545e-04 - val_loss: 0.2005\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.1991\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - val_loss: 0.2002\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2034\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0896e-04 - val_loss: 0.2085\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - val_loss: 0.2109\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0074 - val_loss: 0.2108\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0073 - val_loss: 0.2085\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0050 - val_loss: 0.2042\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.2008e-04 - val_loss: 0.1981\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - val_loss: 0.1949\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0086 - val_loss: 0.1942\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0093 - val_loss: 0.1958\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0076 - val_loss: 0.1995\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2050\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2078\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - val_loss: 0.2081\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - val_loss: 0.2061\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2022\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2019\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2049\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2055\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2039\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.2126e-04 - val_loss: 0.2002\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 0.1991\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0043 - val_loss: 0.2003\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.2035\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.9900e-05 - val_loss: 0.2043\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.1821e-04 - val_loss: 0.2028\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6398e-04 - val_loss: 0.2036\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4964e-04 - val_loss: 0.2022\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.8828e-04 - val_loss: 0.2060\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - val_loss: 0.2065\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - val_loss: 0.2048\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2011\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.2011\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2042\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.9209e-04 - val_loss: 0.2049\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.6405e-05 - val_loss: 0.2042\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.4527e-04 - val_loss: 0.2027\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.8608e-04 - val_loss: 0.2036\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.5333e-04 - val_loss: 0.2022\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.2254e-04 - val_loss: 0.2060\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - val_loss: 0.2066\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - val_loss: 0.2049\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.2002\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2013\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8072e-04 - val_loss: 0.2051\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.8997e-04 - val_loss: 0.2002\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.1992\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - val_loss: 0.2004\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.2036\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0607e-04 - val_loss: 0.2044\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9640e-04 - val_loss: 0.2030\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.9983e-04 - val_loss: 0.2039\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5235e-04 - val_loss: 0.2025\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.8751e-04 - val_loss: 0.2034\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4916e-05 - val_loss: 0.2021\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3608e-04 - val_loss: 0.2060\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2066\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2050\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2015\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2004\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2015\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2053\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2039\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8475e-04 - val_loss: 0.2005\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1995\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2008\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2040\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6727e-04 - val_loss: 0.2048\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2105e-06 - val_loss: 0.2043\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4576e-04 - val_loss: 0.2029\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7123e-04 - val_loss: 0.2038\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3055e-04 - val_loss: 0.2026\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.4291e-04 - val_loss: 0.2035\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7573e-05 - val_loss: 0.2023\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6880e-04 - val_loss: 0.2062\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2068\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2052\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2007\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2018\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2050\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2057\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2043\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5559e-04 - val_loss: 0.2009\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2012\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2044\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8264e-04 - val_loss: 0.2052\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2945e-04 - val_loss: 0.2005\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.1997\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2009\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2042\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6441e-04 - val_loss: 0.2050\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8917e-04 - val_loss: 0.2004\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.1996\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2009\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2041\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3373e-04 - val_loss: 0.2050\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0069e-04 - val_loss: 0.2005\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1996\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2009\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2042\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0247e-04 - val_loss: 0.2050\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.9251e-04 - val_loss: 0.2006\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.1998\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2011\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2043\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.2377e-04 - val_loss: 0.2052\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2683e-04 - val_loss: 0.2007\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.1999\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2012\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8352e-04 - val_loss: 0.2009\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2001\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2014\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2046\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2055\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.5175e-04 - val_loss: 0.2011\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2003\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.2016\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2048\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2056\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2013\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:11:29,457] Trial 70 finished with value: 0.002904742956161499 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1443 - val_loss: 0.2911\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0517 - val_loss: 0.1396\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0954 - val_loss: 0.1386\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0806 - val_loss: 0.1909\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0246 - val_loss: 0.2559\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0420 - val_loss: 0.2739\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0627 - val_loss: 0.2722\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0612 - val_loss: 0.2609\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0499 - val_loss: 0.2390\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0269 - val_loss: 0.2086\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.1957\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0150 - val_loss: 0.1952\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0150 - val_loss: 0.2019\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0080 - val_loss: 0.2141\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0043 - val_loss: 0.2178\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0082 - val_loss: 0.2148\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0055 - val_loss: 0.2064\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2048\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.2087\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0756e-04 - val_loss: 0.2173\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - val_loss: 0.2197\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0110 - val_loss: 0.2168\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0084 - val_loss: 0.2094\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.1981\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0099 - val_loss: 0.1928\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0151 - val_loss: 0.1928\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0150 - val_loss: 0.1974\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0104 - val_loss: 0.2060\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2180\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - val_loss: 0.2237\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0163 - val_loss: 0.2246\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0177 - val_loss: 0.2223\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0148 - val_loss: 0.2156\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0081 - val_loss: 0.2054\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2004\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0068 - val_loss: 0.2000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - val_loss: 0.2036\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.2109\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - val_loss: 0.2134\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0062 - val_loss: 0.2117\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - val_loss: 0.2063\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2183e-04 - val_loss: 0.2054\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2084\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2072\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.9430e-04 - val_loss: 0.2024\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - val_loss: 0.2019\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0048 - val_loss: 0.2051\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2118\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0051 - val_loss: 0.2140\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0073 - val_loss: 0.2123\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0057 - val_loss: 0.2071\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7073e-04 - val_loss: 0.1987\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0077 - val_loss: 0.1949\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0114 - val_loss: 0.1951\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0111 - val_loss: 0.1989\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0073 - val_loss: 0.2060\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0814e-04 - val_loss: 0.2159\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0095 - val_loss: 0.2211\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0148 - val_loss: 0.2223\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0160 - val_loss: 0.2198\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0136 - val_loss: 0.2140\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0079 - val_loss: 0.2053\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.0035e-04 - val_loss: 0.2010\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - val_loss: 0.2006\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.2038\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2102\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 0.2124\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0065 - val_loss: 0.2110\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0051 - val_loss: 0.2062\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1649e-04 - val_loss: 0.1985\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0072 - val_loss: 0.1950\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0106 - val_loss: 0.1952\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0103 - val_loss: 0.1989\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0066 - val_loss: 0.2055\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.2750e-06 - val_loss: 0.2149\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - val_loss: 0.2199\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0143 - val_loss: 0.2211\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0155 - val_loss: 0.2188\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0133 - val_loss: 0.2135\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - val_loss: 0.2054\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7850e-05 - val_loss: 0.1949\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0104 - val_loss: 0.1887\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0165 - val_loss: 0.1865\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - val_loss: 0.1878\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0174 - val_loss: 0.1922\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0129 - val_loss: 0.1995\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - val_loss: 0.2093\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2148\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0095 - val_loss: 0.2164\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0112 - val_loss: 0.2148\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0095 - val_loss: 0.2101\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 0.2028\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.1994\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - val_loss: 0.1995\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.2028\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2090\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - val_loss: 0.2114\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0066 - val_loss: 0.2103\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0056 - val_loss: 0.2062\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.1994\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - val_loss: 0.1964\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - val_loss: 0.1969\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0078 - val_loss: 0.2004\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.2066\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2091\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.2083\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - val_loss: 0.2045\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.4140e-04 - val_loss: 0.2042\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6225e-04 - val_loss: 0.2070\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2064\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2029\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2057\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2053\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2683e-04 - val_loss: 0.2020\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.2020\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.2050\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8582e-04 - val_loss: 0.2047\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2383e-05 - val_loss: 0.2074\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2069\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2034\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.2061\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2057\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2023\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2023\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2053\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8503e-04 - val_loss: 0.2049\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.6678e-04 - val_loss: 0.2017\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2017\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.2047\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.0111e-05 - val_loss: 0.2044\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9519e-04 - val_loss: 0.2072\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2067\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2033\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2031\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2060\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2056\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2023\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2023\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2053\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.9244e-04 - val_loss: 0.2050\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0415e-04 - val_loss: 0.2018\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2018\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7339e-04 - val_loss: 0.2046\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.8549e-05 - val_loss: 0.2014\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2015\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2046\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6910e-05 - val_loss: 0.2044\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6305e-04 - val_loss: 0.2071\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2067\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2062\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2026\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2055\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2053\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.3862e-04 - val_loss: 0.2021\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2022\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5213e-04 - val_loss: 0.2050\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2996e-04 - val_loss: 0.2018\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2019\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2050\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5632e-04 - val_loss: 0.2048\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6466e-04 - val_loss: 0.2017\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2018\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2049\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6420e-04 - val_loss: 0.2047\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9254e-04 - val_loss: 0.2016\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2018\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3984e-04 - val_loss: 0.2047\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8151e-04 - val_loss: 0.2016\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2018\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6049e-04 - val_loss: 0.2047\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1109e-04 - val_loss: 0.2016\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2018\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2049\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1111e-04 - val_loss: 0.2047\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6770e-04 - val_loss: 0.2017\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2019\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2049\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8180e-04 - val_loss: 0.2048\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4252e-04 - val_loss: 0.2018\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2019\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.2050\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6569e-04 - val_loss: 0.2049\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2918e-04 - val_loss: 0.2018\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2020\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2051\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5838e-04 - val_loss: 0.2050\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2370e-04 - val_loss: 0.2019\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2021\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.5664e-04 - val_loss: 0.2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:11:46,473] Trial 71 finished with value: 0.0006232708692550659 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1426 - val_loss: 0.2928\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0721 - val_loss: 0.2288\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0172 - val_loss: 0.1840\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0217 - val_loss: 0.1767\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0261 - val_loss: 0.1841\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0178 - val_loss: 0.1969\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 0.2109\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0091 - val_loss: 0.2170\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0150 - val_loss: 0.2184\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0163 - val_loss: 0.2168\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0145 - val_loss: 0.2129\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0105 - val_loss: 0.2071\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.1998\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.1958\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - val_loss: 0.1947\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0078 - val_loss: 0.1958\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - val_loss: 0.1989\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.2034\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.3546e-04 - val_loss: 0.2054\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2055\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - val_loss: 0.2040\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2010\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.1999\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2006\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.0958e-05 - val_loss: 0.2030\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.3668e-04 - val_loss: 0.2019\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.2695e-04 - val_loss: 0.2023\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.9685e-04 - val_loss: 0.2042\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1072e-04 - val_loss: 0.2006\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.1998\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2005\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2025\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.8813e-04 - val_loss: 0.2056\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2071\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - val_loss: 0.2071\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.2057\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2032\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6618e-04 - val_loss: 0.1995\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.1976\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - val_loss: 0.1972\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - val_loss: 0.1982\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - val_loss: 0.2005\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2056\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2058\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.2047\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2025\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0915e-04 - val_loss: 0.2017\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.3823e-04 - val_loss: 0.2042\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2046\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3464e-04 - val_loss: 0.2015\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2009\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2016\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3324e-04 - val_loss: 0.2040\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.4441e-04 - val_loss: 0.2012\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2006\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2014\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8149e-04 - val_loss: 0.2038\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.7780e-04 - val_loss: 0.2030\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7990e-04 - val_loss: 0.2011\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2005\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2013\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4118e-04 - val_loss: 0.2038\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.5826e-04 - val_loss: 0.2031\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8524e-04 - val_loss: 0.2011\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2006\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2014\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1016e-04 - val_loss: 0.2039\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2032\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.7788e-04 - val_loss: 0.2012\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2007\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2016\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.3442e-04 - val_loss: 0.2041\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.2033\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.1419e-04 - val_loss: 0.2014\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - val_loss: 0.2017\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.8556e-04 - val_loss: 0.2042\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7139e-04 - val_loss: 0.2016\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.2019\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.4900e-04 - val_loss: 0.2044\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.3773e-04 - val_loss: 0.2018\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - val_loss: 0.2021\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.3201e-04 - val_loss: 0.2041\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.0748e-04 - val_loss: 0.2019\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.8325e-04 - val_loss: 0.2015\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2023\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5707e-04 - val_loss: 0.2042\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2048\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0785e-04 - val_loss: 0.2017\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8271e-04 - val_loss: 0.2044\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2042\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 0.2023\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.3378e-04 - val_loss: 0.2018\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0982e-04 - val_loss: 0.2046\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - val_loss: 0.2044\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2025\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.6147e-04 - val_loss: 0.2020\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.3409e-04 - val_loss: 0.2028\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3874e-04 - val_loss: 0.2048\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2053\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2046\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2027\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.9111e-04 - val_loss: 0.2022\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.6286e-04 - val_loss: 0.2030\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0369e-05 - val_loss: 0.2025\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7098e-04 - val_loss: 0.2033\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.9357e-04 - val_loss: 0.2027\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3176e-04 - val_loss: 0.2035\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.0958e-04 - val_loss: 0.2029\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.5122e-05 - val_loss: 0.2037\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.8739e-04 - val_loss: 0.2031\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2696e-04 - val_loss: 0.2014\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2010\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.2040\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2047\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010 - val_loss: 0.2022\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.5367e-04 - val_loss: 0.2018\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2027\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.8911e-04 - val_loss: 0.2047\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2053\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2046\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2028\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.3013e-04 - val_loss: 0.2023\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.5973e-04 - val_loss: 0.2031\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6546e-04 - val_loss: 0.2027\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0112e-04 - val_loss: 0.2035\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.8861e-04 - val_loss: 0.2030\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.8976e-06 - val_loss: 0.2037\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5307e-04 - val_loss: 0.2032\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3234e-04 - val_loss: 0.2015\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2022\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.9912e-04 - val_loss: 0.2043\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2049\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2043\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6995e-04 - val_loss: 0.2021\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.4755e-04 - val_loss: 0.2030\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2173e-05 - val_loss: 0.2026\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.0193e-04 - val_loss: 0.2034\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.2340e-04 - val_loss: 0.2030\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.8341e-05 - val_loss: 0.2037\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.5103e-04 - val_loss: 0.2033\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.5883e-04 - val_loss: 0.2016\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2013\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.0371e-04 - val_loss: 0.2044\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.2050\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - val_loss: 0.2044\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.2027\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.1422e-04 - val_loss: 0.2023\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.7903e-04 - val_loss: 0.2032\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.9839e-04 - val_loss: 0.2028\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1499e-04 - val_loss: 0.2036\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1613e-04 - val_loss: 0.2032\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.6344e-04 - val_loss: 0.2016\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2013\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.0329e-04 - val_loss: 0.2044\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2051\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2045\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2028\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2715e-04 - val_loss: 0.2024\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7450e-04 - val_loss: 0.2033\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1553e-04 - val_loss: 0.2029\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.3372e-05 - val_loss: 0.2038\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.5756e-04 - val_loss: 0.2033\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1695e-04 - val_loss: 0.2017\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2015\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2025\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2106e-04 - val_loss: 0.2046\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:12:03,080] Trial 72 finished with value: 0.0022574961185455322 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1496 - val_loss: 0.3242\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1130 - val_loss: 0.2809\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0715 - val_loss: 0.2266\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0196 - val_loss: 0.1972\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2074\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0086 - val_loss: 0.1965\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2010\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.1948\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - val_loss: 0.1974\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2073\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.2085\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.2031\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.1925\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 0.1891\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0119 - val_loss: 0.1915\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0095 - val_loss: 0.1986\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2095\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0080 - val_loss: 0.2144\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0127 - val_loss: 0.2144\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0126 - val_loss: 0.2102\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0084 - val_loss: 0.2025\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.3961e-04 - val_loss: 0.1918\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0097 - val_loss: 0.1863\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0152 - val_loss: 0.1852\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0163 - val_loss: 0.1880\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0135 - val_loss: 0.1941\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0076 - val_loss: 0.2028\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1052e-04 - val_loss: 0.2072\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2078\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - val_loss: 0.2051\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.1995\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.1977\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - val_loss: 0.1992\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2036\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2045\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2023\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.0486e-05 - val_loss: 0.2033\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.2515e-04 - val_loss: 0.2012\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.9873e-05 - val_loss: 0.2062\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.2068\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.2044\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.1995\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1979\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.1994\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2035\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.9623e-04 - val_loss: 0.2043\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2023\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4021e-04 - val_loss: 0.2033\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.3165e-04 - val_loss: 0.2014\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2025\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2651e-05 - val_loss: 0.2007\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2019\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4078e-04 - val_loss: 0.2056\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2063\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.2042\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.1995\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.1981\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - val_loss: 0.1995\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.2035\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.9696e-04 - val_loss: 0.2044\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.8582e-05 - val_loss: 0.1982\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - val_loss: 0.1969\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - val_loss: 0.1985\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0040 - val_loss: 0.2026\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.9304e-05 - val_loss: 0.2037\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3436e-04 - val_loss: 0.2030\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.4774e-04 - val_loss: 0.2014\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3643e-05 - val_loss: 0.2062\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.2068\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - val_loss: 0.2048\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2004\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.1991\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - val_loss: 0.2005\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2052\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2035\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6668e-04 - val_loss: 0.1993\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.1981\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 0.1996\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.2036\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.8309e-04 - val_loss: 0.2046\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0792e-04 - val_loss: 0.1988\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.1978\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.1994\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.2033\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.2776e-04 - val_loss: 0.2044\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.6618e-04 - val_loss: 0.1988\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.1978\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.1994\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2033\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.3363e-04 - val_loss: 0.2044\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.2824e-04 - val_loss: 0.1989\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - val_loss: 0.1979\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.1995\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2035\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.6387e-04 - val_loss: 0.2045\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.8566e-04 - val_loss: 0.1991\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.1982\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.1998\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2037\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2047\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2032\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8530e-04 - val_loss: 0.1994\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.1984\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - val_loss: 0.2000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2039\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2050\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2035\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.0173e-04 - val_loss: 0.1996\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.1987\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2003\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2041\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2052\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.1999\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.1989\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2005\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2044\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2054\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2039\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2002\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.1992\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 0.2008\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2056\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2042\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2004\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.1994\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - val_loss: 0.2010\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2048\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2059\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2044\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2006\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.1997\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2013\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2051\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2061\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2046\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.1999\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2015\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2053\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2063\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 0.2048\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2011\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2002\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2017\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2055\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.2065\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.2050\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2013\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2004\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2019\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.1386e-04 - val_loss: 0.2057\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2067\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2053\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2016\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2006\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2022\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.0786e-04 - val_loss: 0.2059\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2069\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2055\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2018\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.8741e-04 - val_loss: 0.2008\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.0540e-04 - val_loss: 0.2061\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2071\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - val_loss: 0.2057\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2020\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.8551e-04 - val_loss: 0.2011\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2026\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0626e-04 - val_loss: 0.2063\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2073\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - val_loss: 0.2059\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8681e-04 - val_loss: 0.2013\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2028\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0088e-05 - val_loss: 0.2065\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.2075\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.2060\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.2024\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9086e-04 - val_loss: 0.2015\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8334e-04 - val_loss: 0.2020\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.9891e-04 - val_loss: 0.2035\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.5170e-04 - val_loss: 0.2024\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7421e-04 - val_loss: 0.2039\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2028\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7150e-05 - val_loss: 0.2042\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5705e-04 - val_loss: 0.1998\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.1991\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:12:18,908] Trial 73 finished with value: 0.0037026554346084595 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1186 - val_loss: 0.1618\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0819 - val_loss: 0.1840\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.3530\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1743 - val_loss: 0.3892\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1929 - val_loss: 0.3572\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1553 - val_loss: 0.2957\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0927 - val_loss: 0.2157\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0136 - val_loss: 0.1552\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0459 - val_loss: 0.1382\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0635 - val_loss: 0.1400\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0612 - val_loss: 0.1549\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0453 - val_loss: 0.1787\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0213 - val_loss: 0.2078\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0079 - val_loss: 0.2221\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0219 - val_loss: 0.2256\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0253 - val_loss: 0.2212\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0208 - val_loss: 0.2107\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0103 - val_loss: 0.1954\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0051 - val_loss: 0.1885\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0122 - val_loss: 0.1883\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0124 - val_loss: 0.1937\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - val_loss: 0.2035\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2065\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - val_loss: 0.2042\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.1977\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.1964\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0048 - val_loss: 0.1996\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2066\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0054 - val_loss: 0.2087\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0075 - val_loss: 0.2064\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0052 - val_loss: 0.2005\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5904e-04 - val_loss: 0.1992\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2018\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4896e-04 - val_loss: 0.2005\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2015\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2754e-04 - val_loss: 0.2036\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2024\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9968e-04 - val_loss: 0.1982\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.1982\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2015\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2802e-04 - val_loss: 0.2078\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.2101\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0081 - val_loss: 0.2088\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0068 - val_loss: 0.2046\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.1976\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0046 - val_loss: 0.1946\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0077 - val_loss: 0.1949\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.1983\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0040 - val_loss: 0.2042\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2066\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2057\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2021\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5436e-04 - val_loss: 0.2017\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4987e-04 - val_loss: 0.2042\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2037\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2003\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.2001\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2028\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.4064e-04 - val_loss: 0.2023\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.6540e-06 - val_loss: 0.1992\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.1991\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2018\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.4914e-04 - val_loss: 0.2070\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.2089\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - val_loss: 0.2079\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0056 - val_loss: 0.2043\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.1983\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0041 - val_loss: 0.1956\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - val_loss: 0.1960\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0065 - val_loss: 0.1990\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2044\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2065\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - val_loss: 0.2058\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.2025\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.8559e-05 - val_loss: 0.1969\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.1945\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - val_loss: 0.1950\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0075 - val_loss: 0.1981\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 0.2035\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2058\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2052\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.2021\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4149e-04 - val_loss: 0.2019\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.6033e-04 - val_loss: 0.2043\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2009\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2033\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6015e-04 - val_loss: 0.2030\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.3705e-04 - val_loss: 0.2001\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2001\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - val_loss: 0.2027\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4327e-04 - val_loss: 0.2025\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0897e-04 - val_loss: 0.2048\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2043\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2014\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.1171e-04 - val_loss: 0.2006\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2005\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2031\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7421e-04 - val_loss: 0.2028\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1097e-04 - val_loss: 0.2000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2001\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2027\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8845e-05 - val_loss: 0.2025\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.5427e-04 - val_loss: 0.2048\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2044\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - val_loss: 0.2015\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2014\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2038\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2035\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0943e-04 - val_loss: 0.2007\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2007\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2033\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.2354e-04 - val_loss: 0.2030\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.7526e-04 - val_loss: 0.2003\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - val_loss: 0.2003\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2029\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.5637e-04 - val_loss: 0.2027\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3391e-05 - val_loss: 0.2000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - val_loss: 0.2001\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - val_loss: 0.2027\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.4033e-05 - val_loss: 0.2025\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2918e-04 - val_loss: 0.2049\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2045\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2016\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - val_loss: 0.2016\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2037\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2010\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2010\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2035\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.5029e-04 - val_loss: 0.2033\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.1752e-04 - val_loss: 0.2006\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2007\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3234e-04 - val_loss: 0.2030\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.3985e-04 - val_loss: 0.2004\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2005\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2030\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5214e-04 - val_loss: 0.2029\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.8615e-04 - val_loss: 0.2003\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2004\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.6241e-04 - val_loss: 0.2028\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1390e-04 - val_loss: 0.2002\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2003\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2029\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3198e-04 - val_loss: 0.2028\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.5040e-05 - val_loss: 0.2002\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2004\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - val_loss: 0.2030\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.4053e-04 - val_loss: 0.2028\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1119e-04 - val_loss: 0.2002\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2004\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.7463e-04 - val_loss: 0.2029\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.5032e-04 - val_loss: 0.2003\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2005\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2031\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2535e-04 - val_loss: 0.2029\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0452e-04 - val_loss: 0.2004\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2005\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.8706e-04 - val_loss: 0.2030\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.6850e-04 - val_loss: 0.2004\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2006\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2032\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5587e-04 - val_loss: 0.2031\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3893e-04 - val_loss: 0.2005\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2938e-04 - val_loss: 0.2032\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.1352e-04 - val_loss: 0.2006\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2008\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2034\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.0585e-04 - val_loss: 0.2033\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9080e-04 - val_loss: 0.2007\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2009\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.8434e-04 - val_loss: 0.2033\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6982e-04 - val_loss: 0.2008\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2010\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.6412e-04 - val_loss: 0.2034\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4999e-04 - val_loss: 0.2009\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2010\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.4461e-04 - val_loss: 0.2035\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.3083e-04 - val_loss: 0.2010\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2011\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.2557e-04 - val_loss: 0.2036\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.1208e-04 - val_loss: 0.2011\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2012\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:12:34,257] Trial 74 finished with value: 0.0008936375379562378 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1482 - val_loss: 0.3250\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1129 - val_loss: 0.2833\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0735 - val_loss: 0.2617\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0506 - val_loss: 0.2085\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.2043\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2266\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0201 - val_loss: 0.2287\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0212 - val_loss: 0.2165\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - val_loss: 0.1944\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0141 - val_loss: 0.1863\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0220 - val_loss: 0.1894\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0187 - val_loss: 0.2007\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0073 - val_loss: 0.2175\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0097 - val_loss: 0.2247\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0169 - val_loss: 0.2245\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0168 - val_loss: 0.2185\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0108 - val_loss: 0.2076\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1913e-05 - val_loss: 0.2034\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2050\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2113\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2120\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.2080\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.2055e-04 - val_loss: 0.1998\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0074 - val_loss: 0.1971\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0100 - val_loss: 0.1991\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0080 - val_loss: 0.2052\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2146\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0077 - val_loss: 0.2189\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0121 - val_loss: 0.2187\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0120 - val_loss: 0.2147\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0081 - val_loss: 0.2072\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9854e-04 - val_loss: 0.1968\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0097 - val_loss: 0.1913\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0151 - val_loss: 0.1901\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0162 - val_loss: 0.1927\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0135 - val_loss: 0.1986\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.2074\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2116\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - val_loss: 0.2121\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - val_loss: 0.2091\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2033\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - val_loss: 0.2013\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.2027\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2071\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2080\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2056\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3429e-04 - val_loss: 0.2004\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - val_loss: 0.1988\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0063 - val_loss: 0.2004\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0046 - val_loss: 0.2049\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.3539e-05 - val_loss: 0.2119\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0070 - val_loss: 0.2152\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0104 - val_loss: 0.2152\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0104 - val_loss: 0.2123\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0075 - val_loss: 0.2067\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.1987\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0059 - val_loss: 0.1945\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0101 - val_loss: 0.1936\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0110 - val_loss: 0.1958\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0088 - val_loss: 0.2006\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2077\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2113\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069 - val_loss: 0.2117\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0073 - val_loss: 0.2092\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - val_loss: 0.2042\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2122e-04 - val_loss: 0.2025\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3918e-04 - val_loss: 0.2077\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2084\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.2063\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2017\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2002\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0040 - val_loss: 0.2017\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2058\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2067\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2048\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5699e-04 - val_loss: 0.2003\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.1991\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0050 - val_loss: 0.2007\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - val_loss: 0.2048\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.1813e-04 - val_loss: 0.2058\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2041\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4468e-05 - val_loss: 0.2051\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2729e-04 - val_loss: 0.2046\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3322e-04 - val_loss: 0.2029\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2372e-05 - val_loss: 0.2025\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2038\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.6381e-04 - val_loss: 0.2076\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2083\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.2063\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2018\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2005\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2019\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2059\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.2068\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2050\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2007\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.1994\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.2010\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2061\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.7900e-04 - val_loss: 0.2001\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.1989\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - val_loss: 0.2006\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2047\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3905e-04 - val_loss: 0.2057\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2015e-04 - val_loss: 0.1999\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.1988\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0052 - val_loss: 0.2004\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - val_loss: 0.2045\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2050e-04 - val_loss: 0.2056\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.6401e-05 - val_loss: 0.1998\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - val_loss: 0.1987\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2004\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 0.2045\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3036e-04 - val_loss: 0.2056\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.6336e-05 - val_loss: 0.1999\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0040 - val_loss: 0.1988\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2005\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2046\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.0785e-04 - val_loss: 0.2057\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.9041e-04 - val_loss: 0.2000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.1989\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0049 - val_loss: 0.2006\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2047\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.2003e-04 - val_loss: 0.2057\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.1185e-04 - val_loss: 0.2001\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.1990\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.2007\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 0.2048\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.4888e-04 - val_loss: 0.2058\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2042\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4614e-04 - val_loss: 0.2002\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.1992\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0046 - val_loss: 0.2008\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - val_loss: 0.2049\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2060\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2044\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8551e-04 - val_loss: 0.2004\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.1993\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - val_loss: 0.2010\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2050\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.2061\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2045\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2585e-04 - val_loss: 0.2005\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.1995\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.2011\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2051\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2062\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2046\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.6512e-04 - val_loss: 0.2006\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.1996\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.2012\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2052\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2063\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2047\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2008\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.1998\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.2014\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2053\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2064\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2009\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1999\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.2015\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2055\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2065\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0028 - val_loss: 0.2050\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.2010\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - val_loss: 0.2016\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - val_loss: 0.2056\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2066\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2051\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2002\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2018\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2057\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2067\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.2052\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2003\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2019\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2058\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2068\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2053\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2014\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2004\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.2020\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2059\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2069\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:12:49,811] Trial 75 finished with value: 0.0017710328102111816 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1372 - val_loss: 0.3048\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0894 - val_loss: 0.2346\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0212 - val_loss: 0.1740\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0338 - val_loss: 0.1602\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0440 - val_loss: 0.1647\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0385 - val_loss: 0.1769\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0260 - val_loss: 0.1938\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0093 - val_loss: 0.2139\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0105 - val_loss: 0.2233\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0197 - val_loss: 0.2250\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0213 - val_loss: 0.2214\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0177 - val_loss: 0.2141\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0105 - val_loss: 0.2046\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.1932\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0100 - val_loss: 0.1870\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0160 - val_loss: 0.1850\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0180 - val_loss: 0.1863\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0166 - val_loss: 0.1904\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0126 - val_loss: 0.1967\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0063 - val_loss: 0.2049\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.2095\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.2111\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0078 - val_loss: 0.2100\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0067 - val_loss: 0.2068\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2021\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2006\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2019\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2056\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.2062\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2044\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2003\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.1991\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2003\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2036\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8941e-04 - val_loss: 0.2043\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9260e-04 - val_loss: 0.2027\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4817e-04 - val_loss: 0.2035\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1850e-04 - val_loss: 0.2020\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.9923e-04 - val_loss: 0.2057\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2061\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.1998\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2008\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4356e-04 - val_loss: 0.2044\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4465e-04 - val_loss: 0.2037\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.5988e-04 - val_loss: 0.2023\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7470e-04 - val_loss: 0.2031\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0945e-04 - val_loss: 0.2057\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2062\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2046\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.2013\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2002\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2012\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2040\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1745e-04 - val_loss: 0.2046\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6921e-05 - val_loss: 0.2001\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.1992\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2003\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2032\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3782e-05 - val_loss: 0.2039\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2610e-04 - val_loss: 0.2026\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.2598e-04 - val_loss: 0.2034\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3164e-04 - val_loss: 0.2022\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6588e-04 - val_loss: 0.2030\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6382e-04 - val_loss: 0.2056\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2061\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2046\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2014\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.2015\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.9014e-04 - val_loss: 0.2005\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.1997\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2008\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2036\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4017e-04 - val_loss: 0.2043\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5252e-05 - val_loss: 0.2038\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8510e-04 - val_loss: 0.2027\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.7003e-04 - val_loss: 0.2035\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2203e-04 - val_loss: 0.2024\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.9350e-04 - val_loss: 0.2032\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2261e-05 - val_loss: 0.2021\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.9825e-04 - val_loss: 0.2056\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2061\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2047\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2017\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2008\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2018\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2045\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - val_loss: 0.2039\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.4182e-04 - val_loss: 0.2010\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2002\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2012\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.8094e-04 - val_loss: 0.2047\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.1690e-04 - val_loss: 0.2007\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - val_loss: 0.1999\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.2011\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2039\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.4184e-04 - val_loss: 0.2046\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.4845e-04 - val_loss: 0.2007\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - val_loss: 0.2011\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.2039\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7073e-04 - val_loss: 0.2047\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1552e-04 - val_loss: 0.2008\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2001\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 0.2012\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2040\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.8799e-04 - val_loss: 0.2048\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5380e-04 - val_loss: 0.2009\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2002\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2014\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2042\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.2901e-04 - val_loss: 0.2011\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - val_loss: 0.2004\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2044\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 0.2052\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - val_loss: 0.2041\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.2316e-04 - val_loss: 0.2014\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - val_loss: 0.2018\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.2046\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2053\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2043\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.2020\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.2048\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2056\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2045\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2023\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9605e-04 - val_loss: 0.2050\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2058\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2047\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2013\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2025\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.7492e-04 - val_loss: 0.2052\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2060\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.2049\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2022\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0335e-04 - val_loss: 0.2016\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2027\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.5411e-04 - val_loss: 0.2054\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2062\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2051\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - val_loss: 0.2025\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.8140e-04 - val_loss: 0.2018\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2029\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3396e-04 - val_loss: 0.2056\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2064\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2053\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2027\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6036e-04 - val_loss: 0.2020\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4797e-05 - val_loss: 0.2058\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2066\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2055\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2029\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.4024e-04 - val_loss: 0.2022\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.0274e-04 - val_loss: 0.2034\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.0351e-04 - val_loss: 0.2026\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.9971e-04 - val_loss: 0.2037\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.6623e-04 - val_loss: 0.2030\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.6990e-04 - val_loss: 0.2040\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6343e-04 - val_loss: 0.2033\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0078e-04 - val_loss: 0.2009\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2004\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2017\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2046\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2055\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2046\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2021\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2016\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2028\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7169e-04 - val_loss: 0.2056\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2064\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - val_loss: 0.2054\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2029\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.6931e-04 - val_loss: 0.2023\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:13:06,208] Trial 76 finished with value: 0.000863686203956604 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1438 - val_loss: 0.2523\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0214 - val_loss: 0.1561\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0551 - val_loss: 0.1474\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0561 - val_loss: 0.1657\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0368 - val_loss: 0.1933\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0098 - val_loss: 0.2258\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0222 - val_loss: 0.2388\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0350 - val_loss: 0.2390\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0350 - val_loss: 0.2309\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0269 - val_loss: 0.2178\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0139 - val_loss: 0.2018\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.1942\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0097 - val_loss: 0.1927\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0112 - val_loss: 0.1960\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0080 - val_loss: 0.2028\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2125\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.2172\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0133 - val_loss: 0.2178\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0139 - val_loss: 0.2150\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0112 - val_loss: 0.2094\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.2014\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.1975\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0063 - val_loss: 0.1971\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0067 - val_loss: 0.1997\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2048\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2065\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2053\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2016\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2010\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2030\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.5023e-04 - val_loss: 0.2075\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.2088\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.2075\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.2039\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.8083e-04 - val_loss: 0.1981\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - val_loss: 0.1955\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0081 - val_loss: 0.1957\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0080 - val_loss: 0.1983\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2030\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0946e-04 - val_loss: 0.2096\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.2130\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0095 - val_loss: 0.2139\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0103 - val_loss: 0.2124\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0088 - val_loss: 0.2088\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.2033\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6497e-04 - val_loss: 0.2006\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2005\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2026\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1466e-04 - val_loss: 0.2066\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2081\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - val_loss: 0.2073\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.2044\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.1993\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - val_loss: 0.1972\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1978\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.2006\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2050\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2067\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2062\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2036\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5055e-04 - val_loss: 0.1992\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.1973\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.1978\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0057 - val_loss: 0.2004\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2047\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2066\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2061\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2037\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3729e-04 - val_loss: 0.1995\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.1977\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - val_loss: 0.1982\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.2008\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2050\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2068\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2065\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2042\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6327e-04 - val_loss: 0.2002\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.1986\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.1991\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2015\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2056\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2074\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2071\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2049\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2010\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.1995\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.2000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2023\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2063\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2080\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2077\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.2055\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2018\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2002\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2007\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2030\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9652e-04 - val_loss: 0.2069\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - val_loss: 0.2085\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0052 - val_loss: 0.2082\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - val_loss: 0.2061\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2024\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.3958e-04 - val_loss: 0.2009\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2014\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2036\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6293e-04 - val_loss: 0.2038\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6641e-04 - val_loss: 0.2022\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.2026\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9949e-04 - val_loss: 0.2047\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2048\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.7442e-04 - val_loss: 0.2033\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.3594e-05 - val_loss: 0.2018\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.2043\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.9867e-04 - val_loss: 0.2031\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.7036e-05 - val_loss: 0.2052\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.2053\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2036\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.1744e-04 - val_loss: 0.2003\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 0.1991\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - val_loss: 0.1998\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2022\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2061\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2079\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0046 - val_loss: 0.2077\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - val_loss: 0.2058\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2024\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.2080e-04 - val_loss: 0.2011\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2016\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2039\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3497e-04 - val_loss: 0.2041\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.0963e-04 - val_loss: 0.2026\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7927e-04 - val_loss: 0.2030\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.8032e-04 - val_loss: 0.2051\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2053\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2037\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.7752e-04 - val_loss: 0.2005\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.1994\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - val_loss: 0.2002\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2026\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4591e-04 - val_loss: 0.2064\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2082\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0050 - val_loss: 0.2081\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 0.2063\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 0.2030\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4936e-04 - val_loss: 0.2017\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2022\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7670e-04 - val_loss: 0.2044\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2047\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.2196e-05 - val_loss: 0.2003\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.1993\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - val_loss: 0.2001\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2025\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.6924e-04 - val_loss: 0.2064\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2082\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0050 - val_loss: 0.2081\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 0.2064\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - val_loss: 0.2032\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4075e-07 - val_loss: 0.1986\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.1964\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - val_loss: 0.1963\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - val_loss: 0.1979\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0052 - val_loss: 0.2010\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2054\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2076\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - val_loss: 0.2080\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0049 - val_loss: 0.2068\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.2041\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.7261e-04 - val_loss: 0.2001\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.1980\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.1978\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - val_loss: 0.1992\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - val_loss: 0.2021\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2062\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 0.2083\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2086\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0055 - val_loss: 0.2074\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 0.2048\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2010\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.1990\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.1988\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - val_loss: 0.2002\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2029\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9550e-04 - val_loss: 0.2068\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2088\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0057 - val_loss: 0.2092\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0060 - val_loss: 0.2080\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0049 - val_loss: 0.2055\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2017\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.1998\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.1996\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2009\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2036\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.0691e-04 - val_loss: 0.2045\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5236e-04 - val_loss: 0.2018\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2014\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:13:23,258] Trial 77 finished with value: 0.0017941296100616455 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1357 - val_loss: 0.3338\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1308 - val_loss: 0.2704\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0575 - val_loss: 0.1830\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0178 - val_loss: 0.1825\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0184 - val_loss: 0.1922\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0097 - val_loss: 0.2081\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - val_loss: 0.2073\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2025\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5871e-04 - val_loss: 0.1941\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - val_loss: 0.1915\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0111 - val_loss: 0.1930\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0096 - val_loss: 0.1975\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2043\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2072\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2069\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.2042\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.1993\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.1975\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - val_loss: 0.1982\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2056\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2075\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - val_loss: 0.2072\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2049\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2010\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.1994\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.1999\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2022\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6048e-04 - val_loss: 0.2062\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2078\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2075\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.2054\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2018\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.4701e-04 - val_loss: 0.2003\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2008\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2029\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6521e-04 - val_loss: 0.2031\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5048e-04 - val_loss: 0.2016\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2019\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.9730e-04 - val_loss: 0.2039\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2024\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1172e-04 - val_loss: 0.2027\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6285e-04 - val_loss: 0.2046\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2046\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2030\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3831e-04 - val_loss: 0.1998\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.1986\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.1993\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2016\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2053\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2069\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2068\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2050\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2017\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2004\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2010\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2031\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1699e-04 - val_loss: 0.2033\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6986e-04 - val_loss: 0.2019\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.5077e-04 - val_loss: 0.2023\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7882e-04 - val_loss: 0.2043\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2044\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2029\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1114e-05 - val_loss: 0.1999\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.1989\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - val_loss: 0.1996\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.2019\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2055\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2072\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2071\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - val_loss: 0.2054\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2023\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6671e-04 - val_loss: 0.2010\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2016\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2037\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.2776e-04 - val_loss: 0.2039\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9444e-04 - val_loss: 0.2026\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6831e-04 - val_loss: 0.2030\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5069e-06 - val_loss: 0.2017\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2022\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.8517e-04 - val_loss: 0.2042\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2030\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.3464e-05 - val_loss: 0.2002\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.1992\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - val_loss: 0.1999\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 0.2022\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5835e-04 - val_loss: 0.2058\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2075\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.2074\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - val_loss: 0.2058\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2027\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4962e-04 - val_loss: 0.2016\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2021\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.8727e-04 - val_loss: 0.2042\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2401e-04 - val_loss: 0.2003\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.1994\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - val_loss: 0.2002\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2025\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3233e-04 - val_loss: 0.2061\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2077\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.2077\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0047 - val_loss: 0.2061\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2031\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.8960e-05 - val_loss: 0.1988\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.1965\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0065 - val_loss: 0.1961\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.1972\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - val_loss: 0.1999\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.2038\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6510e-04 - val_loss: 0.2057\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2060\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2046\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2016\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7690e-04 - val_loss: 0.2042\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2031\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6731e-05 - val_loss: 0.2005\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - val_loss: 0.1997\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2006\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2029\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8275e-04 - val_loss: 0.2065\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.2082\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - val_loss: 0.2082\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.2067\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2038\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5877e-04 - val_loss: 0.1997\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.1975\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.1971\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - val_loss: 0.1982\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.2008\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2047\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2067\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2069\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.2056\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2029\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8197e-04 - val_loss: 0.2020\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2027\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.7417e-04 - val_loss: 0.2049\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2053\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2042\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2017\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.0601e-04 - val_loss: 0.2045\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.0047e-04 - val_loss: 0.2010\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2012\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2036\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0880e-04 - val_loss: 0.2042\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0918e-04 - val_loss: 0.2008\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2001\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2011\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - val_loss: 0.2035\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7137e-04 - val_loss: 0.2041\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.8647e-04 - val_loss: 0.2031\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8223e-05 - val_loss: 0.2007\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2001\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2011\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2035\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.7174e-04 - val_loss: 0.2041\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 0.2031\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8874e-05 - val_loss: 0.2008\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2002\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2011\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2035\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4523e-04 - val_loss: 0.2042\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4852e-04 - val_loss: 0.2009\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2003\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2013\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2036\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.5721e-04 - val_loss: 0.2043\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.6932e-04 - val_loss: 0.2010\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2004\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - val_loss: 0.2014\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2038\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.8946e-04 - val_loss: 0.2044\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.0640e-04 - val_loss: 0.2012\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2006\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.2015\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2039\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.3217e-04 - val_loss: 0.2046\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.5186e-04 - val_loss: 0.2013\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2017\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2041\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8015e-04 - val_loss: 0.2047\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.2038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:13:40,594] Trial 78 finished with value: 0.0007015019655227661 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1407 - val_loss: 0.3272\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1151 - val_loss: 0.2902\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0719 - val_loss: 0.2153\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2591e-04 - val_loss: 0.1606\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0500 - val_loss: 0.1445\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0620 - val_loss: 0.1493\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0545 - val_loss: 0.1652\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0351 - val_loss: 0.1914\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0075 - val_loss: 0.2216\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0231 - val_loss: 0.2353\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0365 - val_loss: 0.2376\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0383 - val_loss: 0.2328\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0328 - val_loss: 0.2238\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0233 - val_loss: 0.2118\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0108 - val_loss: 0.1997\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.1942\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0091 - val_loss: 0.1927\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0108 - val_loss: 0.1943\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0092 - val_loss: 0.1987\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0048 - val_loss: 0.2052\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2083\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.2086\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - val_loss: 0.2065\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2023\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - val_loss: 0.2019\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - val_loss: 0.2052\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2058\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - val_loss: 0.2041\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.5945e-04 - val_loss: 0.2004\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.1993\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2005\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.2038\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4551e-04 - val_loss: 0.2045\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2031\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1707e-04 - val_loss: 0.2039\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.0001e-04 - val_loss: 0.2025\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4366e-04 - val_loss: 0.2034\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1487e-05 - val_loss: 0.2021\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5718e-04 - val_loss: 0.2058\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2063\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2048\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2014\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2004\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2015\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.9402e-04 - val_loss: 0.2005\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.1997\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2009\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4616e-04 - val_loss: 0.2046\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8024e-04 - val_loss: 0.2003\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.1995\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2008\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9192e-04 - val_loss: 0.2046\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3013e-04 - val_loss: 0.2004\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.1997\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.2009\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.7610e-04 - val_loss: 0.2047\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7097e-04 - val_loss: 0.2007\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2012\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2039\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.0593e-04 - val_loss: 0.2011\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2004\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2016\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2046\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.2054\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2043\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2015\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.2008\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2020\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2057\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2047\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2025\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.4449e-04 - val_loss: 0.2053\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2061\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.2050\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2023\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5728e-04 - val_loss: 0.2017\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4720e-04 - val_loss: 0.2057\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2064\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.2054\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2027\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7119e-04 - val_loss: 0.2021\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2032\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2720e-04 - val_loss: 0.2025\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.7319e-04 - val_loss: 0.2036\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3498e-04 - val_loss: 0.2029\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0041e-04 - val_loss: 0.2040\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6975e-04 - val_loss: 0.2032\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0622e-04 - val_loss: 0.2008\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2003\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2017\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2046\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2056\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2047\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.4077e-04 - val_loss: 0.2016\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2029\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3878e-04 - val_loss: 0.2057\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2065\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2056\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2030\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1272e-05 - val_loss: 0.2024\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.5874e-04 - val_loss: 0.2036\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1682e-04 - val_loss: 0.2030\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2422e-04 - val_loss: 0.2041\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9660e-04 - val_loss: 0.2034\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1233e-04 - val_loss: 0.2011\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2007\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2021\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2050\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2060\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2051\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2027\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2979e-04 - val_loss: 0.2022\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3205e-04 - val_loss: 0.2034\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0322e-04 - val_loss: 0.2028\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6746e-04 - val_loss: 0.2040\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.9985e-04 - val_loss: 0.2034\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.7403e-04 - val_loss: 0.2011\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2008\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2022\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.1733e-04 - val_loss: 0.2051\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2061\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2053\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2029\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2531e-04 - val_loss: 0.2024\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0189e-04 - val_loss: 0.2037\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3982e-04 - val_loss: 0.2031\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.7321e-06 - val_loss: 0.2043\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5571e-04 - val_loss: 0.2015\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2011\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2025\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9275e-04 - val_loss: 0.2054\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2064\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2056\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.2032\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1845e-04 - val_loss: 0.1994\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.1977\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.1978\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.1996\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2028\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7862e-04 - val_loss: 0.2074\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2099\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0067 - val_loss: 0.2104\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0073 - val_loss: 0.2094\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - val_loss: 0.2068\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - val_loss: 0.2028\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.1617e-04 - val_loss: 0.2009\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2008\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2023\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0535e-04 - val_loss: 0.2053\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2064\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2058\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.2036\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8766e-04 - val_loss: 0.2000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.1984\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.1986\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 0.2004\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.2037\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4383e-04 - val_loss: 0.2050\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2045\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2026\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6651e-04 - val_loss: 0.2024\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4968e-04 - val_loss: 0.2038\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.7662e-04 - val_loss: 0.2035\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7362e-04 - val_loss: 0.2016\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.2015\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.2031\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.4270e-05 - val_loss: 0.2060\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - val_loss: 0.2071\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.2065\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - val_loss: 0.2044\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.1993\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 0.1995\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - val_loss: 0.2013\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 0.2057\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2053\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.0070e-04 - val_loss: 0.2000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.1986\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:13:58,620] Trial 79 finished with value: 0.004503354430198669 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1585 - val_loss: 0.3490\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1455 - val_loss: 0.3476\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1447 - val_loss: 0.3465\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1434 - val_loss: 0.3448\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1412 - val_loss: 0.3318\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1274 - val_loss: 0.3153\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1111 - val_loss: 0.2943\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0902 - val_loss: 0.2733\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0689 - val_loss: 0.2572\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0516 - val_loss: 0.2373\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0316 - val_loss: 0.2136\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0095 - val_loss: 0.1932\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0137 - val_loss: 0.1865\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0202 - val_loss: 0.1891\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0167 - val_loss: 0.1965\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 0.2069\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2104\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0062 - val_loss: 0.2089\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 0.2037\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6744e-04 - val_loss: 0.2027\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2052\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4106e-04 - val_loss: 0.1998\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.1992\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.2017\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2068\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2084\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.2069\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2029\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7258e-04 - val_loss: 0.2021\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0768e-04 - val_loss: 0.2030\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1655e-04 - val_loss: 0.2048\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5429e-04 - val_loss: 0.2004\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.1998\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2018\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2061\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2075\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2062\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2027\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8186e-04 - val_loss: 0.2020\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2037\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1066e-04 - val_loss: 0.2029\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0662e-04 - val_loss: 0.2045\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1596e-04 - val_loss: 0.2005\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.2019\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2059\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2071\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.2060\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2027\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4129e-04 - val_loss: 0.2020\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2638e-04 - val_loss: 0.2029\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3675e-04 - val_loss: 0.2045\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.7062e-04 - val_loss: 0.2007\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2002\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2020\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2058\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2071\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.2060\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2029\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9074e-04 - val_loss: 0.2022\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5899e-04 - val_loss: 0.2031\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7283e-04 - val_loss: 0.2046\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2038\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2231e-04 - val_loss: 0.2009\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2004\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2022\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2059\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2071\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2061\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2030\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.8852e-04 - val_loss: 0.2024\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.1080e-04 - val_loss: 0.2040\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4395e-04 - val_loss: 0.2033\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6981e-05 - val_loss: 0.2047\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1589e-04 - val_loss: 0.2011\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2007\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2047\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.1994\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.1992\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2032\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.8999e-04 - val_loss: 0.2028\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8548e-04 - val_loss: 0.1984\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.1985\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2022\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0413e-04 - val_loss: 0.2089\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.2114\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.2102\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.2061\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.1993\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.1964\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0064 - val_loss: 0.1968\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.2000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.2057\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2079\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - val_loss: 0.2072\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.2039\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.3473e-04 - val_loss: 0.1983\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.1960\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0070 - val_loss: 0.1965\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0065 - val_loss: 0.1994\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2046\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2067\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2061\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2032\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3404e-04 - val_loss: 0.1981\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - val_loss: 0.1960\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0071 - val_loss: 0.1965\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.1993\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2042\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2062\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2057\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2029\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7339e-04 - val_loss: 0.2027\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.6153e-04 - val_loss: 0.2048\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7951e-04 - val_loss: 0.2037\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9403e-04 - val_loss: 0.2012\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2012\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1298e-04 - val_loss: 0.2032\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7574e-05 - val_loss: 0.2007\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2008\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0887e-05 - val_loss: 0.2072\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.2088\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - val_loss: 0.2080\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2052\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.1984\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.1987\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.2011\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2054\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2071\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2066\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2039\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2630e-04 - val_loss: 0.1994\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.1975\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.1979\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - val_loss: 0.2003\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2047\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2064\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2059\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2034\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2245e-04 - val_loss: 0.1990\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.1972\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - val_loss: 0.1976\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2001\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2044\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2062\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2057\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2032\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5494e-04 - val_loss: 0.1990\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.1972\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.1976\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - val_loss: 0.2001\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2043\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2061\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2056\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2032\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3264e-04 - val_loss: 0.1990\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.1973\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1977\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.2002\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2043\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2061\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2056\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2033\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7379e-04 - val_loss: 0.1991\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.1974\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.1979\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.2003\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2044\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2061\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2057\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2033\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4334e-04 - val_loss: 0.1993\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.1976\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0055 - val_loss: 0.1980\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2004\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.2044\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2061\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2057\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2034\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2610e-04 - val_loss: 0.1994\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.1977\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0054 - val_loss: 0.1982\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - val_loss: 0.2005\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2045\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:14:17,271] Trial 80 finished with value: 0.0014169812202453613 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1476 - val_loss: 0.3297\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1087 - val_loss: 0.2659\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0601 - val_loss: 0.2214\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0164 - val_loss: 0.1811\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0220 - val_loss: 0.1776\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0247 - val_loss: 0.1853\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0173 - val_loss: 0.1949\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0085 - val_loss: 0.2058\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2097\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0060 - val_loss: 0.2088\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2044\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4568e-04 - val_loss: 0.1976\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - val_loss: 0.1948\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0088 - val_loss: 0.1952\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0084 - val_loss: 0.1982\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.2032\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.8545e-04 - val_loss: 0.2099\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.2134\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0097 - val_loss: 0.2142\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0105 - val_loss: 0.2127\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0091 - val_loss: 0.2092\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - val_loss: 0.2042\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9040e-04 - val_loss: 0.1977\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - val_loss: 0.1940\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0093 - val_loss: 0.1927\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0106 - val_loss: 0.1934\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0098 - val_loss: 0.1959\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0073 - val_loss: 0.2000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2053\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2083\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.2093\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.2085\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.2060\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2021\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5443e-04 - val_loss: 0.2003\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2004\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2023\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.6641e-04 - val_loss: 0.2055\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2067\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.2062\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2041\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2006\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.1991\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 0.1994\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2013\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2045\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2059\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2055\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2036\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6264e-04 - val_loss: 0.2002\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.1988\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.1992\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - val_loss: 0.2011\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2044\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2058\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2054\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2035\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3823e-04 - val_loss: 0.2003\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.1989\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.1993\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2012\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2045\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2059\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2056\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2038\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.3862e-04 - val_loss: 0.2005\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.1992\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 0.1996\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2015\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2048\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2062\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2059\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2041\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.3445e-04 - val_loss: 0.2009\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.1996\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.2019\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2065\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2062\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2044\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2012\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.1999\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2003\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2022\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.1884e-04 - val_loss: 0.2055\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2068\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.2066\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 0.2048\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2016\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2003\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2007\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2026\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4705e-04 - val_loss: 0.2058\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2072\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 0.2069\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2051\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2020\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2007\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2011\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2030\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7296e-04 - val_loss: 0.2062\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2075\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2073\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.2055\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.2024\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6005e-04 - val_loss: 0.2011\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2015\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0097e-04 - val_loss: 0.2035\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5724e-04 - val_loss: 0.2021\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3405e-04 - val_loss: 0.2042\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2043\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.2617e-04 - val_loss: 0.2031\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0850e-04 - val_loss: 0.2048\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2048\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4620e-04 - val_loss: 0.2005\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.1994\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.2000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2020\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2054\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2069\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2067\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2051\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2021\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2010\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2014\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9015e-04 - val_loss: 0.2036\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1592e-04 - val_loss: 0.2023\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.7839e-04 - val_loss: 0.2026\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4307e-04 - val_loss: 0.2044\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2046\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.2387e-07 - val_loss: 0.2004\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.1995\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2001\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.9193e-04 - val_loss: 0.2055\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2071\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.2070\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2054\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2025\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8258e-04 - val_loss: 0.2014\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2019\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0311e-04 - val_loss: 0.2040\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.4865e-04 - val_loss: 0.2028\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1331e-04 - val_loss: 0.2031\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3464e-05 - val_loss: 0.2049\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2050\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2037\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1865e-04 - val_loss: 0.2010\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2007\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2028\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2436e-04 - val_loss: 0.2061\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2076\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2075\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0043 - val_loss: 0.2060\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2031\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.6814e-05 - val_loss: 0.2020\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2025\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.1086e-04 - val_loss: 0.2044\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9793e-04 - val_loss: 0.2008\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.1999\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2006\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2027\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.3732e-04 - val_loss: 0.2061\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2077\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2076\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2061\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.2033\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3751e-04 - val_loss: 0.1993\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.1972\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.1967\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.1978\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - val_loss: 0.2003\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2040\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9764e-04 - val_loss: 0.2058\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2060\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2048\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2013\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4521e-04 - val_loss: 0.2044\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6207e-04 - val_loss: 0.2009\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2002\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2010\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2032\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5868e-05 - val_loss: 0.2066\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2082\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - val_loss: 0.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:14:36,322] Trial 81 finished with value: 0.004983887076377869 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1388 - val_loss: 0.3021\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0891 - val_loss: 0.2608\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0539 - val_loss: 0.2362\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0326 - val_loss: 0.2185\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0158 - val_loss: 0.2029\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7636e-04 - val_loss: 0.1872\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0155 - val_loss: 0.1797\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0229 - val_loss: 0.1779\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0247 - val_loss: 0.1797\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0230 - val_loss: 0.1837\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0191 - val_loss: 0.1890\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0138 - val_loss: 0.1952\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0077 - val_loss: 0.2019\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2091\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - val_loss: 0.2136\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0105 - val_loss: 0.2161\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0130 - val_loss: 0.2168\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0137 - val_loss: 0.2162\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0131 - val_loss: 0.2144\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0113 - val_loss: 0.2115\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - val_loss: 0.2077\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2030\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.8319e-05 - val_loss: 0.2001\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.1988\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.1988\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2001\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2025\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6641e-04 - val_loss: 0.2057\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2075\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2079\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.2071\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.2053\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - val_loss: 0.2025\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2808e-04 - val_loss: 0.2012\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2011\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2022\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.7054e-04 - val_loss: 0.2043\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2050\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2031\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.1484e-05 - val_loss: 0.2029\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8440e-04 - val_loss: 0.2038\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1525e-04 - val_loss: 0.2035\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1982e-04 - val_loss: 0.2021\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2030\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8167e-04 - val_loss: 0.2050\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2056\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.2052\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2037\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3880e-04 - val_loss: 0.2012\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2001\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2002\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2014\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7700e-04 - val_loss: 0.2045\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2028\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1787e-04 - val_loss: 0.2027\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5183e-04 - val_loss: 0.2037\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1431e-04 - val_loss: 0.2034\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0048e-04 - val_loss: 0.2022\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7662e-04 - val_loss: 0.2021\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2031\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4985e-06 - val_loss: 0.2051\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2059\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2055\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2040\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.7164e-04 - val_loss: 0.2016\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2006\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2007\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2019\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.4749e-04 - val_loss: 0.2050\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1213e-04 - val_loss: 0.2011\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2001\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2003\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2016\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2039\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.1403e-04 - val_loss: 0.2048\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2046\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4967e-04 - val_loss: 0.2011\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2001\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2004\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.2017\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.3266e-04 - val_loss: 0.2049\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4298e-04 - val_loss: 0.2013\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2004\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2007\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2020\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2042\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2052\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2050\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2038\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4461e-04 - val_loss: 0.2016\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2007\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2010\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2023\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.2012e-04 - val_loss: 0.2046\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2055\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2054\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2041\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9082e-04 - val_loss: 0.2020\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2011\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2027\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5492e-04 - val_loss: 0.2049\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2059\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2057\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2045\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2024\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9626e-04 - val_loss: 0.2015\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2018\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2031\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9706e-05 - val_loss: 0.2053\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2063\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2061\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2049\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1622e-04 - val_loss: 0.2019\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2021\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2034\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9781e-04 - val_loss: 0.2036\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1972e-04 - val_loss: 0.2026\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.2443e-04 - val_loss: 0.2028\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1734e-04 - val_loss: 0.2041\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.2313e-04 - val_loss: 0.2041\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8853e-04 - val_loss: 0.2031\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.2948e-06 - val_loss: 0.2033\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5873e-04 - val_loss: 0.2024\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.5024e-04 - val_loss: 0.2026\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1150e-04 - val_loss: 0.2039\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5726e-04 - val_loss: 0.2040\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4828e-04 - val_loss: 0.2030\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1916e-04 - val_loss: 0.2032\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2525e-05 - val_loss: 0.2023\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.2740e-04 - val_loss: 0.2026\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7195e-04 - val_loss: 0.2039\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.1135e-04 - val_loss: 0.2040\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.1594e-04 - val_loss: 0.2030\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3874e-04 - val_loss: 0.2032\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3883e-05 - val_loss: 0.2023\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.2560e-04 - val_loss: 0.2026\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.6139e-04 - val_loss: 0.2039\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.2914e-04 - val_loss: 0.2040\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4089e-04 - val_loss: 0.2030\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0660e-04 - val_loss: 0.2032\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.1732e-05 - val_loss: 0.2024\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.8186e-04 - val_loss: 0.2026\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1308e-04 - val_loss: 0.2039\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8072e-04 - val_loss: 0.2040\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9625e-04 - val_loss: 0.2031\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7117e-05 - val_loss: 0.2033\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5420e-04 - val_loss: 0.2024\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1591e-04 - val_loss: 0.2027\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4484e-04 - val_loss: 0.2040\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5020e-04 - val_loss: 0.2041\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6765e-04 - val_loss: 0.2032\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6882e-05 - val_loss: 0.2013\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2006\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.2011\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7355e-04 - val_loss: 0.2050\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2060\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2060\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.2049\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2029\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5125e-04 - val_loss: 0.2021\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2025\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6349e-04 - val_loss: 0.2039\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0879e-04 - val_loss: 0.2040\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9751e-04 - val_loss: 0.2032\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3946e-05 - val_loss: 0.2013\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2012\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2028\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7718e-04 - val_loss: 0.2052\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2063\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2063\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.2052\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2032\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0109e-04 - val_loss: 0.2004\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1989\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.1986\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.1994\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2012\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2038\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.8532e-04 - val_loss: 0.2052\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - val_loss: 0.2053\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2044\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3114e-04 - val_loss: 0.2020\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4304e-04 - val_loss: 0.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:14:55,541] Trial 82 finished with value: 0.0008420497179031372 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1592 - val_loss: 0.3302\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1212 - val_loss: 0.2966\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0902 - val_loss: 0.2678\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0613 - val_loss: 0.2445\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0397 - val_loss: 0.2247\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0209 - val_loss: 0.2089\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.1934\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0106 - val_loss: 0.1862\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0178 - val_loss: 0.1845\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0193 - val_loss: 0.1867\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0169 - val_loss: 0.1918\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0117 - val_loss: 0.1991\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 0.2079\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.2126\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - val_loss: 0.2141\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0107 - val_loss: 0.2129\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0096 - val_loss: 0.2096\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0064 - val_loss: 0.2046\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.1984\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0047 - val_loss: 0.1950\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0082 - val_loss: 0.1939\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0093 - val_loss: 0.1948\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0084 - val_loss: 0.1974\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.2014\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2065\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - val_loss: 0.2095\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.2104\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0073 - val_loss: 0.2098\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - val_loss: 0.2076\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2042\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.1996\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.1971\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - val_loss: 0.1963\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0069 - val_loss: 0.1971\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.1993\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2027\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5374e-04 - val_loss: 0.2072\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2098\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0066 - val_loss: 0.2107\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0075 - val_loss: 0.2101\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.2082\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.2052\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2011\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.1989\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.1983\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.1995\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.2021\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2061\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2080\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.2081\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - val_loss: 0.2067\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.2040\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8632e-04 - val_loss: 0.2000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.1980\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.1977\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.1988\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.2012\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0020 - val_loss: 0.2048\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2066\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - val_loss: 0.2068\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2057\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2033\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5886e-04 - val_loss: 0.1998\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.1981\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.1978\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.1990\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.2013\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2065\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.2068\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2057\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2035\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4960e-04 - val_loss: 0.2002\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.1985\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.1983\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.1994\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - val_loss: 0.2017\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2051\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2068\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2070\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.2061\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2039\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7467e-04 - val_loss: 0.2007\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.1991\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.1989\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.2000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7589e-04 - val_loss: 0.2055\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2072\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.2075\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.2065\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2044\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2013\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.1997\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.1995\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.2006\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2028\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2067e-04 - val_loss: 0.2060\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2077\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.2079\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.2070\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2049\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2003\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2001\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2012\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3495e-04 - val_loss: 0.2041\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7591e-04 - val_loss: 0.2036\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.3963e-04 - val_loss: 0.2019\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2016\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2025\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3135e-04 - val_loss: 0.2045\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2045\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4782e-04 - val_loss: 0.2024\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3150e-04 - val_loss: 0.2032\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2127e-04 - val_loss: 0.2028\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0674e-04 - val_loss: 0.2036\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0288e-04 - val_loss: 0.2032\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9086e-05 - val_loss: 0.2015\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2013\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2023\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5723e-04 - val_loss: 0.2043\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2050\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.2479e-04 - val_loss: 0.2023\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.7689e-04 - val_loss: 0.2032\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6381e-05 - val_loss: 0.2028\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0544e-04 - val_loss: 0.2036\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2021e-04 - val_loss: 0.2032\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8186e-05 - val_loss: 0.2016\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2014\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6649e-04 - val_loss: 0.2044\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2051\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2045\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9442e-04 - val_loss: 0.2025\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3658e-04 - val_loss: 0.2034\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3931e-04 - val_loss: 0.2030\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5391e-04 - val_loss: 0.2038\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.7334e-04 - val_loss: 0.2034\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3887e-04 - val_loss: 0.2018\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2025\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8864e-04 - val_loss: 0.2046\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2053\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2047\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0742e-04 - val_loss: 0.2027\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4571e-04 - val_loss: 0.2036\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2792e-04 - val_loss: 0.2032\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8370e-05 - val_loss: 0.2016\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2014\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.8036e-04 - val_loss: 0.2045\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2047\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0176e-04 - val_loss: 0.2027\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2003e-04 - val_loss: 0.2036\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6709e-04 - val_loss: 0.2032\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.4280e-05 - val_loss: 0.2017\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2025\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8468e-04 - val_loss: 0.2046\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2053\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2048\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5839e-05 - val_loss: 0.2005\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.1993\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.1994\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2006\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2029\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9127e-04 - val_loss: 0.2062\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2079\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.2083\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.2075\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2057\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2029\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3729e-04 - val_loss: 0.2015\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2014\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2025\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9661e-04 - val_loss: 0.2047\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2054\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2050\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.0009e-04 - val_loss: 0.2009\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.1997\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.1999\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2011\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2034\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.1009e-04 - val_loss: 0.2044\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.1246e-04 - val_loss: 0.2026\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1130e-04 - val_loss: 0.2025\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4954e-04 - val_loss: 0.2035\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:15:14,074] Trial 83 finished with value: 0.0003688931465148926 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1168 - val_loss: 0.1788\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0686 - val_loss: 0.2349\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0299 - val_loss: 0.2202\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.1820\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0303 - val_loss: 0.1842\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0248 - val_loss: 0.2042\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - val_loss: 0.2299\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0224 - val_loss: 0.2379\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0300 - val_loss: 0.2349\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0268 - val_loss: 0.2249\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0170 - val_loss: 0.2105\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.1931\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0150 - val_loss: 0.1842\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0239 - val_loss: 0.1822\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0258 - val_loss: 0.1856\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0220 - val_loss: 0.1930\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0143 - val_loss: 0.2030\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.2155\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0091 - val_loss: 0.2219\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0157 - val_loss: 0.2235\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0178 - val_loss: 0.2221\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0172 - val_loss: 0.2185\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0138 - val_loss: 0.2127\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - val_loss: 0.2049\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.9523e-04 - val_loss: 0.1954\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0088 - val_loss: 0.1896\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0145 - val_loss: 0.1871\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0169 - val_loss: 0.1873\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0166 - val_loss: 0.1900\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0138 - val_loss: 0.1948\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0090 - val_loss: 0.2014\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - val_loss: 0.2094\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0057 - val_loss: 0.2143\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0106 - val_loss: 0.2165\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0128 - val_loss: 0.2163\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0127 - val_loss: 0.2140\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0104 - val_loss: 0.2098\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - val_loss: 0.2038\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.3726e-04 - val_loss: 0.1964\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0070 - val_loss: 0.1919\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0116 - val_loss: 0.1899\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0135 - val_loss: 0.1903\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0130 - val_loss: 0.1928\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0105 - val_loss: 0.1971\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0062 - val_loss: 0.2030\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.9755e-04 - val_loss: 0.2103\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.2148\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0115 - val_loss: 0.2169\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0136 - val_loss: 0.2168\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0134 - val_loss: 0.2146\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0113 - val_loss: 0.2108\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0075 - val_loss: 0.2053\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.1984\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.1942\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0090 - val_loss: 0.1924\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0108 - val_loss: 0.1928\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0104 - val_loss: 0.1952\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0081 - val_loss: 0.1993\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2049\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2080\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - val_loss: 0.2088\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.2076\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2047\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.1978\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.1978\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.1996\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2033\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1742e-05 - val_loss: 0.2046\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3227e-04 - val_loss: 0.2013\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2010\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2025\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3355e-04 - val_loss: 0.2058\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2069\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2060\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2033\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1042e-05 - val_loss: 0.1989\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.1969\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - val_loss: 0.1970\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.1990\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.2027\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6668e-04 - val_loss: 0.2079\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.2105\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0070 - val_loss: 0.2105\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - val_loss: 0.2085\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.2046\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.1990\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.1961\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0073 - val_loss: 0.1957\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0077 - val_loss: 0.1975\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - val_loss: 0.2012\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2065\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2093\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - val_loss: 0.2097\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - val_loss: 0.2081\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.2046\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.1995\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.1969\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - val_loss: 0.1966\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0067 - val_loss: 0.1984\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - val_loss: 0.2020\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2072\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2099\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0065 - val_loss: 0.2103\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - val_loss: 0.2088\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.2054\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2004\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.1979\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.1976\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.1993\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2028\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0817e-04 - val_loss: 0.2079\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.2106\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0072 - val_loss: 0.2110\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0077 - val_loss: 0.2095\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - val_loss: 0.2062\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2012\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.1988\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.1985\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2002\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2036\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6985e-04 - val_loss: 0.2048\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2039\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7237e-04 - val_loss: 0.2012\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2007\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2022\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2054\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2064\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2054\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5904e-04 - val_loss: 0.2020\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9206e-05 - val_loss: 0.2064\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2073\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2063\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2034\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.3795e-05 - val_loss: 0.1989\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.1967\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.1967\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - val_loss: 0.1987\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.2023\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2074\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - val_loss: 0.2102\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - val_loss: 0.2108\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.2094\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - val_loss: 0.2063\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2016\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.1993\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.1991\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.2009\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2043\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.6203e-04 - val_loss: 0.2055\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2047\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2021\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7351e-04 - val_loss: 0.2064\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.2074\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.2064\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2037\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5566e-04 - val_loss: 0.1993\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.1973\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.1974\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.1993\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.2030\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.6706e-04 - val_loss: 0.2081\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.2108\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.2114\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.2101\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - val_loss: 0.2071\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2026\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6713e-04 - val_loss: 0.2003\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2001\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2019\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2052\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2064\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2057\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2032\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5387e-04 - val_loss: 0.2027\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8156e-04 - val_loss: 0.2042\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.7944e-04 - val_loss: 0.2037\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.5153e-04 - val_loss: 0.2013\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2011\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2027\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.7724e-04 - val_loss: 0.2060\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.2072\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2064\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2038\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9801e-04 - val_loss: 0.1997\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.1978\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.1979\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.1999\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2035\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1878e-04 - val_loss: 0.2050\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2044\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0559e-04 - val_loss: 0.2030\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:15:32,624] Trial 84 finished with value: 0.00028495490550994873 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1667 - val_loss: 0.3677\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1663 - val_loss: 0.3446\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1411 - val_loss: 0.3429\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1394 - val_loss: 0.3413\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1378 - val_loss: 0.3393\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1358 - val_loss: 0.3379\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1364 - val_loss: 0.3361\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1328 - val_loss: 0.3351\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1317 - val_loss: 0.3339\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1306 - val_loss: 0.3326\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1292 - val_loss: 0.3311\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1277 - val_loss: 0.3295\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1263 - val_loss: 0.3279\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1247 - val_loss: 0.3262\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1231 - val_loss: 0.3245\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1214 - val_loss: 0.3226\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1195 - val_loss: 0.3204\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1173 - val_loss: 0.3181\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1150 - val_loss: 0.3157\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1126 - val_loss: 0.3133\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1101 - val_loss: 0.3108\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1076 - val_loss: 0.3099\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1070 - val_loss: 0.3061\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1029 - val_loss: 0.3039\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1006 - val_loss: 0.3014\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0982 - val_loss: 0.2988\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0956 - val_loss: 0.2961\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0929 - val_loss: 0.2932\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0901 - val_loss: 0.2904\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0873 - val_loss: 0.2874\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0844 - val_loss: 0.2846\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0813 - val_loss: 0.2832\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0797 - val_loss: 0.2786\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0753 - val_loss: 0.2754\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0723 - val_loss: 0.2722\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0692 - val_loss: 0.2689\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0659 - val_loss: 0.2655\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0625 - val_loss: 0.2618\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0588 - val_loss: 0.2589\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0556 - val_loss: 0.2546\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0516 - val_loss: 0.2509\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0479 - val_loss: 0.2469\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0439 - val_loss: 0.2428\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0398 - val_loss: 0.2384\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0354 - val_loss: 0.2338\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0308 - val_loss: 0.2289\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0259 - val_loss: 0.2253\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0222 - val_loss: 0.2187\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0156 - val_loss: 0.2138\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0107 - val_loss: 0.2087\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - val_loss: 0.2030\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.1524e-05 - val_loss: 0.1991\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 0.1968\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0063 - val_loss: 0.1956\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - val_loss: 0.1953\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0078 - val_loss: 0.1960\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0071 - val_loss: 0.1974\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - val_loss: 0.1994\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.2020\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2069\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.2078\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - val_loss: 0.2080\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - val_loss: 0.2075\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.2063\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2046\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2024\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.7713e-04 - val_loss: 0.2010\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2006\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2008\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2017\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2032\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.5250e-05 - val_loss: 0.2039\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4956e-04 - val_loss: 0.2038\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.8441e-04 - val_loss: 0.2031\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0980e-05 - val_loss: 0.2031\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6078e-05 - val_loss: 0.2038\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.4978e-04 - val_loss: 0.2037\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9856e-04 - val_loss: 0.2030\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.3058e-05 - val_loss: 0.2031\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.8083e-05 - val_loss: 0.2037\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9663e-04 - val_loss: 0.2037\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5449e-04 - val_loss: 0.2030\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1981e-04 - val_loss: 0.2031\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.8528e-05 - val_loss: 0.2037\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7353e-04 - val_loss: 0.2037\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3728e-04 - val_loss: 0.2030\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2414e-04 - val_loss: 0.2031\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.8915e-05 - val_loss: 0.2037\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6972e-04 - val_loss: 0.2037\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3731e-04 - val_loss: 0.2030\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1432e-04 - val_loss: 0.2031\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6666e-05 - val_loss: 0.2037\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7818e-04 - val_loss: 0.2037\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4826e-04 - val_loss: 0.2030\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5636e-05 - val_loss: 0.2031\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6550e-05 - val_loss: 0.2037\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9450e-04 - val_loss: 0.2037\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6618e-04 - val_loss: 0.2031\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1511e-05 - val_loss: 0.2031\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1605e-05 - val_loss: 0.2038\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1572e-04 - val_loss: 0.2037\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8851e-04 - val_loss: 0.2031\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4107e-05 - val_loss: 0.2031\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.7700e-06 - val_loss: 0.2038\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4003e-04 - val_loss: 0.2038\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1353e-04 - val_loss: 0.2031\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4797e-05 - val_loss: 0.2032\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5705e-05 - val_loss: 0.2026\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4352e-04 - val_loss: 0.2027\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.4876e-04 - val_loss: 0.2034\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4118e-04 - val_loss: 0.2034\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5888e-04 - val_loss: 0.2028\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2674e-04 - val_loss: 0.2029\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5082e-04 - val_loss: 0.2036\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1845e-04 - val_loss: 0.2036\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2132e-04 - val_loss: 0.2030\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7427e-04 - val_loss: 0.2030\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1070e-04 - val_loss: 0.2037\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4435e-04 - val_loss: 0.2037\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.3753e-04 - val_loss: 0.2031\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3837e-05 - val_loss: 0.2031\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.3894e-06 - val_loss: 0.2038\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3668e-04 - val_loss: 0.2038\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2352e-04 - val_loss: 0.2032\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8999e-05 - val_loss: 0.2020\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4720e-04 - val_loss: 0.2039\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5404e-04 - val_loss: 0.2045\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2166e-04 - val_loss: 0.2026\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4921e-04 - val_loss: 0.2021\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2023\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.3527e-04 - val_loss: 0.2031\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.4177e-05 - val_loss: 0.2043\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2048\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2041\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7591e-04 - val_loss: 0.2029\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0298e-04 - val_loss: 0.2025\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.7885e-04 - val_loss: 0.2026\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1813e-04 - val_loss: 0.2033\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1321e-04 - val_loss: 0.2034\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.8591e-04 - val_loss: 0.2029\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3259e-04 - val_loss: 0.2030\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1404e-04 - val_loss: 0.2037\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7609e-04 - val_loss: 0.2038\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1508e-04 - val_loss: 0.2032\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9126e-05 - val_loss: 0.2021\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2017\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4222e-04 - val_loss: 0.2041\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6047e-04 - val_loss: 0.2047\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2046\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2040\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.9651e-04 - val_loss: 0.2029\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3402e-04 - val_loss: 0.2025\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7253e-04 - val_loss: 0.2027\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8457e-04 - val_loss: 0.2034\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6493e-04 - val_loss: 0.2035\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6028e-04 - val_loss: 0.2030\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3153e-04 - val_loss: 0.2031\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6641e-06 - val_loss: 0.2027\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5149e-04 - val_loss: 0.2029\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8218e-04 - val_loss: 0.2036\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4803e-04 - val_loss: 0.2037\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2857e-04 - val_loss: 0.2032\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5705e-05 - val_loss: 0.2021\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2018\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2029\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6534e-04 - val_loss: 0.2042\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 0.2048\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2048\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2031\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8113e-05 - val_loss: 0.2026\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8923e-04 - val_loss: 0.2028\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9160e-04 - val_loss: 0.2036\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6067e-04 - val_loss: 0.2037\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6441e-04 - val_loss: 0.2032\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5935e-05 - val_loss: 0.2022\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.2031e-04 - val_loss: 0.2019\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.6768e-04 - val_loss: 0.2030\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3784e-04 - val_loss: 0.2043\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2049\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2049\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0912e-04 - val_loss: 0.2017\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2009\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2007\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2011\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2035\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:15:51,093] Trial 85 finished with value: 0.0003962218761444092 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1260 - val_loss: 0.2336\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0087 - val_loss: 0.1043\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1156 - val_loss: 0.0966\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1087 - val_loss: 0.1385\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0635 - val_loss: 0.1980\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - val_loss: 0.2439\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0419 - val_loss: 0.2603\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0584 - val_loss: 0.2618\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0599 - val_loss: 0.2537\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0519 - val_loss: 0.2397\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0376 - val_loss: 0.2229\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0209 - val_loss: 0.2027\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4285e-04 - val_loss: 0.1797\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0226 - val_loss: 0.1672\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0351 - val_loss: 0.1628\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0396 - val_loss: 0.1643\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0381 - val_loss: 0.1701\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0323 - val_loss: 0.1789\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0236 - val_loss: 0.1898\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0128 - val_loss: 0.2023\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.0296e-04 - val_loss: 0.2160\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0133 - val_loss: 0.2248\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0221 - val_loss: 0.2294\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0267 - val_loss: 0.2305\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0278 - val_loss: 0.2285\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0259 - val_loss: 0.2239\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0213 - val_loss: 0.2169\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0143 - val_loss: 0.2078\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0053 - val_loss: 0.1969\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0057 - val_loss: 0.1899\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0127 - val_loss: 0.1865\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0161 - val_loss: 0.1864\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0162 - val_loss: 0.1891\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0135 - val_loss: 0.1943\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0084 - val_loss: 0.2016\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2107\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0080 - val_loss: 0.2163\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0134 - val_loss: 0.2186\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0158 - val_loss: 0.2181\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0153 - val_loss: 0.2152\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0123 - val_loss: 0.2100\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0071 - val_loss: 0.2028\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.5755e-05 - val_loss: 0.1988\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - val_loss: 0.1978\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0050 - val_loss: 0.1995\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.2035\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2978e-04 - val_loss: 0.2046\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7996e-04 - val_loss: 0.1992\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.1982\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - val_loss: 0.1999\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2038\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7832e-04 - val_loss: 0.2049\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.2041e-04 - val_loss: 0.1995\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.1985\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.2002\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2041\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2036\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4696e-04 - val_loss: 0.1998\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.1988\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.2004\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2043\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2053\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.6738e-04 - val_loss: 0.2000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - val_loss: 0.1991\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.2006\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2045\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2056\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2041\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2003\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.1993\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - val_loss: 0.2009\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2047\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2058\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2043\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2005\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.1995\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.2011\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2050\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2060\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - val_loss: 0.2045\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.2007\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.1998\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2013\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2052\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2062\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - val_loss: 0.2047\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2009\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2015\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2054\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2064\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2049\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2012\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2002\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2018\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2056\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2066\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.2051\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2004\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2020\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2058\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.2068\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2054\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2016\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2006\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2022\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.0343e-04 - val_loss: 0.2060\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2071\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2056\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2018\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2009\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2024\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9173e-04 - val_loss: 0.2062\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2073\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2058\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2020\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.8117e-04 - val_loss: 0.2011\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8080e-04 - val_loss: 0.2064\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2075\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2060\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2022\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.6991e-04 - val_loss: 0.2013\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7065e-04 - val_loss: 0.2067\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2077\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - val_loss: 0.2062\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.2025\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5943e-04 - val_loss: 0.2015\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2031\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.8654e-05 - val_loss: 0.2020\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.7361e-04 - val_loss: 0.2035\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2637e-04 - val_loss: 0.2025\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.3190e-04 - val_loss: 0.2039\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.2474e-04 - val_loss: 0.2029\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7071e-04 - val_loss: 0.2043\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2523e-04 - val_loss: 0.1997\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.1991\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.2009\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2062\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2049\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2013\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2022\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.3844e-04 - val_loss: 0.2061\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2072\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2059\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2022\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9618e-04 - val_loss: 0.2014\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2030\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4882e-05 - val_loss: 0.2068\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2079\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2065\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2028\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0374e-04 - val_loss: 0.2019\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7317e-04 - val_loss: 0.2025\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9874e-04 - val_loss: 0.2041\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.2030\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7684e-07 - val_loss: 0.1997\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.1991\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2010\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2051\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2064\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2051\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2016\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2009\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2026\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2678e-04 - val_loss: 0.2065\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2077\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.2064\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2028\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6859e-04 - val_loss: 0.2019\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1969e-04 - val_loss: 0.2026\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9977e-04 - val_loss: 0.2042\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2032\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8062e-04 - val_loss: 0.2000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.1994\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2013\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2054\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2067\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2055\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2020\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - val_loss: 0.2013\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2030\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8774e-05 - val_loss: 0.2069\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2081\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.2068\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2032\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7565e-04 - val_loss: 0.1976\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.1950\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0081 - val_loss: 0.1950\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:16:08,993] Trial 86 finished with value: 0.008062705397605896 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1516 - val_loss: 0.3130\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0993 - val_loss: 0.2806\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0725 - val_loss: 0.2214\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0109 - val_loss: 0.1497\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0617 - val_loss: 0.1408\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0652 - val_loss: 0.1640\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0405 - val_loss: 0.1856\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0177 - val_loss: 0.2082\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2190\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0147 - val_loss: 0.2213\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0168 - val_loss: 0.2177\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0133 - val_loss: 0.2100\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0057 - val_loss: 0.1994\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 0.1945\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0095 - val_loss: 0.1941\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0098 - val_loss: 0.1974\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0065 - val_loss: 0.2039\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.8786e-04 - val_loss: 0.2129\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0088 - val_loss: 0.2175\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0133 - val_loss: 0.2182\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0140 - val_loss: 0.2156\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0115 - val_loss: 0.2102\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0062 - val_loss: 0.2024\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.1986\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 0.1980\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0056 - val_loss: 0.2003\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2051\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2066\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2054\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2017\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2009\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2029\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.0573e-04 - val_loss: 0.2071\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.2084\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0050 - val_loss: 0.2071\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.2034\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.3982e-05 - val_loss: 0.1977\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.1950\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0083 - val_loss: 0.1950\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0082 - val_loss: 0.1975\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0058 - val_loss: 0.2021\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2086\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0054 - val_loss: 0.2121\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0088 - val_loss: 0.2128\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0096 - val_loss: 0.2111\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0079 - val_loss: 0.2073\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2015\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.1987\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - val_loss: 0.1984\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - val_loss: 0.2005\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2047\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2062\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2052\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2015\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2033\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2750e-05 - val_loss: 0.2026\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1116e-04 - val_loss: 0.2043\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - val_loss: 0.2035\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.8957e-04 - val_loss: 0.2006\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - val_loss: 0.2002\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - val_loss: 0.2021\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.2060\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - val_loss: 0.2074\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - val_loss: 0.2063\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - val_loss: 0.2031\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.4057e-05 - val_loss: 0.2025\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.0609e-04 - val_loss: 0.2042\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6300e-04 - val_loss: 0.2035\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.3991e-04 - val_loss: 0.2006\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2002\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - val_loss: 0.2021\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.2061\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - val_loss: 0.2074\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - val_loss: 0.2064\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - val_loss: 0.2032\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2650e-06 - val_loss: 0.2026\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0725e-04 - val_loss: 0.2043\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2036\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.5146e-04 - val_loss: 0.2007\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - val_loss: 0.2004\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.2023\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.4791e-04 - val_loss: 0.2062\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2075\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2065\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2034\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5856e-04 - val_loss: 0.1984\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.1961\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0071 - val_loss: 0.1963\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0070 - val_loss: 0.1986\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - val_loss: 0.2029\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5144e-04 - val_loss: 0.2089\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0057 - val_loss: 0.2122\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0089 - val_loss: 0.2129\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0097 - val_loss: 0.2114\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0082 - val_loss: 0.2080\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.2027\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.9031e-04 - val_loss: 0.2001\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.1999\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2019\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2058\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - val_loss: 0.2073\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.2064\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.2035\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1857e-04 - val_loss: 0.1987\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - val_loss: 0.1966\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0067 - val_loss: 0.1968\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0065 - val_loss: 0.1991\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2034\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1292e-04 - val_loss: 0.2051\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2045\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2015\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2778e-04 - val_loss: 0.2030\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0242e-04 - val_loss: 0.2047\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2041\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.6807e-04 - val_loss: 0.2015\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2013\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.7650e-05 - val_loss: 0.2070\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - val_loss: 0.2083\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0051 - val_loss: 0.2074\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.2045\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.1998\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.1977\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0056 - val_loss: 0.1979\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.2001\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2043\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2059\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2053\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2027\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8931e-04 - val_loss: 0.2024\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.7473e-04 - val_loss: 0.2042\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.5882e-04 - val_loss: 0.2038\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.2240e-04 - val_loss: 0.2013\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2012\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2031\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3600e-04 - val_loss: 0.2070\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - val_loss: 0.2083\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2075\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.2047\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2001\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.1980\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.1983\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2006\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2047\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2063\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2057\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2032\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0093e-04 - val_loss: 0.2029\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.6159e-04 - val_loss: 0.2047\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2043\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4779e-04 - val_loss: 0.2034\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4338e-04 - val_loss: 0.2011\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2010\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9807e-04 - val_loss: 0.2069\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2084\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.2076\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2049\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2004\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.1984\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.1987\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2010\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - val_loss: 0.2051\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2068\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2062\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2037\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3693e-04 - val_loss: 0.1994\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.1975\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - val_loss: 0.1979\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.2003\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.2046\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2063\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2058\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.2034\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4929e-04 - val_loss: 0.1992\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.1974\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - val_loss: 0.1979\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - val_loss: 0.2003\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2063\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2059\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2035\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6131e-04 - val_loss: 0.1993\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.1976\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0056 - val_loss: 0.1981\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.2005\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2065\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2062\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2038\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4336e-04 - val_loss: 0.1997\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.1980\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.1984\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.2009\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:16:26,203] Trial 87 finished with value: 0.002364546060562134 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1369 - val_loss: 0.2360\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0084 - val_loss: 0.1331\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0829 - val_loss: 0.1269\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0785 - val_loss: 0.1517\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0504 - val_loss: 0.1829\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0199 - val_loss: 0.2080\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.2142\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0083 - val_loss: 0.2077\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.1948\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0107 - val_loss: 0.1918\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0131 - val_loss: 0.1957\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0090 - val_loss: 0.2045\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.2437e-05 - val_loss: 0.2171\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0123 - val_loss: 0.2225\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0175 - val_loss: 0.2223\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0171 - val_loss: 0.2166\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0117 - val_loss: 0.2073\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.1949\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0098 - val_loss: 0.1887\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0158 - val_loss: 0.1877\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0167 - val_loss: 0.1909\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0134 - val_loss: 0.1973\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0070 - val_loss: 0.2060\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2101\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.2106\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.2080\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2029\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2027\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2066\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2074\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2056\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2014\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2003\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2018\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2056\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2065\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2050\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2012\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2002\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 0.2018\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2054\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2064\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2050\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2015\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2006\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.2021\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.2057\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2067\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2054\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2012\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2026\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2061\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2071\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2058\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2026\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5778e-04 - val_loss: 0.2066\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2075\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2063\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2031\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0333e-04 - val_loss: 0.2024\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.7955e-05 - val_loss: 0.2029\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.8729e-04 - val_loss: 0.2043\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4710e-04 - val_loss: 0.2034\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.0845e-04 - val_loss: 0.2047\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.7562e-04 - val_loss: 0.2038\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.7872e-05 - val_loss: 0.2009\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2004\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2020\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2055\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2066\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2056\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2027\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2020\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6680e-04 - val_loss: 0.2068\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2078\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.2067\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 0.2038\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1209e-04 - val_loss: 0.1991\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0046 - val_loss: 0.1969\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - val_loss: 0.1970\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0067 - val_loss: 0.1990\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.2029\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7464e-04 - val_loss: 0.2082\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.2111\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0075 - val_loss: 0.2117\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0081 - val_loss: 0.2104\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - val_loss: 0.2074\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.2027\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.9306e-04 - val_loss: 0.2004\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2003\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.2021\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2056\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2068\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2061\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2035\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2010e-05 - val_loss: 0.2031\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1753e-04 - val_loss: 0.2046\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.8447e-04 - val_loss: 0.2018\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2016\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2032\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.9045e-04 - val_loss: 0.2066\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.2078\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0042 - val_loss: 0.2070\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2044\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.9827e-04 - val_loss: 0.2002\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.1984\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - val_loss: 0.1985\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.2006\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2042\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.2674e-04 - val_loss: 0.2057\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2051\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.4646e-04 - val_loss: 0.2026\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.8328e-04 - val_loss: 0.2042\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3531e-04 - val_loss: 0.2038\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.6588e-04 - val_loss: 0.2017\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2016\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2033\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7668e-04 - val_loss: 0.2067\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2079\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2072\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2047\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2007\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.1989\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.1991\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 0.2011\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2048\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2062\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2057\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2035\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7313e-05 - val_loss: 0.1997\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 0.1980\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0054 - val_loss: 0.1984\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.2005\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2042\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7991e-04 - val_loss: 0.2058\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2054\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2032\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0958e-04 - val_loss: 0.2031\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4709e-04 - val_loss: 0.2047\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2045\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2024\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8043e-04 - val_loss: 0.2039\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6727e-04 - val_loss: 0.2019\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2019\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2037\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9460e-04 - val_loss: 0.2036\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2849e-04 - val_loss: 0.2016\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2035\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.0199e-05 - val_loss: 0.2034\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5044e-05 - val_loss: 0.2050\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2047\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2027\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.1985e-04 - val_loss: 0.2026\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6813e-04 - val_loss: 0.2044\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.5819e-04 - val_loss: 0.2042\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.4661e-04 - val_loss: 0.2022\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7635e-04 - val_loss: 0.2038\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1117e-04 - val_loss: 0.2019\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2038\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5368e-04 - val_loss: 0.2036\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1896e-04 - val_loss: 0.2017\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2018\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3541e-04 - val_loss: 0.2035\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2073e-04 - val_loss: 0.2017\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2017\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8555e-04 - val_loss: 0.2035\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3983e-05 - val_loss: 0.2016\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8044e-04 - val_loss: 0.2035\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.7500e-05 - val_loss: 0.2016\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0455e-04 - val_loss: 0.2035\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1729e-04 - val_loss: 0.2017\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2018\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2036\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4772e-04 - val_loss: 0.2036\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6415e-04 - val_loss: 0.2017\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2018\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0315e-04 - val_loss: 0.2036\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2203e-04 - val_loss: 0.2018\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:16:41,620] Trial 88 finished with value: 0.0014913231134414673 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1363 - val_loss: 0.3103\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0978 - val_loss: 0.2474\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.2010\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.1975\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - val_loss: 0.2080\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - val_loss: 0.2079\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.2014\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2018\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2060\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2058\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.2026\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4118e-04 - val_loss: 0.2026\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9467e-04 - val_loss: 0.2055\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2054\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2028\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1139e-04 - val_loss: 0.2028\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.3362e-05 - val_loss: 0.2006\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2009\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2034\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9347e-04 - val_loss: 0.2035\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.8130e-04 - val_loss: 0.2014\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2040\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.7571e-04 - val_loss: 0.2022\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1624e-04 - val_loss: 0.2044\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2025\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2237e-04 - val_loss: 0.2027\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.6723e-05 - val_loss: 0.2047\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2048\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2029\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1316e-04 - val_loss: 0.1994\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.1997\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2034\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8507e-05 - val_loss: 0.2101\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.2121\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0084 - val_loss: 0.2105\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0069 - val_loss: 0.2061\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.1996\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - val_loss: 0.1966\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0065 - val_loss: 0.1966\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0064 - val_loss: 0.1991\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2037\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5015e-04 - val_loss: 0.2054\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2047\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2019\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.4191e-04 - val_loss: 0.2029\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0088e-05 - val_loss: 0.2046\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2041\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2013\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2077e-04 - val_loss: 0.2027\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6479e-04 - val_loss: 0.2043\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2038\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.7167e-04 - val_loss: 0.2014\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2030\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8238e-05 - val_loss: 0.2027\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2243e-04 - val_loss: 0.2043\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2038\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2320e-04 - val_loss: 0.2015\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2013\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2031\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0366e-05 - val_loss: 0.2027\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.8086e-04 - val_loss: 0.2043\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6252e-04 - val_loss: 0.2016\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2014\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2873e-04 - val_loss: 0.2028\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9138e-04 - val_loss: 0.2044\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.2040\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.4388e-04 - val_loss: 0.2017\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2016\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3212e-04 - val_loss: 0.2030\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.1316e-05 - val_loss: 0.2045\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - val_loss: 0.2019\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2017\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2034\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4411e-04 - val_loss: 0.2031\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4839e-05 - val_loss: 0.2010\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2009\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.2027\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.6658e-04 - val_loss: 0.2061\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2074\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - val_loss: 0.2067\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2043\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2003\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - val_loss: 0.1986\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.1988\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - val_loss: 0.2008\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2044\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.2059\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.2054\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2032\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.7979e-05 - val_loss: 0.1995\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.1979\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0052 - val_loss: 0.1982\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - val_loss: 0.2003\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - val_loss: 0.2039\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.5193e-04 - val_loss: 0.2054\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2050\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7013e-04 - val_loss: 0.2028\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.9640e-04 - val_loss: 0.2044\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2022\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.0094e-04 - val_loss: 0.2022\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.4183e-04 - val_loss: 0.2039\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.9892e-04 - val_loss: 0.2037\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.0433e-04 - val_loss: 0.2018\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2018\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2035\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.5796e-04 - val_loss: 0.2034\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.0851e-04 - val_loss: 0.2016\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2016\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7057e-04 - val_loss: 0.2032\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9964e-05 - val_loss: 0.2014\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2015\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0884e-05 - val_loss: 0.2031\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.1249e-05 - val_loss: 0.2047\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2045\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7025e-04 - val_loss: 0.2026\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9852e-04 - val_loss: 0.2042\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2040\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3984e-04 - val_loss: 0.2022\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6600e-04 - val_loss: 0.2022\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.4567e-04 - val_loss: 0.2039\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.1646e-04 - val_loss: 0.2037\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7340e-04 - val_loss: 0.2020\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.4571e-04 - val_loss: 0.2036\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.2866e-04 - val_loss: 0.2018\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2019\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.6371e-04 - val_loss: 0.2035\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6372e-04 - val_loss: 0.2018\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2019\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.3978e-04 - val_loss: 0.2035\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5106e-04 - val_loss: 0.2018\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2019\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5383e-04 - val_loss: 0.2035\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7250e-04 - val_loss: 0.2018\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2019\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9257e-04 - val_loss: 0.2036\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.1609e-04 - val_loss: 0.2019\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2020\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2037\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4732e-04 - val_loss: 0.2036\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7401e-04 - val_loss: 0.2019\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - val_loss: 0.2021\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2038\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.1227e-04 - val_loss: 0.2037\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4102e-04 - val_loss: 0.2020\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0010 - val_loss: 0.2038\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8372e-04 - val_loss: 0.2038\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1388e-04 - val_loss: 0.2021\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2022\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.5280e-04 - val_loss: 0.2039\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.5926e-04 - val_loss: 0.2039\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9030e-04 - val_loss: 0.2022\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.8112e-04 - val_loss: 0.2023\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.7218e-04 - val_loss: 0.2040\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.3721e-04 - val_loss: 0.2039\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6883e-04 - val_loss: 0.2023\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.9905e-04 - val_loss: 0.2024\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.8996e-04 - val_loss: 0.2041\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.1656e-04 - val_loss: 0.2040\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4858e-04 - val_loss: 0.2023\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.1600e-04 - val_loss: 0.2024\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.0691e-04 - val_loss: 0.2042\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.9671e-04 - val_loss: 0.2041\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.2894e-04 - val_loss: 0.2024\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.3251e-04 - val_loss: 0.2025\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.2349e-04 - val_loss: 0.2042\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2042\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2025\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4890e-04 - val_loss: 0.2026\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4006e-04 - val_loss: 0.2043\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2043\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.6539e-04 - val_loss: 0.2027\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5678e-04 - val_loss: 0.2044\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2043\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:16:57,110] Trial 89 finished with value: 0.0004821568727493286 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1460 - val_loss: 0.3385\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1334 - val_loss: 0.3185\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1132 - val_loss: 0.3006\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0950 - val_loss: 0.2817\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0761 - val_loss: 0.2654\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0608 - val_loss: 0.2521\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0479 - val_loss: 0.2391\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0352 - val_loss: 0.2263\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0228 - val_loss: 0.2121\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0082 - val_loss: 0.1962\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0075 - val_loss: 0.1884\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0152 - val_loss: 0.1859\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0176 - val_loss: 0.1872\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0163 - val_loss: 0.1893\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0138 - val_loss: 0.1920\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0111 - val_loss: 0.1960\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - val_loss: 0.2010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2065\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.2098\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069 - val_loss: 0.2114\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0084 - val_loss: 0.2114\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0084 - val_loss: 0.2103\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0073 - val_loss: 0.2080\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2049\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2009\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.1985\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.1975\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0055 - val_loss: 0.1978\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - val_loss: 0.1992\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 0.2015\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2047\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2065\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.2070\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2064\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2048\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2023\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.2443e-04 - val_loss: 0.2012\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2012\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2022\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.2673e-04 - val_loss: 0.2042\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2050\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1012e-04 - val_loss: 0.2010\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2001\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2002\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2014\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2035\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.9190e-04 - val_loss: 0.2043\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.8132e-04 - val_loss: 0.2028\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5514e-04 - val_loss: 0.2027\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5582e-04 - val_loss: 0.2036\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6456e-04 - val_loss: 0.2035\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.8475e-04 - val_loss: 0.2023\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8522e-04 - val_loss: 0.2023\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2748e-04 - val_loss: 0.2032\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4418e-04 - val_loss: 0.2031\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1712e-05 - val_loss: 0.2020\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2030\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1364e-04 - val_loss: 0.2049\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2056\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2052\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.4159e-04 - val_loss: 0.2017\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2009\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2021\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2041\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2049\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5129e-04 - val_loss: 0.2013\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2004\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2007\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2018\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2039\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.3318e-04 - val_loss: 0.2048\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2046\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0799e-04 - val_loss: 0.2013\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2005\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2007\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2019\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2040\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.2471e-04 - val_loss: 0.2049\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2047\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.5478e-04 - val_loss: 0.2015\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2007\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2021\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.6099e-04 - val_loss: 0.2042\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2051\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.2049\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2038\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8137e-04 - val_loss: 0.2017\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2009\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2012\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.0842e-04 - val_loss: 0.2045\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.2054\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2052\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2040\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.4035e-04 - val_loss: 0.2020\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2012\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2014\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.3564e-04 - val_loss: 0.2047\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2056\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2054\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2043\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2023\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.9578e-04 - val_loss: 0.2015\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2029\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5585e-04 - val_loss: 0.2050\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.2059\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2057\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2046\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.1267e-04 - val_loss: 0.2018\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2020\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2514e-04 - val_loss: 0.2033\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3080e-04 - val_loss: 0.2024\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5421e-04 - val_loss: 0.2026\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6848e-04 - val_loss: 0.2038\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7897e-04 - val_loss: 0.2038\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3370e-04 - val_loss: 0.2029\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9403e-04 - val_loss: 0.2031\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.9815e-05 - val_loss: 0.2042\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2042\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2356e-04 - val_loss: 0.2014\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2007\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2011\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2024\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.8799e-04 - val_loss: 0.2046\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2056\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2044\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0697e-04 - val_loss: 0.2017\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9591e-04 - val_loss: 0.2035\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4626e-04 - val_loss: 0.2026\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9300e-04 - val_loss: 0.2028\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7166e-04 - val_loss: 0.2040\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.0200e-04 - val_loss: 0.2041\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.8605e-04 - val_loss: 0.2032\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.0644e-05 - val_loss: 0.2014\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2012\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2026\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4403e-04 - val_loss: 0.2048\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2058\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2057\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2047\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2028\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2674e-04 - val_loss: 0.2021\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2024\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.3671e-04 - val_loss: 0.2036\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2358e-04 - val_loss: 0.2038\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.8712e-04 - val_loss: 0.2030\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3438e-04 - val_loss: 0.2032\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.6932e-05 - val_loss: 0.2024\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6569e-04 - val_loss: 0.2027\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7937e-04 - val_loss: 0.2040\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.4831e-04 - val_loss: 0.2041\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.8535e-04 - val_loss: 0.2033\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4244e-04 - val_loss: 0.2015\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2014\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.4134e-04 - val_loss: 0.2050\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2060\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2060\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2050\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2031\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5069e-06 - val_loss: 0.2024\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.1803e-04 - val_loss: 0.2027\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.8581e-04 - val_loss: 0.2040\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7973e-04 - val_loss: 0.2042\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4861e-04 - val_loss: 0.2017\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2011\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2016\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2030\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2888e-04 - val_loss: 0.2052\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2062\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0031 - val_loss: 0.2062\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - val_loss: 0.2052\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2034\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8354e-04 - val_loss: 0.2008\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.1994\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.1991\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:17:12,371] Trial 90 finished with value: 0.003289952874183655 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1583 - val_loss: 0.3424\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1344 - val_loss: 0.3191\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1113 - val_loss: 0.2972\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0906 - val_loss: 0.2750\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0698 - val_loss: 0.2517\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0469 - val_loss: 0.2257\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0210 - val_loss: 0.1990\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - val_loss: 0.1883\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0154 - val_loss: 0.1886\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0148 - val_loss: 0.1940\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0090 - val_loss: 0.2027\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1310e-05 - val_loss: 0.2134\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0109 - val_loss: 0.2186\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0160 - val_loss: 0.2198\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0172 - val_loss: 0.2181\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0156 - val_loss: 0.2142\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0116 - val_loss: 0.2083\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - val_loss: 0.2007\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.1965\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.1952\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0073 - val_loss: 0.1964\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.1997\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2045\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2067\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.2068\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2051\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2017\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6048e-04 - val_loss: 0.2005\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2013\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2036\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2027\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3201e-04 - val_loss: 0.1999\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.1991\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - val_loss: 0.2024\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5716e-04 - val_loss: 0.2061\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2079\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - val_loss: 0.2079\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - val_loss: 0.2065\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.2037\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.1996\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.1974\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.1971\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0055 - val_loss: 0.1984\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.2010\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2049\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2068\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2071\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.2060\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2035\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0717e-04 - val_loss: 0.1998\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.1980\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - val_loss: 0.1978\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - val_loss: 0.1991\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2017\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0010 - val_loss: 0.2054\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2073\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.2077\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - val_loss: 0.2067\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - val_loss: 0.2044\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.1992\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.1990\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.2003\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.2028\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.7040e-05 - val_loss: 0.2064\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2082\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - val_loss: 0.2086\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - val_loss: 0.2076\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - val_loss: 0.2053\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2020\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7991e-04 - val_loss: 0.2003\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2002\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.2014\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2038\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.1219e-04 - val_loss: 0.2047\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2041\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - val_loss: 0.2023\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.2700e-04 - val_loss: 0.2020\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.4363e-04 - val_loss: 0.2030\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.3788e-05 - val_loss: 0.2026\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9057e-04 - val_loss: 0.2036\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.7906e-04 - val_loss: 0.2032\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4030e-04 - val_loss: 0.2014\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2012\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.6745e-04 - val_loss: 0.2047\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2055\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.2049\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2432e-05 - val_loss: 0.2000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.1987\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - val_loss: 0.1988\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2002\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2028\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2265e-04 - val_loss: 0.2064\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.2084\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0054 - val_loss: 0.2089\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0059 - val_loss: 0.2080\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.2060\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - val_loss: 0.2029\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2570e-05 - val_loss: 0.2014\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2013\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2026\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.0482e-04 - val_loss: 0.2049\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.2058\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2053\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2036\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.6240e-04 - val_loss: 0.2008\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.1995\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.1997\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 0.2012\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5863e-04 - val_loss: 0.2048\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2044\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2029\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0695e-04 - val_loss: 0.2027\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4684e-04 - val_loss: 0.2039\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.9785e-04 - val_loss: 0.2036\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6125e-04 - val_loss: 0.2022\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.1946e-04 - val_loss: 0.2021\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.8058e-04 - val_loss: 0.2033\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.3540e-04 - val_loss: 0.2031\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6253e-04 - val_loss: 0.2017\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2017\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1211e-06 - val_loss: 0.2054\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2063\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.2058\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2042\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - val_loss: 0.2014\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2002\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.2004\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2018\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2054\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2051\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2036\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.8888e-04 - val_loss: 0.2009\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.1998\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 0.2001\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2016\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2042\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2053\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2051\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2036\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7240e-04 - val_loss: 0.2010\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.1999\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2002\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.2018\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2044\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2055\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.2053\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.2038\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0258e-04 - val_loss: 0.2013\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2002\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2005\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - val_loss: 0.2021\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.4455e-04 - val_loss: 0.2047\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2058\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.2056\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2042\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2016\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2006\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - val_loss: 0.2024\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.7569e-04 - val_loss: 0.2050\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 0.2062\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - val_loss: 0.2059\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - val_loss: 0.2045\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.2020\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.9860e-04 - val_loss: 0.2010\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.2013\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2028\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8397e-04 - val_loss: 0.2054\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.2065\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - val_loss: 0.2063\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - val_loss: 0.2049\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2024\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9789e-04 - val_loss: 0.2014\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.1327e-04 - val_loss: 0.2034\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4986e-04 - val_loss: 0.2023\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.4743e-04 - val_loss: 0.2025\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1169e-04 - val_loss: 0.2040\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.2047e-04 - val_loss: 0.2040\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.9260e-04 - val_loss: 0.2029\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5748e-04 - val_loss: 0.2031\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5600e-05 - val_loss: 0.2020\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2023\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5540e-04 - val_loss: 0.2037\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.0931e-04 - val_loss: 0.2038\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1195e-04 - val_loss: 0.2027\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0948e-04 - val_loss: 0.2029\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0183e-04 - val_loss: 0.2043\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.8442e-04 - val_loss: 0.2009\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:17:27,357] Trial 91 finished with value: 0.002085283398628235 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1465 - val_loss: 0.3330\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1248 - val_loss: 0.2769\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0692 - val_loss: 0.2407\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0328 - val_loss: 0.2025\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.1905\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0131 - val_loss: 0.1932\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0098 - val_loss: 0.2036\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.0423e-04 - val_loss: 0.2053\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2009\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2067\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.2048\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.1972\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.1956\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0075 - val_loss: 0.1991\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.2068\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.2095\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - val_loss: 0.2078\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.2023\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.6254e-04 - val_loss: 0.2009\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2033\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.1321e-04 - val_loss: 0.2021\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.0778e-04 - val_loss: 0.2043\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2032\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7895e-04 - val_loss: 0.1989\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.1980\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.2004\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2056\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2075\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.2064\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2024\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9777e-04 - val_loss: 0.2014\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.5452e-04 - val_loss: 0.2025\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.5363e-04 - val_loss: 0.2044\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.5449e-04 - val_loss: 0.2000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.1993\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2014\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.2060\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - val_loss: 0.2077\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - val_loss: 0.2067\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2031\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4770e-04 - val_loss: 0.1973\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - val_loss: 0.1945\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0085 - val_loss: 0.1944\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0085 - val_loss: 0.1970\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.2018\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.8735e-04 - val_loss: 0.2087\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - val_loss: 0.2126\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0100 - val_loss: 0.2137\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0110 - val_loss: 0.2124\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0096 - val_loss: 0.2089\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - val_loss: 0.2036\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.0900e-04 - val_loss: 0.1965\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0066 - val_loss: 0.1924\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0108 - val_loss: 0.1908\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0123 - val_loss: 0.1916\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0113 - val_loss: 0.1946\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0083 - val_loss: 0.1996\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2060\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2098\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.2112\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0082 - val_loss: 0.2105\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0074 - val_loss: 0.2079\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.2037\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9433e-04 - val_loss: 0.1980\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - val_loss: 0.1947\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0085 - val_loss: 0.1937\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0094 - val_loss: 0.1948\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0084 - val_loss: 0.1977\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0055 - val_loss: 0.2021\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.9157e-04 - val_loss: 0.2079\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 0.2113\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0082 - val_loss: 0.2125\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0094 - val_loss: 0.2118\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0087 - val_loss: 0.2094\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.2055\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2002\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.1972\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0060 - val_loss: 0.1963\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0069 - val_loss: 0.1973\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.2000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - val_loss: 0.2042\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2061\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 0.2062\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.2045\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2012\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2008\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2032\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.5986e-05 - val_loss: 0.2036\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.3856e-04 - val_loss: 0.2022\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.2466e-04 - val_loss: 0.2027\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.2328e-04 - val_loss: 0.2049\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2051\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.2036\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8974e-04 - val_loss: 0.2005\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.1995\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.2003\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2027\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8019e-04 - val_loss: 0.2066\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2084\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.2084\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0053 - val_loss: 0.2066\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2034\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3313e-04 - val_loss: 0.1987\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.1962\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.1957\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0074 - val_loss: 0.1970\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.1999\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2041\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.8865e-04 - val_loss: 0.2062\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2065\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2050\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2021\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2011\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2042\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2047\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2035\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3748e-04 - val_loss: 0.2007\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.1998\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2008\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2033\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4411e-04 - val_loss: 0.2038\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3059e-04 - val_loss: 0.2027\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.9722e-04 - val_loss: 0.2034\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4484e-04 - val_loss: 0.2023\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.3217e-04 - val_loss: 0.2030\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4479e-04 - val_loss: 0.2052\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2056\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2044\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2016\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2007\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2015\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5540e-04 - val_loss: 0.2045\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2034\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4925e-04 - val_loss: 0.2007\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.1999\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - val_loss: 0.2009\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2034\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.8384e-04 - val_loss: 0.2040\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.0484e-04 - val_loss: 0.2029\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7057e-04 - val_loss: 0.2036\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.9740e-04 - val_loss: 0.2026\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.3543e-04 - val_loss: 0.2033\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7086e-04 - val_loss: 0.2023\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.2724e-04 - val_loss: 0.2030\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.9809e-05 - val_loss: 0.2053\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2058\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2045\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2018\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2009\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.2018\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2043\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2048\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2037\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.1861e-04 - val_loss: 0.2010\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2004\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2014\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.3293e-04 - val_loss: 0.2046\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.5536e-04 - val_loss: 0.2010\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.2014\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.2039\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.2456e-04 - val_loss: 0.2046\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.8955e-04 - val_loss: 0.2011\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2004\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2015\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.2040\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.1770e-04 - val_loss: 0.2047\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.0698e-04 - val_loss: 0.2012\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2006\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2016\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2042\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - val_loss: 0.2049\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.6835e-04 - val_loss: 0.2014\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.2018\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 0.2044\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2051\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.5160e-04 - val_loss: 0.2016\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2009\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2020\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2046\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2052\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2012\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2022\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.2728e-04 - val_loss: 0.2047\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2054\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:17:41,822] Trial 92 finished with value: 0.0013414323329925537 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1720 - val_loss: 0.3661\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1666 - val_loss: 0.3422\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1324 - val_loss: 0.3076\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0979 - val_loss: 0.2837\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0787 - val_loss: 0.2657\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0611 - val_loss: 0.2505\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0459 - val_loss: 0.2341\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0293 - val_loss: 0.2160\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0109 - val_loss: 0.1962\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0092 - val_loss: 0.1846\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0204 - val_loss: 0.1799\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0246 - val_loss: 0.1806\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0236 - val_loss: 0.1852\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0188 - val_loss: 0.1922\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0115 - val_loss: 0.2005\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2092\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - val_loss: 0.2140\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0108 - val_loss: 0.2161\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0129 - val_loss: 0.2161\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0129 - val_loss: 0.2143\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0112 - val_loss: 0.2112\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0080 - val_loss: 0.2068\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.2013\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.1981\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.1967\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0065 - val_loss: 0.1971\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - val_loss: 0.1989\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.2019\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2061\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2083\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0051 - val_loss: 0.2089\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - val_loss: 0.2081\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - val_loss: 0.2061\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 0.2029\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.6786e-04 - val_loss: 0.2014\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2014\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2028\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 4.2976e-04 - val_loss: 0.2053\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2062\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - val_loss: 0.2058\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2041\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.8014e-04 - val_loss: 0.2012\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.2000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - val_loss: 0.2002\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2017\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2043\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2050\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5775e-04 - val_loss: 0.2008\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - val_loss: 0.1997\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - val_loss: 0.1999\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.2015\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2041\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.5431e-04 - val_loss: 0.2052\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2034\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.0067e-04 - val_loss: 0.2008\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - val_loss: 0.1997\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.2000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2016\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2042\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.5594e-04 - val_loss: 0.2053\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2050\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2036\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.7067e-04 - val_loss: 0.2010\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2003\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2018\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.2044\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2055\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.2053\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2038\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2919e-04 - val_loss: 0.2013\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2003\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2006\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - val_loss: 0.2021\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2047\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2058\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - val_loss: 0.2041\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.1894e-04 - val_loss: 0.2016\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2006\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2009\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2024\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.8519e-04 - val_loss: 0.2050\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2060\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2058\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - val_loss: 0.2044\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - val_loss: 0.2020\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2010\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2013\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2027\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6955e-04 - val_loss: 0.2052\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.2063\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.2061\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 0.2047\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2023\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.1644e-04 - val_loss: 0.2013\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - val_loss: 0.2016\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.2030\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.5695e-04 - val_loss: 0.2055\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2066\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2064\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.2050\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2026\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.0102e-04 - val_loss: 0.2016\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5183e-04 - val_loss: 0.2035\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.7503e-04 - val_loss: 0.2024\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.9007e-04 - val_loss: 0.2026\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7049e-04 - val_loss: 0.2040\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.0197e-04 - val_loss: 0.2041\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.6467e-04 - val_loss: 0.2029\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4952e-04 - val_loss: 0.2031\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.9438e-05 - val_loss: 0.2044\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2124e-04 - val_loss: 0.2011\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - val_loss: 0.2007\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - val_loss: 0.2023\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.6315e-04 - val_loss: 0.2049\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2061\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2060\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.2047\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2024\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.8243e-04 - val_loss: 0.2015\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2019\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2033\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.6119e-04 - val_loss: 0.2035\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.3669e-04 - val_loss: 0.2025\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.6517e-04 - val_loss: 0.2028\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.0492e-04 - val_loss: 0.2042\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.8802e-04 - val_loss: 0.2043\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2032\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8075e-05 - val_loss: 0.2011\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2008\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2024\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.4929e-04 - val_loss: 0.2050\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2062\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2061\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2049\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.0616e-04 - val_loss: 0.2018\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2022\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9877e-04 - val_loss: 0.2037\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9037e-04 - val_loss: 0.2039\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8101e-04 - val_loss: 0.2029\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9400e-04 - val_loss: 0.2032\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.2784e-05 - val_loss: 0.2045\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2036\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.2942e-04 - val_loss: 0.2015\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.2008\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - val_loss: 0.2013\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2029\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.9705e-04 - val_loss: 0.2055\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - val_loss: 0.2066\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - val_loss: 0.2066\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2054\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.2031\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1456e-05 - val_loss: 0.2023\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8586e-04 - val_loss: 0.2027\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.1135e-04 - val_loss: 0.2041\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.6491e-04 - val_loss: 0.2043\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2034\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.9424e-04 - val_loss: 0.2014\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - val_loss: 0.2012\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.2029\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.9252e-04 - val_loss: 0.2055\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2067\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2067\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 0.2055\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2033\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5783e-04 - val_loss: 0.2002\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.1986\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.1983\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - val_loss: 0.1991\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - val_loss: 0.2010\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - val_loss: 0.2039\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.8216e-04 - val_loss: 0.2053\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.2054\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2045\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.0564e-04 - val_loss: 0.2018\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.2023\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5756e-04 - val_loss: 0.2039\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3572e-04 - val_loss: 0.2042\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.2034\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1110e-04 - val_loss: 0.2015\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2009\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.2016\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.2032\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.4074e-05 - val_loss: 0.2036\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6641e-04 - val_loss: 0.2029\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9762e-04 - val_loss: 0.2033\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:17:57,971] Trial 93 finished with value: 0.00013349950313568115 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1501 - val_loss: 0.3565\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1603 - val_loss: 0.3556\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1549 - val_loss: 0.3552\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1525 - val_loss: 0.3489\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1448 - val_loss: 0.3489\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1476 - val_loss: 0.3487\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1470 - val_loss: 0.3434\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1411 - val_loss: 0.3409\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1377 - val_loss: 0.3407\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1383 - val_loss: 0.3334\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1308 - val_loss: 0.3254\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1224 - val_loss: 0.3168\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1135 - val_loss: 0.3079\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1044 - val_loss: 0.2973\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0917 - val_loss: 0.2799\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0751 - val_loss: 0.2717\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0681 - val_loss: 0.2665\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0617 - val_loss: 0.2558\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0511 - val_loss: 0.2426\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0380 - val_loss: 0.2278\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0235 - val_loss: 0.2122\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0080 - val_loss: 0.1957\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - val_loss: 0.1871\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0169 - val_loss: 0.1838\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0201 - val_loss: 0.1834\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0203 - val_loss: 0.1852\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0184 - val_loss: 0.1882\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0153 - val_loss: 0.1917\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0117 - val_loss: 0.1959\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0074 - val_loss: 0.2008\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2062\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.2098\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.2116\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085 - val_loss: 0.2120\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0089 - val_loss: 0.2112\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0081 - val_loss: 0.2093\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.2064\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - val_loss: 0.2027\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5320e-04 - val_loss: 0.2005\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.1997\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - val_loss: 0.2001\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2016\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2041\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1587e-04 - val_loss: 0.2051\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.2050\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2038\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.6303e-04 - val_loss: 0.2017\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2008\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2011\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2025\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0396e-04 - val_loss: 0.2047\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2057\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.2055\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2043\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.8185e-04 - val_loss: 0.2013\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2016\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2029\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.0062e-04 - val_loss: 0.2050\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2060\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2058\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2046\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2025\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.9037e-04 - val_loss: 0.2016\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.7116e-05 - val_loss: 0.2052\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.2051\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.2645e-04 - val_loss: 0.2003\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.1993\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.2000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2261e-04 - val_loss: 0.2057\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - val_loss: 0.2073\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - val_loss: 0.2072\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - val_loss: 0.2058\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - val_loss: 0.2030\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9510e-05 - val_loss: 0.2020\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 0.2025\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1201e-04 - val_loss: 0.2044\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - val_loss: 0.2046\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.5660e-04 - val_loss: 0.2011\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.2004\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2010\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2030\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8580e-04 - val_loss: 0.2060\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 0.2074\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - val_loss: 0.2074\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - val_loss: 0.2060\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2036\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.9904e-04 - val_loss: 0.2000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 0.1981\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - val_loss: 0.1978\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - val_loss: 0.1987\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - val_loss: 0.2008\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.2040\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.3183e-04 - val_loss: 0.2056\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - val_loss: 0.2057\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - val_loss: 0.2046\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2024\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8885e-04 - val_loss: 0.2016\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.3716e-04 - val_loss: 0.2042\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2033\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1779e-04 - val_loss: 0.2012\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2005\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2012\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - val_loss: 0.2030\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2740e-04 - val_loss: 0.2059\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2072\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.2072\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - val_loss: 0.2060\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.2037\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4760e-04 - val_loss: 0.2004\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.1987\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - val_loss: 0.1983\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - val_loss: 0.1992\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - val_loss: 0.2012\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2043\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2058\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2059\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2049\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.2027\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.0673e-04 - val_loss: 0.2020\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9547e-04 - val_loss: 0.2042\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2045\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2036\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9113e-04 - val_loss: 0.2017\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2010\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2017\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.7990e-04 - val_loss: 0.2038\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.7644e-04 - val_loss: 0.2030\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4196e-04 - val_loss: 0.2034\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.9585e-04 - val_loss: 0.2027\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.8395e-04 - val_loss: 0.2031\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2904e-05 - val_loss: 0.2047\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.2050\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.2041\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.1566e-04 - val_loss: 0.2021\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.2014\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.2020\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7961e-04 - val_loss: 0.2041\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4707e-04 - val_loss: 0.2033\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1565e-04 - val_loss: 0.2014\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2008\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - val_loss: 0.2015\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2032\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0229e-05 - val_loss: 0.2036\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.9163e-04 - val_loss: 0.2029\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8692e-04 - val_loss: 0.2033\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.6968e-04 - val_loss: 0.2026\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.7633e-04 - val_loss: 0.2031\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.1255e-05 - val_loss: 0.2046\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.7492e-04 - val_loss: 0.2021\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 0.2014\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.2021\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2037\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.9208e-04 - val_loss: 0.2041\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.6436e-04 - val_loss: 0.2033\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5140e-04 - val_loss: 0.2014\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2009\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2015\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2033\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3424e-04 - val_loss: 0.2037\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.5616e-04 - val_loss: 0.2029\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.0897e-04 - val_loss: 0.2034\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.4711e-04 - val_loss: 0.2027\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.8676e-04 - val_loss: 0.2031\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0994e-06 - val_loss: 0.2047\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2050\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.2041\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.6224e-04 - val_loss: 0.2022\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.7875e-04 - val_loss: 0.2016\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.8570e-04 - val_loss: 0.2038\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.9250e-04 - val_loss: 0.2042\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5974e-04 - val_loss: 0.2015\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.2010\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.2017\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2034\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.4949e-04 - val_loss: 0.2038\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.6888e-04 - val_loss: 0.2031\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.8125e-05 - val_loss: 0.2035\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.6505e-04 - val_loss: 0.2028\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6123e-04 - val_loss: 0.2033\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1925e-04 - val_loss: 0.2026\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.8204e-04 - val_loss: 0.2031\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.9513e-05 - val_loss: 0.2047\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.2049\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 0.2041\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.3415e-04 - val_loss: 0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:18:14,449] Trial 94 finished with value: 0.0009742081165313721 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1284 - val_loss: 0.2308\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0100 - val_loss: 0.2188\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2664\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0668 - val_loss: 0.2742\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0712 - val_loss: 0.2589\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0580 - val_loss: 0.2333\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0311 - val_loss: 0.2046\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2377e-04 - val_loss: 0.1748\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0313 - val_loss: 0.1602\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0460 - val_loss: 0.1571\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0487 - val_loss: 0.1621\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0432 - val_loss: 0.1721\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0325 - val_loss: 0.1845\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0194 - val_loss: 0.1976\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.2106\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0074 - val_loss: 0.2181\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0151 - val_loss: 0.2216\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0187 - val_loss: 0.2218\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0192 - val_loss: 0.2199\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0172 - val_loss: 0.2161\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0133 - val_loss: 0.2109\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0080 - val_loss: 0.2044\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.1968\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.1922\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0110 - val_loss: 0.1900\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0132 - val_loss: 0.1898\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0134 - val_loss: 0.1912\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0119 - val_loss: 0.1942\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0090 - val_loss: 0.1984\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - val_loss: 0.2037\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8573e-04 - val_loss: 0.2068\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.2081\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - val_loss: 0.2078\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.2060\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2029\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0537e-04 - val_loss: 0.2016\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1686e-04 - val_loss: 0.2038\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3936e-04 - val_loss: 0.2025\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.2502e-04 - val_loss: 0.2027\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7679e-04 - val_loss: 0.2044\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2031\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3755e-04 - val_loss: 0.2033\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5984e-05 - val_loss: 0.2020\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2023\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.2272e-04 - val_loss: 0.2040\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0371e-04 - val_loss: 0.2041\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.0693e-04 - val_loss: 0.2027\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4659e-04 - val_loss: 0.2030\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1617e-04 - val_loss: 0.2046\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.0794e-05 - val_loss: 0.2006\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.1996\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2001\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2021\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2053\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.2067\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.2066\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - val_loss: 0.2050\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2022\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.7878e-04 - val_loss: 0.2011\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2015\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8601e-04 - val_loss: 0.2036\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.0205e-04 - val_loss: 0.2024\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.3527e-04 - val_loss: 0.2027\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1488e-04 - val_loss: 0.2044\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2037e-06 - val_loss: 0.2006\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.1996\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.2003\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - val_loss: 0.2022\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.5338e-04 - val_loss: 0.2054\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2069\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2068\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2053\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.2025\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.8015e-04 - val_loss: 0.2014\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.2019\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2037\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.3753e-04 - val_loss: 0.2040\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6844e-04 - val_loss: 0.2028\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4480e-04 - val_loss: 0.2031\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1349e-04 - val_loss: 0.2048\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2049\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3307e-04 - val_loss: 0.2010\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2001\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2007\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2027\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.8716e-04 - val_loss: 0.2059\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.2074\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.2073\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - val_loss: 0.2058\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2030\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9337e-04 - val_loss: 0.2019\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2024\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.0387e-04 - val_loss: 0.2042\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - val_loss: 0.2045\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2032\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.1960e-05 - val_loss: 0.2008\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - val_loss: 0.1999\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - val_loss: 0.2006\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2026\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7775e-04 - val_loss: 0.2058\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - val_loss: 0.2073\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - val_loss: 0.2073\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - val_loss: 0.2058\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2031\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.7101e-05 - val_loss: 0.2021\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.2026\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.0083e-04 - val_loss: 0.2044\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 0.2047\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2035\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.2042e-04 - val_loss: 0.2011\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2003\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2009\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - val_loss: 0.2030\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.3697e-04 - val_loss: 0.2062\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - val_loss: 0.2077\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - val_loss: 0.2076\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - val_loss: 0.2062\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - val_loss: 0.2035\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.3490e-04 - val_loss: 0.1997\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 0.1977\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0055 - val_loss: 0.1973\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0059 - val_loss: 0.1983\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0049 - val_loss: 0.2007\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - val_loss: 0.2042\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.6071e-04 - val_loss: 0.2059\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.2061\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2049\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.6394e-04 - val_loss: 0.2016\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.2022\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.6025e-04 - val_loss: 0.2042\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.9285e-04 - val_loss: 0.2046\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.2035\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.3961e-04 - val_loss: 0.2012\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.2005\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5470e-04 - val_loss: 0.2038\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.3285e-04 - val_loss: 0.2029\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0962e-04 - val_loss: 0.2034\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1672e-04 - val_loss: 0.2025\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8304e-04 - val_loss: 0.2031\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1763e-04 - val_loss: 0.2050\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.2053\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.2042\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - val_loss: 0.2019\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0013 - val_loss: 0.2011\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.2019\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2039\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7836e-04 - val_loss: 0.2043\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6147e-04 - val_loss: 0.2011\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7294e-04 - val_loss: 0.2039\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.8592e-04 - val_loss: 0.2030\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.1872e-04 - val_loss: 0.2035\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.3520e-04 - val_loss: 0.2027\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3337e-04 - val_loss: 0.2033\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.3704e-05 - val_loss: 0.2024\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.8565e-04 - val_loss: 0.2030\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7168e-04 - val_loss: 0.2049\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2053\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.2043\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2013\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2020\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.6026e-04 - val_loss: 0.2045\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.2036\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.8716e-04 - val_loss: 0.2014\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.2007\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2016\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2037\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.5946e-04 - val_loss: 0.2042\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8182e-04 - val_loss: 0.2033\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.1493e-05 - val_loss: 0.2011\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - val_loss: 0.2014\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.1647e-04 - val_loss: 0.2041\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6761e-04 - val_loss: 0.2032\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.6194e-06 - val_loss: 0.2011\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - val_loss: 0.2014\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.2035\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1032e-04 - val_loss: 0.2041\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.7619e-04 - val_loss: 0.2032\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.8387e-05 - val_loss: 0.2011\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.2005\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:18:31,464] Trial 95 finished with value: 0.0026458799839019775 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1353 - val_loss: 0.3072\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0970 - val_loss: 0.2515\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0435 - val_loss: 0.2024\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.1918\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0105 - val_loss: 0.2111\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0113 - val_loss: 0.2125\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0122 - val_loss: 0.2027\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.1864\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0152 - val_loss: 0.1807\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0209 - val_loss: 0.1827\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0187 - val_loss: 0.1902\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0110 - val_loss: 0.2012\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4785e-04 - val_loss: 0.2039\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.2015\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8101e-04 - val_loss: 0.1951\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - val_loss: 0.1940\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - val_loss: 0.1969\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.2032\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2051\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.2033\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.1984\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.1974\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 0.1997\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.2047\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.2062\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.2045\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.2001\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.1991\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2010\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7661e-04 - val_loss: 0.2055\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.2067\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0055 - val_loss: 0.2051\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2009\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4890e-04 - val_loss: 0.1999\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2016\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1315e-04 - val_loss: 0.2006\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0463e-04 - val_loss: 0.2022\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.4381e-04 - val_loss: 0.2011\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1167e-04 - val_loss: 0.2027\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2015\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6719e-05 - val_loss: 0.2030\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2019\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.9959e-04 - val_loss: 0.1983\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.1976\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 0.1995\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - val_loss: 0.2037\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2049\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2036\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.1999\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - val_loss: 0.1991\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - val_loss: 0.2008\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.3417e-04 - val_loss: 0.2048\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2059\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.2045\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - val_loss: 0.2008\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.1999\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2015\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.1538e-04 - val_loss: 0.2053\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.2064\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - val_loss: 0.2049\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2013\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0861e-04 - val_loss: 0.2003\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.9838e-06 - val_loss: 0.2056\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2066\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.2052\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.2015\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1242e-04 - val_loss: 0.2006\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2021\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4026e-04 - val_loss: 0.2011\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.7300e-04 - val_loss: 0.2026\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8712e-04 - val_loss: 0.2016\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6696e-04 - val_loss: 0.2030\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4837e-04 - val_loss: 0.2019\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3857e-04 - val_loss: 0.2033\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2703e-04 - val_loss: 0.1989\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.1982\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.2000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.2038\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2050\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2038\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2003\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.1996\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2012\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.9207e-04 - val_loss: 0.2049\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - val_loss: 0.2059\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2046\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2012\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - val_loss: 0.2003\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2018\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.6968e-04 - val_loss: 0.2055\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.2065\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - val_loss: 0.2051\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - val_loss: 0.2016\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.1007e-04 - val_loss: 0.2008\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2022\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8999e-05 - val_loss: 0.2058\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.2068\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.2054\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 0.2019\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.5599e-04 - val_loss: 0.2011\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - val_loss: 0.2025\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9570e-04 - val_loss: 0.2016\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.5452e-04 - val_loss: 0.2030\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4351e-04 - val_loss: 0.2020\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4799e-04 - val_loss: 0.2033\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2023\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7658e-05 - val_loss: 0.2036\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2026\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5113e-04 - val_loss: 0.1995\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.1988\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.2005\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2042\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2054\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - val_loss: 0.2042\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2009\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.2002\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2017\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.2290e-04 - val_loss: 0.2053\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2063\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - val_loss: 0.2050\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.2017\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.2287e-04 - val_loss: 0.2009\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.2024\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9471e-05 - val_loss: 0.2059\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2069\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - val_loss: 0.2056\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.4711e-04 - val_loss: 0.2014\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.2028\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.4460e-04 - val_loss: 0.2020\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 5.5349e-04 - val_loss: 0.2033\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.2554e-04 - val_loss: 0.2024\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1736e-04 - val_loss: 0.2037\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 0.2028\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.3767e-04 - val_loss: 0.1997\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 0.1992\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.2008\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.2045\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - val_loss: 0.2056\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 0.2045\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.2013\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.2006\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 0.2021\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.4227e-04 - val_loss: 0.2056\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2067\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0041 - val_loss: 0.2054\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.2022\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7269e-04 - val_loss: 0.2014\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.2029\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0369e-04 - val_loss: 0.2021\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.3868e-04 - val_loss: 0.2034\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5339e-04 - val_loss: 0.2026\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.0695e-05 - val_loss: 0.2039\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.2030\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6472e-04 - val_loss: 0.2000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - val_loss: 0.1995\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.2012\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2048\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.2059\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2048\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2017\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.7591e-04 - val_loss: 0.2011\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.2026\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.7776e-05 - val_loss: 0.2061\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.2071\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.2059\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 0.2027\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1019e-04 - val_loss: 0.1978\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - val_loss: 0.1955\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0072 - val_loss: 0.1955\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0072 - val_loss: 0.1976\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - val_loss: 0.2016\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2072\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.2102\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0076 - val_loss: 0.2109\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - val_loss: 0.2088\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0058 - val_loss: 0.2042\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 0.1977\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0053 - val_loss: 0.1944\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - val_loss: 0.1940\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0090 - val_loss: 0.1961\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069 - val_loss: 0.2003\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.2063\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - val_loss: 0.2094\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0064 - val_loss: 0.2099\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0069 - val_loss: 0.2082\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - val_loss: 0.2044\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.1989\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.1961\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0069 - val_loss: 0.1958\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0072 - val_loss: 0.1977\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - val_loss: 0.2015\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.2070\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - val_loss: 0.2098\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - val_loss: 0.2103\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0073 - val_loss: 0.2087\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - val_loss: 0.2052\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:18:49,455] Trial 96 finished with value: 0.0029349476099014282 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1466 - val_loss: 0.2507\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0107 - val_loss: 0.1318\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0893 - val_loss: 0.1166\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0878 - val_loss: 0.1422\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0591 - val_loss: 0.1776\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0245 - val_loss: 0.2150\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 0.2302\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0251 - val_loss: 0.2310\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0257 - val_loss: 0.2234\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0182 - val_loss: 0.2109\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - val_loss: 0.1955\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0090 - val_loss: 0.1883\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0159 - val_loss: 0.1872\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0169 - val_loss: 0.1907\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0133 - val_loss: 0.1978\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0061 - val_loss: 0.2078\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.2128\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0090 - val_loss: 0.2137\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0099 - val_loss: 0.2111\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0073 - val_loss: 0.2054\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.1972\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0065 - val_loss: 0.1931\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0105 - val_loss: 0.1927\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0108 - val_loss: 0.1956\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0079 - val_loss: 0.2012\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2093\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - val_loss: 0.2134\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0099 - val_loss: 0.2141\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0107 - val_loss: 0.2119\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0085 - val_loss: 0.2071\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.1999\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.1963\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0071 - val_loss: 0.1959\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0075 - val_loss: 0.1984\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 0.2035\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1914e-05 - val_loss: 0.2052\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.2040\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.9710e-04 - val_loss: 0.2002\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.1995\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.2016\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2062\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - val_loss: 0.2076\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2062\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2023\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2015\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2034\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8743e-05 - val_loss: 0.2077\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.2090\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - val_loss: 0.2075\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.2035\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3001e-04 - val_loss: 0.1974\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - val_loss: 0.1944\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0090 - val_loss: 0.1944\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0090 - val_loss: 0.1971\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.2020\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.2091\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.2128\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0094 - val_loss: 0.2136\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0102 - val_loss: 0.2118\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0083 - val_loss: 0.2076\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.2013\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.1982\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - val_loss: 0.1979\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.2003\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2049\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2065\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2055\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2021\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.2015\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2034\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3231e-05 - val_loss: 0.2027\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9517e-04 - val_loss: 0.2046\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2038\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2924e-04 - val_loss: 0.2005\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2001\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.2022\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2066\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.2081\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2069\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.2034\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7895e-05 - val_loss: 0.1978\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - val_loss: 0.1952\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0082 - val_loss: 0.1954\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0080 - val_loss: 0.1981\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0054 - val_loss: 0.2029\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0449e-04 - val_loss: 0.2097\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - val_loss: 0.2134\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0099 - val_loss: 0.2143\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0108 - val_loss: 0.2126\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0091 - val_loss: 0.2087\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.2027\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.7247e-04 - val_loss: 0.1998\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.1996\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - val_loss: 0.2019\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0015 - val_loss: 0.2064\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.2080\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.2070\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.2038\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7232e-04 - val_loss: 0.1984\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.1960\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0074 - val_loss: 0.1963\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0071 - val_loss: 0.1989\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.2037\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.6094e-04 - val_loss: 0.2056\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.2050\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.2020\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.2017\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2038\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.7392e-04 - val_loss: 0.2034\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2883e-06 - val_loss: 0.2006\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2004\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - val_loss: 0.2027\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6948e-04 - val_loss: 0.2071\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.2087\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0053 - val_loss: 0.2077\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2046\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.1994\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - val_loss: 0.1971\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0063 - val_loss: 0.1973\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0060 - val_loss: 0.1999\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 0.2046\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0013 - val_loss: 0.2065\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - val_loss: 0.2059\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - val_loss: 0.2030\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.5389e-04 - val_loss: 0.2027\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2871e-04 - val_loss: 0.2048\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.2043\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - val_loss: 0.2016\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.2015\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2037\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.5678e-04 - val_loss: 0.2034\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.7522e-05 - val_loss: 0.2008\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - val_loss: 0.2007\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - val_loss: 0.2030\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.2350e-04 - val_loss: 0.2074\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 0.2090\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0057 - val_loss: 0.2082\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - val_loss: 0.2051\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2001\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - val_loss: 0.1979\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.1982\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0051 - val_loss: 0.2008\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - val_loss: 0.2054\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.2073\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.2067\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2039\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4701e-04 - val_loss: 0.1991\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.1970\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.1975\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.2002\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.2049\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.2068\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2063\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - val_loss: 0.2036\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0763e-04 - val_loss: 0.1990\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - val_loss: 0.1970\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0063 - val_loss: 0.1975\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0058 - val_loss: 0.2002\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0031 - val_loss: 0.2049\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.2069\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - val_loss: 0.2064\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - val_loss: 0.2038\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.6898e-04 - val_loss: 0.1992\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - val_loss: 0.1973\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - val_loss: 0.1978\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0055 - val_loss: 0.2005\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.2051\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.2071\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - val_loss: 0.2067\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 0.2041\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.6644e-04 - val_loss: 0.1995\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - val_loss: 0.1977\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - val_loss: 0.1982\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - val_loss: 0.2009\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - val_loss: 0.2054\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.2074\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - val_loss: 0.2069\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - val_loss: 0.2044\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.1999\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - val_loss: 0.1980\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - val_loss: 0.1986\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - val_loss: 0.2012\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.2057\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.2077\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - val_loss: 0.2072\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - val_loss: 0.2047\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.2002\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 0.1984\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - val_loss: 0.1989\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.2015\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - val_loss: 0.2060\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.2079\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - val_loss: 0.2075\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - val_loss: 0.2050\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.2005\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 0.1987\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - val_loss: 0.1992\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - val_loss: 0.2018\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.2063\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - val_loss: 0.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:19:07,508] Trial 97 finished with value: 0.004919826984405518 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.0890 - val_loss: 0.1523\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0909 - val_loss: 0.1517\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0558 - val_loss: 0.2169\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0130 - val_loss: 0.2318\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0227 - val_loss: 0.2161\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.1875\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0232 - val_loss: 0.1781\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0314 - val_loss: 0.1820\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0272 - val_loss: 0.1946\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0146 - val_loss: 0.2135\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - val_loss: 0.2214\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0114 - val_loss: 0.2202\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0103 - val_loss: 0.2124\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.1998\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0094 - val_loss: 0.1946\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0142 - val_loss: 0.1952\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0133 - val_loss: 0.2006\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0080 - val_loss: 0.2099\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2135\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.2122\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0035 - val_loss: 0.2067\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.2059\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2093\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.5892e-04 - val_loss: 0.2083\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1769e-04 - val_loss: 0.2037\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - val_loss: 0.2033\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - val_loss: 0.2065\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2130\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 0.2151\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.2135\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.2085\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.2208e-04 - val_loss: 0.2007\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0067 - val_loss: 0.1972\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0101 - val_loss: 0.1971\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0100 - val_loss: 0.2002\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - val_loss: 0.2061\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - val_loss: 0.2145\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0069 - val_loss: 0.2189\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0113 - val_loss: 0.2195\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0120 - val_loss: 0.2170\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0095 - val_loss: 0.2116\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - val_loss: 0.2038\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.1999\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - val_loss: 0.1992\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.2014\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - val_loss: 0.2061\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4815e-04 - val_loss: 0.2131\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - val_loss: 0.2166\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0098 - val_loss: 0.2169\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0101 - val_loss: 0.2144\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0078 - val_loss: 0.2094\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.2024\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.1987\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0073 - val_loss: 0.1980\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0079 - val_loss: 0.1999\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.2040\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2103\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.2134\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0073 - val_loss: 0.2137\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0076 - val_loss: 0.2114\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.2069\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2005\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.1972\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.1965\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0088 - val_loss: 0.1983\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0071 - val_loss: 0.2022\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2080\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - val_loss: 0.2109\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - val_loss: 0.2112\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - val_loss: 0.2092\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.2050\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2489e-04 - val_loss: 0.2036\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2046\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9998e-04 - val_loss: 0.2077\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2083\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - val_loss: 0.2065\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2028\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.2016\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2027\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2059\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.9142e-04 - val_loss: 0.2066\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2051\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.7128e-05 - val_loss: 0.2015\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.2005\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.2017\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.2049\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1176e-06 - val_loss: 0.2100\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - val_loss: 0.2124\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.2124\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0074 - val_loss: 0.2103\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - val_loss: 0.2062\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2004\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - val_loss: 0.1973\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0074 - val_loss: 0.1967\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0080 - val_loss: 0.1982\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0065 - val_loss: 0.2016\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.2068\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2094\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.2096\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - val_loss: 0.2077\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - val_loss: 0.2040\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.8042e-04 - val_loss: 0.2027\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.2035\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2064\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2069\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2053\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.9384e-04 - val_loss: 0.2018\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - val_loss: 0.2007\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.2018\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - val_loss: 0.2048\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2034e-04 - val_loss: 0.2054\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.7288e-04 - val_loss: 0.2040\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4352e-04 - val_loss: 0.2047\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8334e-04 - val_loss: 0.2034\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.7429e-04 - val_loss: 0.2069\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2073\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.2057\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2011\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.2021\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2050\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2144e-04 - val_loss: 0.2056\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2042\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0015e-04 - val_loss: 0.2048\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.8980e-04 - val_loss: 0.2035\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.6509e-04 - val_loss: 0.2042\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1006e-04 - val_loss: 0.2069\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2073\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - val_loss: 0.2057\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.2023\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.2011\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2021\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2050\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.6873e-04 - val_loss: 0.2056\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.2041\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.6380e-04 - val_loss: 0.2048\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.1202e-04 - val_loss: 0.2034\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.3769e-04 - val_loss: 0.2042\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9573e-04 - val_loss: 0.2068\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - val_loss: 0.2072\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - val_loss: 0.2056\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.2011\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - val_loss: 0.2021\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.2049\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4751e-04 - val_loss: 0.2055\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - val_loss: 0.2041\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.8221e-04 - val_loss: 0.2047\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8588e-04 - val_loss: 0.2034\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.5366e-04 - val_loss: 0.2041\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1966e-04 - val_loss: 0.2067\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2071\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - val_loss: 0.2055\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - val_loss: 0.2022\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - val_loss: 0.2011\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2020\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.2048\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1229e-04 - val_loss: 0.2054\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2040\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0997e-04 - val_loss: 0.2047\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5229e-04 - val_loss: 0.2033\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.7525e-04 - val_loss: 0.2040\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4758e-04 - val_loss: 0.2066\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2070\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - val_loss: 0.2055\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2021\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.2010\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.2020\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2048\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8192e-04 - val_loss: 0.2053\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.3092e-04 - val_loss: 0.2046\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2622e-04 - val_loss: 0.2033\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.8833e-04 - val_loss: 0.2040\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6640e-04 - val_loss: 0.2066\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2070\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - val_loss: 0.2054\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2021\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - val_loss: 0.2010\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.2019\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - val_loss: 0.2047\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6527e-04 - val_loss: 0.2053\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3706e-04 - val_loss: 0.2045\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.1556e-04 - val_loss: 0.2032\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.8586e-04 - val_loss: 0.2039\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.6906e-04 - val_loss: 0.2065\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - val_loss: 0.2069\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - val_loss: 0.2053\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0011 - val_loss: 0.2020\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.2010\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 0.2019\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.2047\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6769e-04 - val_loss: 0.2052\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0010 - val_loss: 0.2039\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.2395e-04 - val_loss: 0.2045\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.2468e-04 - val_loss: 0.2032\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.6391e-04 - val_loss: 0.2039\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.5173e-04 - val_loss: 0.2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:19:25,948] Trial 98 finished with value: 0.0022584348917007446 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2172)\n",
      "(1, 2172)\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     temperatures      slp  wet_bulb_temperature  specific_humidity  water  \\\n",
      "0           12.21  1018.53                  7.76               5.39    1.0   \n",
      "1            8.17  1021.23                  4.33               4.30    1.0   \n",
      "2           15.68  1018.97                 10.49               6.51    1.0   \n",
      "3           22.46  1014.69                 16.98              10.21    1.0   \n",
      "4           23.66  1014.24                 18.68              11.74    1.0   \n",
      "..            ...      ...                   ...                ...    ...   \n",
      "222         27.66  1016.01                 23.90              17.03    1.0   \n",
      "223         28.00  1016.53                 22.80              15.20    1.0   \n",
      "224         23.86  1013.56                 20.33              13.73    1.0   \n",
      "225         20.59  1020.43                 14.60               8.35    1.0   \n",
      "226         15.82  1017.05                 13.00               9.05    1.0   \n",
      "\n",
      "        GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0    108.34  6.348387  0.23   0.0     4.0           20.90 -0.91  \n",
      "1    126.00  4.871429  0.17   0.0     4.0            5.71 -0.67  \n",
      "2    180.94  6.396774  0.17   0.0     4.0           17.29 -0.71  \n",
      "3    241.31  5.590000  0.11   0.0     4.0           50.27 -0.32  \n",
      "4    260.04  4.967742  0.11   0.0     4.0           37.23 -0.09  \n",
      "..      ...       ...   ...   ...     ...             ...   ...  \n",
      "222     NaN  3.596774  0.13   0.0     4.0          196.55  0.05  \n",
      "223     NaN  3.306452  0.03   0.0     4.0          215.52 -0.11  \n",
      "224     NaN  3.570000  0.15   0.0     4.0          141.37 -0.25  \n",
      "225     NaN  3.474194  0.00   0.0     4.0          166.39 -0.26  \n",
      "226     NaN  4.653333  0.17   0.0     4.0          152.47 -0.19  \n",
      "\n",
      "[227 rows x 12 columns]\n",
      "[[ 1.22100e+01  1.01853e+03  7.76000e+00 ...  4.00000e+00  2.09000e+01\n",
      "  -9.10000e-01]\n",
      " [ 8.17000e+00  1.02123e+03  4.33000e+00 ...  4.00000e+00  5.71000e+00\n",
      "  -6.70000e-01]\n",
      " [ 1.56800e+01  1.01897e+03  1.04900e+01 ...  4.00000e+00  1.72900e+01\n",
      "  -7.10000e-01]\n",
      " ...\n",
      " [ 2.38600e+01  1.01356e+03  2.03300e+01 ...  4.00000e+00  1.41370e+02\n",
      "  -2.50000e-01]\n",
      " [ 2.05900e+01  1.02043e+03  1.46000e+01 ...  4.00000e+00  1.66390e+02\n",
      "  -2.60000e-01]\n",
      " [ 1.58200e+01  1.01705e+03  1.30000e+01 ...  4.00000e+00  1.52470e+02\n",
      "  -1.90000e-01]]\n",
      "0      12.21\n",
      "1       8.17\n",
      "2      15.68\n",
      "3      22.46\n",
      "4      23.66\n",
      "       ...  \n",
      "222    27.66\n",
      "223    28.00\n",
      "224    23.86\n",
      "225    20.59\n",
      "226    15.82\n",
      "Length: 227, dtype: float64\n",
      "Agg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Test columns:\n",
      "     var1(t-33)  var2(t-33)  var3(t-33)  var4(t-33)  var5(t-33)  var6(t-33)  \\\n",
      "178    0.649022    0.171565    0.579188    0.436955         0.0    1.000000   \n",
      "179    0.498331    0.433356    0.517766    0.468676         0.0    0.630694   \n",
      "\n",
      "     var7(t-33)  var8(t-33)  var9(t-33)  var10(t-33)  ...  var1(t+26)  \\\n",
      "178    0.479920    0.192308         0.0          0.0  ...    0.545064   \n",
      "179    0.381215    0.471154         0.0          0.0  ...    0.585122   \n",
      "\n",
      "     var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  var1(t+32)  \\\n",
      "178    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "179    0.597043    0.732952    0.652361    0.545541    0.506438    0.270386   \n",
      "\n",
      "     var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.270386    0.230806    0.144969  \n",
      "179    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 432 columns]\n",
      "     var1(t-178)  var2(t-178)  var3(t-178)  var4(t-178)  var5(t-178)  \\\n",
      "178     0.279447     0.657553     0.313706     0.360825          0.0   \n",
      "179     0.830234     0.318524     0.800508     0.622522          0.0   \n",
      "\n",
      "     var6(t-178)  var7(t-178)  var8(t-178)  var9(t-178)  var10(t-178)  ...  \\\n",
      "178     0.551782     0.118135     0.461538          0.0           0.0  ...   \n",
      "179     0.740484     0.803567     0.519231          0.0           0.0  ...   \n",
      "\n",
      "     var1(t+26)  var1(t+27)  var1(t+28)  var1(t+29)  var1(t+30)  var1(t+31)  \\\n",
      "178    0.545064    0.585122    0.597043    0.732952    0.652361    0.545541   \n",
      "179    0.585122    0.597043    0.732952    0.652361    0.545541    0.506438   \n",
      "\n",
      "     var1(t+32)  var1(t+33)  var1(t+34)  var1(t+35)  \n",
      "178    0.506438    0.270386    0.230806    0.144969  \n",
      "179    0.270386    0.230806    0.144969    0.348116  \n",
      "\n",
      "[2 rows x 2172 columns]\n",
      "Supervised going into train/test:\n",
      "2\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Train:\n",
      "(1, 2172)\n",
      "[[0.27944683 0.65755297 0.31370558 ... 0.27038627 0.23080591 0.144969  ]]\n",
      "Test:\n",
      "(1, 2172)\n",
      "[[0.83023367 0.31852358 0.80050761 ... 0.23080591 0.144969   0.34811636]]\n",
      "Fitting model:\n",
      "1\n",
      "1\n",
      "1\n",
      "2171\n",
      "(1, 1, 2171)\n",
      "(1, 1)\n",
      "[[0.144969]]\n",
      "(1, 2172)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1417 - val_loss: 0.3659\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1726 - val_loss: 0.3257\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1154 - val_loss: 0.2744\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0705 - val_loss: 0.2288\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0217 - val_loss: 0.1948\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - val_loss: 0.1930\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - val_loss: 0.1991\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7533e-05 - val_loss: 0.1976\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - val_loss: 0.2020\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - val_loss: 0.1983\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - val_loss: 0.1977\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - val_loss: 0.1997\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - val_loss: 0.2039\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - val_loss: 0.2052\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.2041\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.2010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.3364e-05 - val_loss: 0.1961\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - val_loss: 0.1939\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0072 - val_loss: 0.1939\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0072 - val_loss: 0.1958\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - val_loss: 0.1994\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2045\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.2072\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - val_loss: 0.2077\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0067 - val_loss: 0.2064\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0053 - val_loss: 0.2034\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.1991\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.1970\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - val_loss: 0.1968\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - val_loss: 0.1983\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - val_loss: 0.2012\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2019e-04 - val_loss: 0.2054\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.2076\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0064 - val_loss: 0.2079\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0067 - val_loss: 0.2067\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.2039\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - val_loss: 0.2000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.1980\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - val_loss: 0.1978\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - val_loss: 0.1990\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.2016\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9813e-05 - val_loss: 0.2025\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.1417e-04 - val_loss: 0.2018\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8476e-04 - val_loss: 0.1997\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.1993\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2004\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - val_loss: 0.2028\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - val_loss: 0.2035\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0018 - val_loss: 0.2027\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2006\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.2002\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2011\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.9015e-04 - val_loss: 0.2034\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2040\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.2032\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - val_loss: 0.2011\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.6509e-04 - val_loss: 0.2006\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - val_loss: 0.2015\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.9184e-04 - val_loss: 0.2037\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2043\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2035\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2014\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8411e-04 - val_loss: 0.2009\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2017\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5688e-04 - val_loss: 0.2039\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2044\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2036\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2015\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.0427e-04 - val_loss: 0.2010\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2018\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0036e-04 - val_loss: 0.2039\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.2045\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2037\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2016\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7022e-04 - val_loss: 0.2011\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.2019\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7749e-04 - val_loss: 0.2040\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2045\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - val_loss: 0.2037\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2017\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5288e-04 - val_loss: 0.2012\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9313e-04 - val_loss: 0.2020\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6490e-04 - val_loss: 0.2040\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3719e-04 - val_loss: 0.2013\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7056e-04 - val_loss: 0.2021\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5065e-04 - val_loss: 0.2041\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.2046\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - val_loss: 0.2038\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.2018\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1591e-04 - val_loss: 0.2013\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.4223e-04 - val_loss: 0.2021\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2922e-04 - val_loss: 0.2041\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2047\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.2039\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.2019\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.8595e-04 - val_loss: 0.2014\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0547e-04 - val_loss: 0.2022\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.8437e-05 - val_loss: 0.2042\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.2047\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2040\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.2020\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4653e-04 - val_loss: 0.2015\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5966e-04 - val_loss: 0.2023\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.8010e-05 - val_loss: 0.2043\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.2048\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.2040\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2021\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.9790e-04 - val_loss: 0.2016\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0523e-04 - val_loss: 0.2024\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.4490e-06 - val_loss: 0.2043\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.2049\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - val_loss: 0.2041\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.2022\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4095e-04 - val_loss: 0.2017\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.4296e-04 - val_loss: 0.2025\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9278e-05 - val_loss: 0.2020\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7944e-04 - val_loss: 0.2027\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8549e-04 - val_loss: 0.2022\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6488e-04 - val_loss: 0.2029\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7790e-04 - val_loss: 0.2024\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.9958e-05 - val_loss: 0.2031\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3494e-04 - val_loss: 0.2025\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2914e-05 - val_loss: 0.2008\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2004\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.2014\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - val_loss: 0.2034\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.3773e-04 - val_loss: 0.2040\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2034\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.0007e-04 - val_loss: 0.2016\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.2573e-04 - val_loss: 0.2012\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0013 - val_loss: 0.2020\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8073e-04 - val_loss: 0.2040\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.2046\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.2039\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.2020\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7255e-04 - val_loss: 0.2016\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.1985e-04 - val_loss: 0.2024\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.9435e-05 - val_loss: 0.2044\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.2049\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.2042\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.2024\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9255e-04 - val_loss: 0.2019\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5659e-04 - val_loss: 0.2027\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4204e-04 - val_loss: 0.2022\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.5335e-04 - val_loss: 0.2030\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1434e-04 - val_loss: 0.2025\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0648e-04 - val_loss: 0.2032\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.3619e-04 - val_loss: 0.2027\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.4801e-05 - val_loss: 0.2010\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.2007\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.2016\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9008e-04 - val_loss: 0.2036\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2043\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.2036\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2019\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.2421e-04 - val_loss: 0.2015\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.2023\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6178e-04 - val_loss: 0.2043\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.2049\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - val_loss: 0.2042\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.2024\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.1471e-04 - val_loss: 0.2020\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4588e-04 - val_loss: 0.2028\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6686e-04 - val_loss: 0.2023\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0050e-04 - val_loss: 0.2031\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7727e-04 - val_loss: 0.2026\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9416e-05 - val_loss: 0.2034\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3002e-04 - val_loss: 0.2028\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0963e-04 - val_loss: 0.2012\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.2009\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2018\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2664e-04 - val_loss: 0.2038\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2045\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.2039\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - val_loss: 0.2021\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3079e-04 - val_loss: 0.2017\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1155e-04 - val_loss: 0.2026\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1154e-05 - val_loss: 0.2045\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.2051\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2044\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.2027\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8743e-06 - val_loss: 0.1999\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - val_loss: 0.1986\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.1986\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.1998\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - val_loss: 0.2020\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.6906e-04 - val_loss: 0.2052\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - val_loss: 0.2069\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.2073\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.2065\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.2045\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.2017\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - val_loss: 0.2002\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.2001\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.2012\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.2033\n",
      "(1, 2172)\n",
      "(1, 2172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 13:19:44,629] Trial 99 finished with value: 0.0005907714366912842 and parameters: {}. Best is trial 52 with value: 5.8963894844055176e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Activation\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "import keras.backend as K\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def mape (y_true, y_pred):\n",
    "    return 100*K.mean(K.sqrt(K.square(y_true - y_pred))/y_true)\n",
    "\n",
    "def pearson (y_true, y_pred):\n",
    "    return (K.square(K.mean((y_true - K.mean(y_true))*(y_pred - K.mean(y_pred)))))/(K.mean(K.square(y_true - K.mean(y_true)))*K.mean(K.square(y_pred - K.mean(y_pred))))\n",
    " \n",
    "# convert time series into a supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    cols, names = list(), list()\n",
    "    df = DataFrame(data)\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "    \tcols.append(df.shift(i))\n",
    "    \tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df[0].shift(-i)) # df[0] for temperature, df[1] for specific humidity\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (1))] # % (1) for temperature, % (2) for specific humidity\n",
    "        else:            \n",
    "            names += [('var%d(t+%d)' % (1, i))] # % (1) for temperature, % (2) for specific humidity\n",
    "    \n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "\n",
    "    if dropnan:\n",
    "        #Drop rows containing NaN\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    print(\"Agg:\")\n",
    "    agg.columns = names\n",
    "    print(type(agg))\n",
    "    print(agg)\n",
    "\n",
    "    print(\"Test columns:\")\n",
    "    print(agg.iloc[:, -432:]) # Column containing response actual values (temperature) at time t\n",
    "\n",
    "    return agg\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    " \n",
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(data, n_test, n_lag, n_seq):\n",
    "\n",
    "    #Prepare data for time series forecasting.\n",
    "    \n",
    "    #Parameters:\n",
    "    #x (array-like): Input features.\n",
    "    #y (array-like): Target values.\n",
    "    #n_test (int): Number of test samples.\n",
    "    #n_lag (int): Number of lag observations.\n",
    "    #n_seq (int): Number of sequence observations.\n",
    "    \n",
    "    #Returns:\n",
    "    #tuple: Training and test datasets.\n",
    "\n",
    "    #print(\"Prepare data input (difference input)\")\n",
    "    #print(data.shape)\n",
    "    #print(data)\n",
    "\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\n",
    "\t# transform data to be stationary\n",
    "    diff_series = difference(data, 1)\n",
    "    diff_values = []\n",
    "    for i in range(len(diff_series)):\n",
    "        diff_values_row = []\n",
    "        for j in range(len(diff_series[0])):\n",
    "            diff_values_row.append(diff_series[i][j])\n",
    "        diff_values.append(diff_values_row)\n",
    "    #print(\"Diff Series:\")\n",
    "    #print(diff_series.shape)\n",
    "    #print(diff_series)\n",
    "    #print(\"Diff_Values:\")\n",
    "    #print(len(diff_values))\n",
    "    #print(diff_values)\n",
    "    \n",
    "    # split into train and test sets\n",
    "    train_values, test_values = diff_values[0:-n_test], diff_values[-n_test:]\n",
    "    \n",
    "    #print(train_values)\n",
    "    \n",
    "    # rescale values to 0, 1\n",
    "    scaler_all_features =  MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler =  MinMaxScaler(feature_range=(0, 1))\n",
    "    train_scaled_values = scaler_all_features.fit_transform(train_values)\n",
    "    response_train_values = []\n",
    "    for i in range(len(train_values)):\n",
    "        response_train_values.append(train_values[i][0]) # Uses first column (temperatures) as response variable\n",
    "    response_train_values = np.array(response_train_values)\n",
    "    response_train_values = response_train_values.reshape(len(response_train_values), 1)\n",
    "    #response_train_values = response_train_values.reshape(-1, 1)\n",
    "    #print(\"Response:\")\n",
    "    #print(response_train_values)\n",
    "    # Fit the scaler for just the response variable for use later when forecasting\n",
    "    response_scaled_values = scaler.fit_transform(response_train_values) \n",
    "    #print(\"Scaled values before reshape:\")\n",
    "    #print(train_scaled_values.shape)\n",
    "    #print(train_scaled_values)\n",
    "    test_scaled_values = scaler_all_features.transform(test_values)\n",
    "    \n",
    "    #scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "    scaled_values = pd.concat([pd.DataFrame(train_scaled_values), pd.DataFrame(test_scaled_values)], axis=0)\n",
    "    scaled_values = np.array(scaled_values)\n",
    "    \n",
    "    #print(\"Supervised input:\")\n",
    "    #print(scaled_values.shape)\n",
    "    #print(scaled_values)\n",
    "    \n",
    "    # transform into supervised learning problem X, y\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    print(supervised)\n",
    "    supervised_values = supervised.values\n",
    "\n",
    "    print(\"Supervised going into train/test:\")\n",
    "    print(len(supervised_values))\n",
    "    print(supervised_values[-n_test:])\n",
    "\n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    #train = pd.DataFrame(train)\n",
    "    #train.dropna(inplace=True)\n",
    "    #train = np.array(train)\n",
    "    \n",
    "    return scaler, scaler_all_features, train, test\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "def create_model(X, y, n_lag, n_seq, n_batch, nb_epoch):\n",
    "\n",
    "    \n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, return_sequences=True, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(16, input_dim=y.shape[1], activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=rmse, optimizer='adam')\n",
    "\n",
    "    return model\n",
    " \n",
    "# make one forecast with an LSTM,\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "\t# reshape input pattern to [samples, timesteps, features]\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\t# make forecast\n",
    "\tforecast = model.predict(X, batch_size=n_batch)\n",
    "\t# convert to array\n",
    "\treturn [x for x in forecast[0, :]]\n",
    " \n",
    "# evaluate the persistence model\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "\tforecasts = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\tX, y = test[i, 0:-1], test[i, -1:]\n",
    "\t\t# make forecast\n",
    "\t\tforecast = forecast_lstm(model, X, n_batch)\n",
    "\t\t# store the forecast\n",
    "\t\tforecasts.append(forecast)\n",
    "\treturn forecasts\n",
    " \n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "\t# invert first forecast\n",
    "\tinverted = list()\n",
    "\tinverted.append(forecast[0] + last_ob)\n",
    "\t# propagate difference forecast using inverted first value\n",
    "\tfor i in range(1, len(forecast)):\n",
    "\t\tinverted.append(forecast[i] + inverted[i-1])\n",
    "\treturn inverted\n",
    " \n",
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        # create array from forecast\n",
    "        forecast = array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        # invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        # invert differencing\n",
    "        index = len(series) - n_test + i - 1\n",
    "        last_ob = series.values[index]\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        # store\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    " \n",
    "# evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    print(test)\n",
    "    print(forecasts)\n",
    "    for i in range(n_seq):\n",
    "        actual = [row[i] for row in test]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        print('t+%d RMSE: %f' % ((i+1), rmse))\n",
    " \n",
    "# plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "\t# plot the entire dataset in blue\n",
    "\tpyplot.plot(series.values)\n",
    "\t# plot the forecasts in red\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\toff_s = len(series) - n_test + i - 1\n",
    "\t\toff_e = off_s + len(forecasts[i]) + 1\n",
    "\t\txaxis = [x for x in range(off_s, off_e)]\n",
    "\t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
    "\t\tpyplot.plot(xaxis, yaxis, color='red')\n",
    "\txlim = [0, 40]\n",
    "    # show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    accuracies = []\n",
    "\n",
    "    # Get the current working directory \n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    # Print the current working directory \n",
    "    print(current_directory)\n",
    "\n",
    "    # Define the directory containing the files \n",
    "    path = current_directory+\"\\\\Modeling\\\\\"\n",
    "    print(path)\n",
    "\n",
    "    filename = path + 'Final_Monthly_Dataset.csv'\n",
    "\n",
    "    # load dataset\n",
    "    df = read_csv(filename, header=0, parse_dates=[0], index_col=0, date_format='%Y-%m')\n",
    "\n",
    "    df = df.rename(columns={'Unnamed: 0' : 'indices'})\n",
    "\n",
    "    #Remove unused columns\n",
    "    df = df.drop(['Day', 'vapor_pressure'], axis=1)\n",
    "\n",
    "    # Round numbers in columns to reasonable precision\n",
    "    df['temperatures'] = np.round(df['temperatures'], 2)\n",
    "    df['slp'] = np.round(df['slp'], 2)\n",
    "    df['wet_bulb_temperature'] = np.round(df['wet_bulb_temperature'], 2)\n",
    "    df['specific_humidity'] = np.round(df['specific_humidity'], 2)\n",
    "    df['GHI'] = np.round(df['GHI'], 2)\n",
    "    df['PRCP'] = np.round(df['PRCP'], 2)\n",
    "    df['SNDP'] = np.round(df['SNDP'], 2)\n",
    "    df['solar_activity'] = np.round(df['solar_activity'], 2)\n",
    "    df['ONI'] = np.round(df['ONI'], 2)\n",
    "    df['water'] = np.round(df['water'], 0)\n",
    "    df['region'] = np.round(df['region'], 0)\n",
    "\n",
    "    df_trimmed = df[df['file_id']==6501]\n",
    "    df_trimmed = df_trimmed.drop(['Year', 'Month', 'file_id', 'date', 'latitude', 'longitude', 'elevation'], axis=1)\n",
    "\n",
    "    print(df_trimmed)\n",
    "\n",
    "    dataset = df_trimmed.values\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    series = pd.Series(dataset[:, 0]) # Using first column (temperatures)\n",
    "\n",
    "    print(series)\n",
    "\n",
    "    # configure\n",
    "    n_seq = 36\n",
    "    n_lag = 178\n",
    "    n_test = 1\n",
    "    n_epochs = 100\n",
    "    n_batch = 1\n",
    "\n",
    "    # prepare data\n",
    "    scaler, scaler_all_features, train, test = prepare_data(dataset, n_test, n_lag, n_seq)\n",
    "\n",
    "    print(\"Train:\")\n",
    "    print(np.array(train).shape)\n",
    "    print(train)\n",
    "    print(\"Test:\")\n",
    "    print(np.array(test).shape)\n",
    "    print(test)\n",
    "\n",
    "    print(\"Fitting model:\")\n",
    "\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    X, y = train[:, 0:-1], train[:, -1:]\n",
    "    X_test, y_test = test[:, 0:-1], test[:, -1:]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    print(y.shape[0])\n",
    "    print(X.shape[0])\n",
    "    print(X.shape[1])\n",
    "    print(X.shape[2])\n",
    "\n",
    "    # fit model\n",
    "    model = create_model(X, y, n_lag, n_seq, n_batch, n_epochs)\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(y)\n",
    "    print(train.shape)\n",
    "    \n",
    "    history = model.fit(X, y, validation_data=(X_test, y_test), epochs=200, verbose=1)\n",
    "\n",
    "    accuracy = model.evaluate(X, y, verbose=0)\n",
    "\n",
    "    loss = history.history['val_loss'][-1]\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "\n",
    "    return np.mean(accuracies)\n",
    "\n",
    "# optimize and fit model\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print('Number of finished trials:', len(study.trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20b2586-f712-43e9-9d82-6e2c718ef78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {}\n",
      "Best hyperparameters:  {}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n\u001b[1;32m----> 4\u001b[0m best_model \u001b[38;5;241m=\u001b[39m create_model(optuna\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mFixedTrial(best_params), \u001b[43my\u001b[49m, n_lag, n_seq, n_batch, nb_epoch)\n\u001b[0;32m      5\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mn_batch, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val))\n\u001b[0;32m      7\u001b[0m optuna\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mplot_optimization_history(study)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "print('Best trial:', study.best_trial.params)\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "best_model = create_model(optuna.trial.FixedTrial(best_params), y, n_lag, n_seq, n_batch, nb_epoch)\n",
    "best_model.fit(X, y, epochs=100, batch_size=n_batch, validation_data=(X_val, y_val))\n",
    "    \n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "    \n",
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "    \n",
    "optuna.visualization.plot_slice(study, params=['lr', 'optimizer', 'activation_function', 'lstm_units', 'dropout_rate'])\n",
    "    \n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73eb32-d4e0-4c69-9535-7837168674f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db552cbd-d168-4c6d-bbba-f3fc84733ede",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make forecasts\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m make_forecasts(\u001b[43mmodel\u001b[49m, n_batch, train, test, n_lag, n_seq)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# inverse transform forecasts and test\u001b[39;00m\n\u001b[0;32m      5\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m inverse_transform(series, forecasts, scaler, n_test\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# make forecasts\n",
    "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n",
    "\n",
    "# inverse transform forecasts and test\n",
    "forecasts = inverse_transform(series, forecasts, scaler, n_test+2)\n",
    "\n",
    "# evaluate forecasts\n",
    "evaluate_forecasts(test, forecasts, n_lag, n_seq)\n",
    "\n",
    "# plot forecasts\n",
    "plot_forecasts(series, forecasts, n_test+2)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fad724-0d01-457e-ae2e-2fe5abb5f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09943514-ef81-41c0-81fe-2f23d2c75957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000002A2980DFF40>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea996e00-9f29-483d-92fa-f70c03ffe79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
