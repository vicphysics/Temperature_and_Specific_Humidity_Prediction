{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5baac998-16fc-4132-83cf-437ab3206a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters:\n",
      "n_lag (number of input time steps): 20\n",
      "n_seq (number of output/future prediction time steps): 5\n",
      "C:\\Users\\User\n",
      "C:\\Users\\User\\Modeling\\\n",
      "     file_id  temperatures      slp  wet_bulb_temperature  specific_humidity  \\\n",
      "0       6678         20.84  1016.20                 18.08              12.82   \n",
      "1       6678         20.69  1017.48                 17.71              12.33   \n",
      "2       6678         20.47  1018.26                 17.29              12.14   \n",
      "3       6678         20.30  1018.41                 17.20              11.90   \n",
      "4       6678         20.46  1017.92                 17.75              12.75   \n",
      "..       ...           ...      ...                   ...                ...   \n",
      "643     8000         13.02  1016.94                  7.64               5.15   \n",
      "644     8000         13.47  1016.16                  7.88               5.24   \n",
      "645     8000         11.84  1017.90                  7.13               5.36   \n",
      "646     8000         12.86  1016.17                  7.66               5.43   \n",
      "647     8000         13.58  1015.12                  8.11               5.32   \n",
      "\n",
      "     water     GHI      WDSP  PRCP  SNDP  region  solar_activity   ONI  \n",
      "0      1.0  217.31  6.212756  0.12  0.00     6.0           88.05 -0.05  \n",
      "1      1.0  222.89  5.525413  0.08  0.05     6.0          136.15 -1.22  \n",
      "2      1.0  228.09  5.557681  0.09  0.00     6.0          173.81 -0.85  \n",
      "3      1.0  221.56  6.402008  0.09  0.00     6.0          170.28 -0.31  \n",
      "4      1.0  217.38  6.154090  0.16  0.00     6.0          163.61  0.66  \n",
      "..     ...     ...       ...   ...   ...     ...             ...   ...  \n",
      "643    1.0  184.81  7.025180  0.01  0.00     1.0            8.80 -0.36  \n",
      "644    1.0     NaN  6.802803  0.02  0.00     1.0           29.47 -0.72  \n",
      "645    1.0     NaN  5.979051  0.03  0.00     1.0           83.04 -0.94  \n",
      "646    1.0     NaN  5.971951  0.02  0.00     1.0          125.33  0.82  \n",
      "647    1.0     NaN  6.623975  0.03  0.00     1.0          154.37  0.45  \n",
      "\n",
      "[648 rows x 13 columns]\n",
      "Empty DataFrame\n",
      "Columns: [temperatures, slp, wet_bulb_temperature, specific_humidity, water, GHI, WDSP, PRCP, SNDP, region, solar_activity, ONI]\n",
      "Index: []\n",
      "[]\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 1:\n",
      "12\n",
      "19\n",
      "<class 'list'>\n",
      "12\n",
      "5\n",
      "<class 'list'>\n",
      "(19, 1, 1, 245)\n",
      "(2, 1, 1, 245)\n",
      "(3, 1, 1, 245)\n",
      "(19, 1, 245)\n",
      "(2, 1, 245)\n",
      "(3, 1, 245)\n",
      "(19, 245)\n",
      "(2, 245)\n",
      "(3, 245)\n",
      "[[0.41503268 0.46007605 0.35622318 ... 0.40359477 0.60947712 0.69117647]\n",
      " [0.48529412 0.46007605 0.38769671 ... 0.59313725 0.54901961 0.62581699]\n",
      " [0.19771242 0.5095057  0.17310443 ... 0.48529412 0.63562092 0.70588235]\n",
      " ...\n",
      " [0.35947712 0.40969582 0.32474964 ... 0.66503268 0.26633987 0.88235294]\n",
      " [0.13071895 0.81939163 0.16452074 ... 0.64052288 0.24346405 0.75653595]\n",
      " [0.39215686 1.         0.25751073 ... 0.62745098 0.2875817  0.72058824]]\n",
      "Fold 2:\n",
      "12\n",
      "19\n",
      "<class 'list'>\n",
      "12\n",
      "5\n",
      "<class 'list'>\n",
      "(19, 1, 1, 245)\n",
      "(2, 1, 1, 245)\n",
      "(3, 1, 1, 245)\n",
      "(19, 1, 245)\n",
      "(2, 1, 245)\n",
      "(3, 1, 245)\n",
      "(19, 245)\n",
      "(2, 245)\n",
      "(3, 245)\n",
      "[[0.59090909 0.44771863 0.50704225 ... 0.58806818 0.64630682 0.671875  ]\n",
      " [0.55255682 0.46007605 0.45198464 ... 0.64630682 0.60795455 0.67471591]\n",
      " [0.52982955 0.45057034 0.41997439 ... 0.53977273 0.65198864 0.58806818]\n",
      " ...\n",
      " [0.24431818 0.81939163 0.25224072 ... 0.6875     0.34232955 0.78835227]\n",
      " [0.53551136 0.57889734 0.45326504 ... 0.68181818 0.46448864 0.68181818]\n",
      " [0.47159091 1.         0.33546735 ... 0.67613636 0.38068182 0.75710227]]\n",
      "Fold 3:\n",
      "12\n",
      "19\n",
      "<class 'list'>\n",
      "12\n",
      "5\n",
      "<class 'list'>\n",
      "(19, 1, 1, 245)\n",
      "(2, 1, 1, 245)\n",
      "(3, 1, 1, 245)\n",
      "(19, 1, 245)\n",
      "(2, 1, 245)\n",
      "(3, 1, 245)\n",
      "(19, 245)\n",
      "(2, 245)\n",
      "(3, 245)\n",
      "[[0.59090909 0.40895219 0.50704225 ... 0.58806818 0.64630682 0.671875  ]\n",
      " [0.49147727 0.42217701 0.42381562 ... 0.48153409 0.66051136 0.73153409]\n",
      " [0.52982955 0.41200407 0.41997439 ... 0.53977273 0.65198864 0.58806818]\n",
      " ...\n",
      " [0.24431818 0.80671414 0.25224072 ... 0.6875     0.34232955 0.78835227]\n",
      " [0.53551136 0.54933876 0.45326504 ... 0.68181818 0.46448864 0.68181818]\n",
      " [0.47159091 1.         0.33546735 ... 0.67613636 0.38068182 0.75710227]]\n",
      "Fold 4:\n",
      "12\n",
      "20\n",
      "<class 'list'>\n",
      "12\n",
      "4\n",
      "<class 'list'>\n",
      "(20, 1, 1, 245)\n",
      "(2, 1, 1, 245)\n",
      "(2, 1, 1, 245)\n",
      "(20, 1, 245)\n",
      "(2, 1, 245)\n",
      "(2, 1, 245)\n",
      "(20, 245)\n",
      "(2, 245)\n",
      "(2, 245)\n",
      "[[0.61176471 0.44771863 0.64285714 ... 0.60882353 0.66911765 0.69558824]\n",
      " [0.50882353 0.46007605 0.53733766 ... 0.49852941 0.68382353 0.75735294]\n",
      " [0.57205882 0.46007605 0.57305195 ... 0.66911765 0.62941176 0.69852941]\n",
      " ...\n",
      " [0.25294118 0.81939163 0.31980519 ... 0.71176471 0.35441176 0.81617647]\n",
      " [0.55441176 0.57889734 0.57467532 ... 0.70588235 0.48088235 0.70588235]\n",
      " [0.48823529 1.         0.42532468 ... 0.7        0.39411765 0.78382353]]\n",
      "Fold 5:\n",
      "12\n",
      "19\n",
      "<class 'list'>\n",
      "12\n",
      "5\n",
      "<class 'list'>\n",
      "(19, 1, 1, 245)\n",
      "(2, 1, 1, 245)\n",
      "(3, 1, 1, 245)\n",
      "(19, 1, 245)\n",
      "(2, 1, 245)\n",
      "(3, 1, 245)\n",
      "(19, 245)\n",
      "(2, 245)\n",
      "(3, 245)\n",
      "[[0.59090909 0.7536     0.50704225 ... 0.58806818 0.64630682 0.671875  ]\n",
      " [0.49147727 0.7744     0.42381562 ... 0.48153409 0.66051136 0.73153409]\n",
      " [0.55255682 0.7744     0.45198464 ... 0.64630682 0.60795455 0.67471591]\n",
      " ...\n",
      " [0.50426136 0.6912     0.42381562 ... 0.67755682 0.42897727 0.78551136]\n",
      " [0.44318182 0.6896     0.39564661 ... 0.70880682 0.36221591 0.89772727]\n",
      " [0.53551136 0.9744     0.45326504 ... 0.68181818 0.46448864 0.68181818]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Activation, Dropout\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from numpy import array\n",
    "import keras.backend as K\n",
    "import itertools\n",
    "#!pip install pydot\n",
    "    \n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime('190'+x, '%Y-%m')\n",
    "    \n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "def mape (y_true, y_pred):\n",
    "    return 100*K.mean(K.sqrt(K.square(y_true - y_pred))/y_true)\n",
    "    \n",
    "def pearson (y_true, y_pred):\n",
    "    return (K.square(K.mean((y_true - K.mean(y_true))*(y_pred - K.mean(y_pred)))))/(K.mean(K.square(y_true - K.mean(y_true)))*K.mean(K.square(y_pred - K.mean(y_pred))))\n",
    "    \n",
    "# convert time series into a supervised learning problem\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "# Convert time series into a supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    cols, names = list(), list()\n",
    "    df = DataFrame(data)\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "    \tcols.append(df.shift(i))\n",
    "    \tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df[0].shift(-i)) # df[0] for temperature\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (1))] # % (1) for temperature\n",
    "        else:            \n",
    "            names += [('var%d(t+%d)' % (1, i))] # % (1) for temperature\n",
    "    \n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "\n",
    "    if dropnan:\n",
    "        #Drop rows containing NaN\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    #print(\"Agg:\")\n",
    "    agg.columns = names\n",
    "    #print(type(agg))\n",
    "    #print(agg)\n",
    "\n",
    "    #print(\"Test columns:\")\n",
    "    #print(agg.iloc[:, -36]) # Column containing response actual values (temperature) at time t\n",
    "\n",
    "    return agg\n",
    "     \n",
    "# create a differenced series\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "     \n",
    "# transform series into training sets for supervised learning\n",
    "def prepare_training_data(data, n_lag, n_seq, n_time_steps):\n",
    "    \n",
    "    #Prepare data for time series forecasting.\n",
    "        \n",
    "    #Parameters:\n",
    "    #x (array-like): Input features.\n",
    "    #y (array-like): Target values.\n",
    "    #n_test (int): Number of test samples (rows).\n",
    "    #n_lag (int): Number of lag observations.\n",
    "    #n_seq (int): Number of sequence observations.\n",
    "    #n_train (int): Number of training samples (rows).\n",
    "        \n",
    "    #Returns:\n",
    "    #tuple: Training and test datasets.\n",
    "    \n",
    "    n_vars = len(data[0][0])\n",
    "\n",
    "    print(n_vars)\n",
    "    print(len(data))\n",
    "    print(type(data))\n",
    "\n",
    "    # Each weather station has 27 time steps (the first 23 have no nan values)\n",
    "    # Loop through data, grabbing one weather station (ws) at a time, \n",
    "    # differencing on each ws and separating by training (first 26-n_lag-n_seq-n_test time steps) \n",
    "    # and testing (n_test time steps) to scale data on training only.\n",
    "    # We then recombine the training and testing datasets to change each ws to a supervised learning problem by taking all the first 23 time steps for all 12 predictors\n",
    "    # and changing these to (t-n_lag) to (t-1) since we lose one row through differencing. We then shift forward only one dependent variable (temperature or specific humidity)\n",
    "    # for time steps t to (t+n_seq)\n",
    "\n",
    "\n",
    "    diff_values = []\n",
    "    \n",
    "    for ws in range(len(data)):\n",
    "        \n",
    "        # transform data to be stationary\n",
    "        diff_series = difference(data[ws], 1)\n",
    "        for i in range(len(diff_series)):\n",
    "            diff_values_row = []\n",
    "            for j in range(len(diff_series[0])):\n",
    "                diff_values_row.append(diff_series[i][j])\n",
    "            diff_values.append(diff_values_row)\n",
    "\n",
    "    #print(\"Diff values:\")\n",
    "    #print(len(diff_values))\n",
    "    #print(len(diff_values[0]))\n",
    "    #print(len(diff_values_for_training))\n",
    "    #print(len(diff_values_for_training[0]))\n",
    "    \n",
    "    # rescale values to 0, 1\n",
    "    scaler_all_features =  MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler =  MinMaxScaler(feature_range=(0, 1))\n",
    "    #diff_values_training = np.array(diff_values_for_training)\n",
    "    #diff_values_training = diff_values_training.reshape(1, -1) \n",
    "    train_scaled_values = scaler_all_features.fit_transform(diff_values)\n",
    "    response_train_values = []\n",
    "    for i in range(len(diff_values)):\n",
    "        response_train_values.append(diff_values[i][0]) # Uses first column (temperatures) as response variable\n",
    "    response_train_values = np.array(response_train_values)\n",
    "    response_train_values = response_train_values.reshape(len(response_train_values), 1)\n",
    "\n",
    "    # Fit the scaler for just the response variable for use later when forecasting\n",
    "    response_scaled_values = scaler.fit_transform(response_train_values) \n",
    "    scaled_values = scaler_all_features.transform(diff_values)\n",
    "\n",
    "    #print(\"Scaled values rows:\")\n",
    "    #print(len(scaled_values))\n",
    "\n",
    "    train = []\n",
    "\n",
    "    # Transform each weather station as a separate \"batch\"\n",
    "    for ws in range(len(data)):\n",
    "        # transform into a supervised learning problem X, y\n",
    "        first = (n_time_steps-1)*ws\n",
    "        last = (n_time_steps-1)*ws+(n_time_steps-2)\n",
    "        #print(\"Batch \"+str(ws+1)+\":\")\n",
    "        #print(\"Range: \"+str(first)+\"-\"+str(last))\n",
    "        scaled_values_batch = scaled_values[first:last]\n",
    "        supervised = series_to_supervised(scaled_values_batch, n_lag, n_seq)\n",
    "        supervised_values = supervised.values\n",
    "        train.append([supervised_values])\n",
    "        #print(\"Supervised count:\")\n",
    "        #print(len(supervised_values))\n",
    "        #print(len(supervised_values[0]))\n",
    "    \n",
    "    return scaler, scaler_all_features, train\n",
    "\n",
    "# transform series into testing and validation sets for supervised learning\n",
    "def prepare_testing_and_validation_data(data, n_lag, n_seq, n_time_steps, scaler_all_features):\n",
    "    \n",
    "    # Prepare data for time series forecasting.\n",
    "        \n",
    "    #Parameters:\n",
    "    #x (array-like): Input features.\n",
    "    #y (array-like): Target values.\n",
    "    #n_test (int): Number of test samples (rows).\n",
    "    #n_lag (int): Number of lag observations.\n",
    "    #n_seq (int): Number of sequence observations.\n",
    "    #n_train (int): Number of training samples (rows).\n",
    "        \n",
    "    #Returns:\n",
    "    #tuple: Training and test datasets.\n",
    "    \n",
    "    n_vars = len(data[0][0])\n",
    "\n",
    "    print(n_vars)\n",
    "    print(len(data))\n",
    "    print(type(data))\n",
    "\n",
    "    # Each weather station has 227 time steps (the first 180 have no nan values)\n",
    "    # Loop through data, grabbing one weather station (ws) at a time, \n",
    "    # differencing on each ws and separating by training (first 226-n_lag-n_seq-n_test time steps) \n",
    "    # and testing (n_test time steps) to scale data on training only.\n",
    "    # We then recombine the training and testing datasets to change each ws to a supervised learning problem by taking all the first 180 time steps for all 12 predictors\n",
    "    # and changing these to (t-n_lag) to (t-1) since we lose one row through differencing. We then shift forward only one dependent variable (temperature or specific humidity)\n",
    "    # for time steps t to (t+n_seq)\n",
    "\n",
    "\n",
    "    diff_values = []\n",
    "    \n",
    "    for ws in range(len(data)):\n",
    "        \n",
    "        # transform data to be stationary\n",
    "        diff_series = difference(data[ws], 1)\n",
    "        for i in range(len(diff_series)):\n",
    "            diff_values_row = []\n",
    "            for j in range(len(diff_series[0])):\n",
    "                diff_values_row.append(diff_series[i][j])\n",
    "            diff_values.append(diff_values_row)\n",
    "\n",
    "    #print(\"Diff values:\")\n",
    "    #print(len(diff_values))\n",
    "    #print(len(diff_values[0]))\n",
    "    #print(len(diff_values_for_training))\n",
    "    #print(len(diff_values_for_training[0]))\n",
    "    \n",
    "    # rescale values to 0, 1\n",
    "    scaled_values = scaler_all_features.transform(diff_values)\n",
    "\n",
    "    validation = []\n",
    "    test = []\n",
    "\n",
    "    \n",
    "    \n",
    "    # Transform each weather station as a separate \"batch\"\n",
    "    for ws in range(len(data)):\n",
    "        # transform into a supervised learning problem X, y\n",
    "        first = (n_time_steps-1)*ws\n",
    "        last = (n_time_steps-1)*ws+(n_time_steps-2)\n",
    "        #print(\"Batch \"+str(ws+1)+\":\")\n",
    "        #print(\"Range: \"+str(first)+\"-\"+str(last))\n",
    "        scaled_values_batch = scaled_values[first:last]\n",
    "        supervised = series_to_supervised(scaled_values_batch, n_lag, n_seq)\n",
    "        supervised_values = supervised.values\n",
    "        # training/test/validation split is 80%/10%/10%\n",
    "        if ws < 2:\n",
    "            test.append([supervised_values])\n",
    "        else:\n",
    "            validation.append([supervised_values])\n",
    "        #print(\"Supervised count:\")\n",
    "        #print(len(supervised_values))\n",
    "        #print(len(supervised_values[0]))\n",
    "    \n",
    "    return validation, test\n",
    "    \n",
    "def plot_kfold(cv, X, y, ax, n_splits, xlim_max=105):\n",
    "    \n",
    "    #Plots the indices for a cross-validation object.\n",
    "    #Taken from https://www.geeksforgeeks.org/cross-validation-using-k-fold-with-scikit-learn/\n",
    "    \n",
    "    #Parameters:\n",
    "    #cv: Cross-validation object\n",
    "    #X: Feature set\n",
    "    #y: Target variable\n",
    "    #ax: Matplotlib axis object\n",
    "    #n_splits: Number of folds in the cross-validation\n",
    "    #xlim_max: Maximum limit for the x-axis\n",
    "        \n",
    "    # Set color map for the plot\n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "    cv_split = cv.split(X=X, y=y)\n",
    "        \n",
    "    for i_split, (train_idx, test_idx) in enumerate(cv_split):\n",
    "        # Create an array of NaNs and fill in training/testing indices\n",
    "        indices = np.full(len(X), np.nan)\n",
    "        indices[test_idx], indices[train_idx] = 1, 0\n",
    "            \n",
    "        # Plot the training and testing indices\n",
    "        ax_x = range(len(indices))\n",
    "        ax_y = [i_split + 0.5] * len(indices)\n",
    "        ax.scatter(ax_x, ax_y, c=indices, marker=\"_\", \n",
    "                   lw=10, cmap=cmap_cv, vmin=-0.2, vmax=1.2)\n",
    "    \n",
    "        # Set y-ticks and labels\n",
    "        y_ticks = np.arange(n_splits) + 0.5\n",
    "        ax.set(yticks=y_ticks, yticklabels=range(n_splits),\n",
    "               xlabel=\"Weather Station index (file_id)\", ylabel=\"Fold\",\n",
    "               ylim=[n_splits, -0.2], xlim=[0, xlim_max])\n",
    "    \n",
    "        # Set plot title and create legend\n",
    "        ax.set_title(\"KFold\", fontsize=14)\n",
    "        legend_patches = [Patch(color=cmap_cv(0.8), label=\"Testing set\"), \n",
    "                          Patch(color=cmap_cv(0.02), label=\"Training set\")]\n",
    "        ax.legend(handles=legend_patches, loc=(1.03, 0.8))\n",
    "    \n",
    "#Main\n",
    "\n",
    "#Configure\n",
    "n_seq = 5\n",
    "if n_seq > 3:\n",
    "    n_lag = 25 - n_seq\n",
    "else:\n",
    "    n_lag = 22\n",
    "n_time_steps = 27\n",
    "n_test = 1\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "print(\"n_lag (number of input time steps): \"+str(n_lag))\n",
    "print(\"n_seq (number of output/future prediction time steps): \"+str(n_seq))\n",
    "\n",
    "# Create 2D array with file_ids to use for sample creation\n",
    "array = np.array([\n",
    "    6501, 6541, 6640, 6668, 6678, \n",
    "    6687, 6697, 6714, 6744, 6772, \n",
    "    6783, 6840, 6844, 6854, 6870, \n",
    "    6891, 6895, 6899, 6901, 6909, \n",
    "    6929, 6950, 6963, 6969, 6994, \n",
    "    7032, 7057, 7094, 7095, 7100, \n",
    "    7108, 7116, 7119, 7131, 7139, \n",
    "    7152, 7155, 7156, 7182, 7193, \n",
    "    7202, 7239, 7280, 7286, 7287, \n",
    "    7311, 7321, 7329, 7347, 7350, \n",
    "    7354, 7357, 7361, 7414, 7423, \n",
    "    7424, 7432, 7463, 7482, 7489, \n",
    "    7528, 7531, 7534, 7538, 7549, \n",
    "    7553, 7555, 7562, 7571, 7573, \n",
    "    7574, 7575, 7585, 7599, 7603, \n",
    "    7606, 7622, 7652, 7671, 7704, \n",
    "    7786, 7805, 7816, 7838, 7861, \n",
    "    7862, 7863, 7870, 7892, 7907, \n",
    "    7938, 7962, 7979, 7987, 7999, \n",
    "    8000, 8034, 8083, 8120, 8133, \n",
    "    8184, 8186, 8247, 8248, 9858])\n",
    "    \n",
    "#Create arrays holding the 5-fold cross-validation indices gathered for consistency across models\n",
    "train_array = []\n",
    "test_array = []\n",
    "    \n",
    "train_array.append([5, 9, 21, 22, 41, 42, 45, 46, 52, 66, 68, 72, 79, 81, 82, 83, 90, 92, 95])\n",
    "test_array.append([4, 10, 47, 53, 94])\n",
    "    \n",
    "train_array.append([4, 9, 10, 21, 41, 45, 46, 47, 52, 53, 66, 68, 81, 82, 83, 90, 92, 94, 95])\n",
    "test_array.append([5, 22, 42, 72, 79])\n",
    "    \n",
    "train_array.append([4, 5, 10, 21, 22, 41, 42, 46, 47, 52, 53, 72, 79, 82, 83, 90, 92, 94, 95])\n",
    "test_array.append([9, 45, 66, 68, 81])\n",
    "    \n",
    "train_array.append([4, 5, 9, 10, 21, 22, 42, 45, 47, 52, 53, 66, 68, 72, 79, 81, 82, 92, 94, 95])\n",
    "test_array.append([41, 46, 83, 90])\n",
    "    \n",
    "train_array.append([4, 5, 9, 10, 22, 41, 42, 45, 46, 47, 53, 66, 68, 72, 79, 81, 83, 90, 94])\n",
    "test_array.append([21, 52, 82, 92, 95])\n",
    "    \n",
    "# Equations for three Principal Components from PCA using response variables combined with other predictors\n",
    "#PC1=-0.0002714X1+0.02612X2+0.03858X3-0.007658X4+0.001592X5-0.02087X6+0.8564X7-0.1468X8+0.01192X9-0.0001049X10+0.01913X11+0.02076X12\n",
    "#PC2=0.0003944X1+0.002204X2+0.01052X3+0.3248X4-0.0009976X5-0.04421X6+2.3406X7+0.06103X8+0.08841X9+0.00009018X10+0.05678X11-0.002022X12\n",
    "#PC3=-0.00007998X1-0.0006124X2-0.001063X3-0.01855X4+0.00001956X5+0.01170X6+0.6076X7+0.4664X8-0.002995X9+0.008185X10+0.8815X11-0.0004730X12\n",
    "    \n",
    "# Equations for three Principal Components from PCA omitting both response variables,\n",
    "#PC-1=-0.0004514X1+0.03194X2-0.04343X3+0.002243X4-0.02252X5+0.9877X6-0.2265X7+0.006144X8-0.0001488X9+0.02943X10\n",
    "#PC-2=0.0001702X1+0.005484X2+0.2057X3-0.0003188X4-0.02584X5+1.6963X6-0.05890X7+0.05809X8+1.9748X9+0.03686X10\n",
    "#PC-3=-0.00006323X1-0.001180X2-0.02384X3-0.00002833X4+0.01170X5+0.5204X6+0.4791X7-0.004318X8+0.008271X9+0.8765X10\n",
    "    \n",
    "# Get the current working directory \n",
    "current_directory = os.getcwd() \n",
    "    \n",
    "# Print the current working directory \n",
    "print(current_directory)\n",
    "    \n",
    "# Define the directory containing the files \n",
    "path = current_directory+\"\\\\Modeling\\\\\"\n",
    "print(path)\n",
    "    \n",
    "filename = path + 'Final_Yearly_Dataset.csv'\n",
    "    \n",
    "# load dataset\n",
    "df = read_csv(filename, header=0, parse_dates=[0], index_col=0, date_format='%Y-%m')\n",
    "    \n",
    "df = df.rename(columns={'Unnamed: 0' : 'indices'})\n",
    "    \n",
    "#Remove unused columns\n",
    "df = df.drop(['vapor_pressure'], axis=1)\n",
    "    \n",
    "# Round numbers in columns to reasonable precision,\n",
    "df['temperatures'] = np.round(df['temperatures'], 2)\n",
    "df['slp'] = np.round(df['slp'], 2)\n",
    "df['wet_bulb_temperature'] = np.round(df['wet_bulb_temperature'], 2)\n",
    "df['specific_humidity'] = np.round(df['specific_humidity'], 2)\n",
    "df['GHI'] = np.round(df['GHI'], 2)\n",
    "df['PRCP'] = np.round(df['PRCP'], 2)\n",
    "df['SNDP'] = np.round(df['SNDP'], 2)\n",
    "df['solar_activity'] = np.round(df['solar_activity'], 2)\n",
    "df['ONI'] = np.round(df['ONI'], 2)\n",
    "df['water'] = np.round(df['water'], 0)\n",
    "df['region'] = np.round(df['region'], 0)\n",
    "    \n",
    "df_trimmed = df[df['file_id'] != 7533] # Remove file_id 7533 so there are 105 weather stations for 5-fold CV\n",
    "df_trimmed = df_trimmed.drop(['Year', 'date', 'latitude', 'longitude', 'elevation'], axis=1)\n",
    "    \n",
    "X = []\n",
    "y = []\n",
    "    \n",
    "for i in array:\n",
    "    add_to_X = [] # create list to store each column to add to X\n",
    "    new_df = df_trimmed[df_trimmed['file_id'] == i].drop(['file_id'], axis=1)\n",
    "    add_to_y = []\n",
    "    for j in range(new_df.shape[0]):\n",
    "        add_to_y.append(new_df['temperatures'].iloc[j])\n",
    "    y.append(add_to_y)\n",
    "    #new_df = new_df.drop(['temperatures'], axis=1)\n",
    "    columns_list = new_df.columns.tolist()\n",
    "    for j in range(new_df.shape[0]):\n",
    "        l=0\n",
    "        new_row = []\n",
    "        for m in columns_list:\n",
    "            new_row.append(new_df.iloc[j, l])\n",
    "            l += 1\n",
    "        add_to_X.append(new_row)\n",
    "    X.append(add_to_X)\n",
    "\n",
    "print(df_trimmed)\n",
    "print(new_df)\n",
    "print(X[0])\n",
    "\n",
    "#Perform k-fold cross-validation\n",
    "#Taken from: https://www.geeksforgeeks.org/cross-validation-using-k-fold-with-scikit-learn/\n",
    "    \n",
    "#k = 5  # Number of folds\n",
    "#kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "#for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#    print(f\"Fold {i}:\")\n",
    "#    print(f\"  Training dataset index: {train_index}\")\n",
    "#    print(f\"  Test dataset index: {test_index}\")\n",
    "    \n",
    "#for train_indices, test_indices in kf.split(X):\n",
    "#    print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "    \n",
    "# Create figure and axis\n",
    "#fig, ax = plt.subplots(figsize=(6, 3))\n",
    "#plot_kfold(kf, X, y, ax, k)\n",
    "#plt.tight_layout()\n",
    "#fig.subplots_adjust(right=0.6)\n",
    "    \n",
    "#Create train and test sets for each cross-validation split\n",
    "train_X = []\n",
    "train_y = []\n",
    "val_X = []\n",
    "val_y = []\n",
    "for i in range(5):\n",
    "    print(f\"Fold {i+1}\")\n",
    "    #Add each corresponding sample for each entry of train index \n",
    "    train_X_rows = [] # Stores all the samples for one fold of train_X\n",
    "    train_y_rows = [] # Stores all the samples for one fold of train_y\n",
    "    for j in train_array[i]:\n",
    "        train_X_rows.append(X[j])\n",
    "        train_y_rows.append(y[j])\n",
    "    # Stores one fold of the train dataset\n",
    "    train_X.append(train_X_rows)\n",
    "    train_y.append(train_y_rows)\n",
    "    #Add each corresponding sample for each entry of the validation index \n",
    "    val_X_rows = [] # Stores all the samples for one fold of val_X\n",
    "    val_y_rows = [] # Stores all the samples for one fold of val_y\n",
    "    for j in test_array[i]: \n",
    "            val_X_rows.append(X[j])\n",
    "            val_y_rows.append(y[j])\n",
    "    # Stores one fold of the validation dataset\n",
    "    val_X.append(val_X_rows)\n",
    "    val_y.append(val_y_rows) \n",
    "    \n",
    "    #print(\"Train_X Fold \"+str(i)+\":\")\n",
    "    #print(len(train_X[i]))\n",
    "    #print(len(train_X[i][0]))\n",
    "    #print(len(train_X[i][0][0])) \n",
    "    #print(\"Train_y Fold \"+str(i)+\":\")\n",
    "    #print(len(train_y[i]))\n",
    "    #print(len(train_y[i][0]))\n",
    "    #print(train_y[i][0][0])\n",
    "    #print(\"Validation_X Fold \"+str(i)+\":\")\n",
    "    #print(len(val_X[i]))\n",
    "    #print(len(val_X[i][0]))\n",
    "    #print(len(val_X[i][0][0]))\n",
    "    #print(\"Validation_y Fold \"+str(i)+\":\")\n",
    "    #print(len(val_y[i]))\n",
    "    #print(len(val_y[i][0]))\n",
    "    #print(val_y[i][0][0])\n",
    "    \n",
    "#Convert 3D arrays to DataFrames\n",
    "df_X = []\n",
    "df_y = []\n",
    "val_df_X = []\n",
    "val_df_y = []\n",
    "dataset = []\n",
    "dataset_test = []\n",
    "scaler = []\n",
    "scaler_all_features = []\n",
    "train = []\n",
    "test = []\n",
    "validation = []\n",
    "\n",
    "for i in range(5):\n",
    "    dataset_scaling = [] # Holds all 22 weather station rows to train the scaling function\n",
    "    dataset_testing = [] # Holds the remaining five weather station rows for testing and validation\n",
    "    print(\"Fold \"+str(i+1)+\":\")\n",
    "    #Transform train_X to the correct format\n",
    "    df1 = []\n",
    "    dataset_df = [] # captures each weather station's dataset as values for training the scaler mapping\n",
    "    df_X.append(pd.DataFrame(train_X[i]))\n",
    "    X_t = df_X[i].transpose()\n",
    "    if i==3:\n",
    "        train_size = 20\n",
    "        val_size = 4\n",
    "    else:\n",
    "        train_size = 19\n",
    "        val_size = 5\n",
    "        \n",
    "    for k in range(train_size):\n",
    "        X = np.array(X_t.iloc[:, k])\n",
    "        df = pd.DataFrame()\n",
    "        for j in range(n_time_steps):\n",
    "            new_row = pd.DataFrame(X[j]).transpose()\n",
    "            new_row.columns = new_df.columns\n",
    "            # Add the new row\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df.columns = new_df.columns\n",
    "        df1.append(df)\n",
    "        dataset_df.append(df.values)\n",
    "        dataset_scaling.append(df.values)\n",
    "    df_X[i] = df1\n",
    "    dataset.append(dataset_df)\n",
    "     \n",
    "\n",
    "    #print(len(dataset))\n",
    "    #print(len(dataset[0]))\n",
    "    #print(len(dataset_scaling))\n",
    "    #print(len(dataset_scaling[:][0]))\n",
    "    #print(\"Stop\")\n",
    "    \n",
    "    #Transform train_y to the correct format\n",
    "    df2 = []\n",
    "    df_y.append(pd.DataFrame(train_y[i]))\n",
    "    y_t = df_y[i].transpose()\n",
    "    \n",
    "    for j in range(train_size):\n",
    "        y = np.array(y_t.iloc[:, j])\n",
    "        y = pd.DataFrame(y)\n",
    "        y.columns = ['temperatures']\n",
    "        df2.append(y)\n",
    "    df_y[i] = df2\n",
    "\n",
    "    #Transform val_X to the correct format\n",
    "    df3 = []\n",
    "    dataset_vl_df = [] # captures each weather station's dataset as values for training scaler mapping\n",
    "    val_df_X.append(pd.DataFrame(val_X[i]))\n",
    "    val_X_t = val_df_X[i].transpose()\n",
    "    for k in range(val_size):\n",
    "        vl_X = np.array(val_X_t.iloc[:, k])\n",
    "        vl_df = pd.DataFrame()\n",
    "        for j in range(n_time_steps):\n",
    "            new1_row = pd.DataFrame(vl_X[j]).transpose()\n",
    "            new1_row.columns = new_df.columns\n",
    "            # Add the new row\n",
    "            vl_df = pd.concat([vl_df, new1_row], ignore_index=True)\n",
    "        vl_df.columns = new_df.columns\n",
    "        df3.append(vl_df)\n",
    "        dataset_vl_df.append(vl_df.values)\n",
    "        dataset_testing.append(vl_df.values)\n",
    "    val_df_X[i] = df3\n",
    "    dataset_test.append(dataset_vl_df)\n",
    "\n",
    "    #Transform val_y to the correct format\n",
    "    df4 = []\n",
    "    val_df_y.append(pd.DataFrame(train_y[i]))\n",
    "    val_y_t = val_df_y[i].transpose()\n",
    "    \n",
    "    for j in range(val_size):\n",
    "        v_y = np.array(val_y_t.iloc[:, j])\n",
    "        v_y = pd.DataFrame(v_y)\n",
    "        v_y.columns = ['temperatures']\n",
    "        df4.append(v_y)\n",
    "    val_df_y[i] = df4\n",
    "    \n",
    "    scaler.append(MinMaxScaler(feature_range=(0, 1)))\n",
    "    scaler_all_features.append(MinMaxScaler(feature_range=(0, 1)))\n",
    "    train.append([1])\n",
    "    test.append([1])\n",
    "    validation.append([1])\n",
    "    \n",
    "    # prepare data\n",
    "    scaler[i], scaler_all_features[i], train[i] = prepare_training_data(dataset_scaling, n_lag, n_seq, n_time_steps)\n",
    "\n",
    "    validation[i], test[i] = prepare_testing_and_validation_data(dataset_testing, n_lag, n_seq, n_time_steps, scaler_all_features[i])\n",
    "\n",
    "    #Reshape dimensionality\n",
    "    train1 = train[i]\n",
    "    test1 = test[i]\n",
    "    validation1 = validation[i]\n",
    "    print(np.array(train1).shape)\n",
    "    print(np.array(test1).shape)\n",
    "    print(np.array(validation1).shape)\n",
    "    train2 = []\n",
    "    test2 = []\n",
    "    validation2 = []\n",
    "\n",
    "    for k in range(train_size):\n",
    "        train2.append(train1[k][0])\n",
    "        \n",
    "    for k in range(2):\n",
    "        test2.append(test1[k][0])\n",
    "\n",
    "    for k in range(val_size-2):\n",
    "        validation2.append(validation1[k][0])\n",
    "\n",
    "    print(np.array(train2).shape)\n",
    "    print(np.array(test2).shape)\n",
    "    print(np.array(validation2).shape)\n",
    "\n",
    "    train[i] = train2\n",
    "    test[i] = test2\n",
    "    validation[i] = validation2\n",
    "\n",
    "    #Reshape dimensionality (again)\n",
    "    dim_size = n_seq + 12*n_lag\n",
    "    train1 = np.array(train[i]).reshape(train_size, dim_size)\n",
    "    test1 = np.array(test[i]).reshape(2, dim_size)\n",
    "    validation1 = np.array(validation[i]).reshape(val_size-2, dim_size)\n",
    "    train2 = pd.DataFrame(train1).values\n",
    "    test2 = pd.DataFrame(test1).values\n",
    "    validation2 = pd.DataFrame(validation1).values\n",
    "    print(np.array(train2).shape)\n",
    "    print(np.array(test2).shape)\n",
    "    print(np.array(validation2).shape)\n",
    "\n",
    "    print(train2)\n",
    "\n",
    "    train[i] = train2\n",
    "    test[i] = test2\n",
    "    validation[i] = validation2\n",
    "    \n",
    "    #X_train = train1[:][:-n_seq]\n",
    "    #y_train = train1[:][-n_seq:]\n",
    "    #X_test = test1[:][:-n_seq]\n",
    "    #y_test = test1[:][-n_seq:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a031307-8159-4546-9aff-c693ce74f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(train[0]))\n",
    "print(len(test[0]))\n",
    "print(len(validation[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be74bc78-33b4-4695-9874-daa61b380616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "21\n",
      "(19, 0, 257)\n",
      "(2, 0, 257)\n"
     ]
    }
   ],
   "source": [
    "print(n_seq)\n",
    "print(n_lag)\n",
    "print(np.array(train[1]).shape)\n",
    "print(np.array(test[1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ad946-c0cb-407a-8a65-8b9aef8cf7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:17:41,984] A new study created in memory with name: no-name-fb68985f-eb58-43aa-8810-20fb71e22747\n",
      "[I 2025-06-04 20:18:46,347] Trial 0 finished with value: 0.1579679161310196 and parameters: {'lr': 0.2548736820168725, 'optimizer': 'RMSprop', 'activation_function': 'relu', 'lstm_units': 512, 'dropout_rate': 0.24420634952419387}. Best is trial 0 with value: 0.1579679161310196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.17619983851909637, 0.15023905038833618, 0.14322228729724884, 0.16496334969997406, 0.1552150547504425]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.1579679161310196\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.011541977871534322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:20:05,753] Trial 1 finished with value: 0.1022038146853447 and parameters: {'lr': 0.018302165065932137, 'optimizer': 'SGD', 'activation_function': 'relu', 'lstm_units': 1024, 'dropout_rate': 0.22691119870166224}. Best is trial 1 with value: 0.1022038146853447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.15212994813919067, 0.0905105397105217, 0.10135584324598312, 0.0916978195309639, 0.07532492280006409]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.1022038146853447\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02631699564925491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:21:48,037] Trial 2 finished with value: 0.6017195105552673 and parameters: {'lr': 0.16890950891584544, 'optimizer': 'Adam', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.1155006155152333}. Best is trial 1 with value: 0.1022038146853447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[1.1425644159317017, 0.49341902136802673, 0.5402485132217407, 0.4918712079524994, 0.34049439430236816]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.6017195105552673\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.27868480478456953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:22:46,541] Trial 3 finished with value: 0.23609517216682435 and parameters: {'lr': 0.006013517664053734, 'optimizer': 'SGD', 'activation_function': 'relu', 'lstm_units': 512, 'dropout_rate': 0.366067454344992}. Best is trial 1 with value: 0.1022038146853447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.24570831656455994, 0.1512024700641632, 0.25639182329177856, 0.3161810636520386, 0.21099218726158142]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.23609517216682435\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.05432319454620715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:24:03,277] Trial 4 finished with value: 0.10046600699424743 and parameters: {'lr': 0.011426783171391282, 'optimizer': 'SGD', 'activation_function': 'relu', 'lstm_units': 512, 'dropout_rate': 0.27418238311097065}. Best is trial 4 with value: 0.10046600699424743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14673450589179993, 0.08948386460542679, 0.106821708381176, 0.08660919964313507, 0.0726807564496994]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.10046600699424743\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025557025020882623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:25:59,821] Trial 5 finished with value: 6.089163017272949 and parameters: {'lr': 0.7255935746951006, 'optimizer': 'Adam', 'activation_function': 'tanh', 'lstm_units': 1024, 'dropout_rate': 0.48501977833738674}. Best is trial 4 with value: 0.10046600699424743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[8.188937187194824, 5.346156120300293, 4.787191390991211, 5.898252964019775, 6.225277423858643]\n",
      "Mean Cross Validation Accuracy:\n",
      "6.089163017272949\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "1.1585520885463938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:27:00,357] Trial 6 finished with value: 0.09898791462182999 and parameters: {'lr': 0.06277395517454439, 'optimizer': 'SGD', 'activation_function': 'relu', 'lstm_units': 256, 'dropout_rate': 0.1271416630787132}. Best is trial 6 with value: 0.09898791462182999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14271430671215057, 0.08402059227228165, 0.10518936067819595, 0.08970681577920914, 0.07330849766731262]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09898791462182999\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.024166287623845782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:28:10,512] Trial 7 finished with value: 0.09809504896402359 and parameters: {'lr': 0.015646684140218022, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 512, 'dropout_rate': 0.3652784842982497}. Best is trial 7 with value: 0.09809504896402359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1436982899904251, 0.08927282691001892, 0.1047714352607727, 0.08139798045158386, 0.07133471220731735]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09809504896402359\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02528623755447649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:30:26,484] Trial 8 finished with value: 0.3744128465652466 and parameters: {'lr': 0.23431920323154143, 'optimizer': 'RMSprop', 'activation_function': 'relu', 'lstm_units': 1024, 'dropout_rate': 0.26228825572974196}. Best is trial 7 with value: 0.09809504896402359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1878395825624466, 1.2165595293045044, 0.2035723328590393, 0.14012686908245087, 0.12396591901779175]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.3744128465652466\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.4220949376564056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:31:45,719] Trial 9 finished with value: 0.1005217745900154 and parameters: {'lr': 0.45908862466551287, 'optimizer': 'Adam', 'activation_function': 'relu', 'lstm_units': 512, 'dropout_rate': 0.44502386920901194}. Best is trial 7 with value: 0.09809504896402359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.15602236986160278, 0.08628007024526596, 0.10115421563386917, 0.0822749212384224, 0.07687729597091675]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.1005217745900154\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.028898274087638207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:32:54,516] Trial 10 finished with value: 0.09665607959032059 and parameters: {'lr': 0.001698581689068802, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.3727336044437487}. Best is trial 10 with value: 0.09665607959032059.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14419245719909668, 0.08707401901483536, 0.10082338750362396, 0.07993781566619873, 0.0712527185678482]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09665607959032059\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025666011128164662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:34:15,169] Trial 11 finished with value: 0.23537104576826096 and parameters: {'lr': 0.0011211965856422457, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.3713637153579019}. Best is trial 10 with value: 0.09665607959032059.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.36684510111808777, 0.08742593973875046, 0.10068659484386444, 0.14623405039310455, 0.47566354274749756]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.23537104576826096\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.1568432153445253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:35:14,008] Trial 12 finished with value: 0.09666166454553604 and parameters: {'lr': 0.0018224755784567563, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.39451961835057303}. Best is trial 10 with value: 0.09665607959032059.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14471721649169922, 0.08579254150390625, 0.10175053775310516, 0.07982627302408218, 0.07122175395488739]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09666166454553604\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02601534161839136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:36:12,510] Trial 13 finished with value: 0.09632550925016403 and parameters: {'lr': 0.0012958444605621683, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.43333321457983764}. Best is trial 13 with value: 0.09632550925016403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14353854954242706, 0.09120248258113861, 0.10148880630731583, 0.07449265569448471, 0.07090505212545395]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09632550925016403\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.026095399392244423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:37:12,281] Trial 14 finished with value: 0.09748123586177826 and parameters: {'lr': 0.0032696669563716677, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.4423187325739876}. Best is trial 13 with value: 0.09632550925016403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1447407603263855, 0.08750050514936447, 0.10270733386278152, 0.08225337415933609, 0.07020420581102371]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09748123586177826\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025831429998778976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:38:14,372] Trial 15 finished with value: 0.16345761716365814 and parameters: {'lr': 0.0031199730934831026, 'optimizer': 'RMSprop', 'activation_function': 'tanh', 'lstm_units': 256, 'dropout_rate': 0.3080336481933407}. Best is trial 13 with value: 0.09632550925016403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.2689809501171112, 0.1716049611568451, 0.14647865295410156, 0.11867810040712357, 0.11154542118310928]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.16345761716365814\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.05690328540576495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:39:07,866] Trial 16 finished with value: 0.2987643346190453 and parameters: {'lr': 0.0010458163974329192, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.49626590483005717}. Best is trial 13 with value: 0.09632550925016403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.2565900981426239, 0.7613149285316467, 0.21406613290309906, 0.19002002477645874, 0.07183048874139786]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.2987643346190453\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.23926127929656515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:40:01,779] Trial 17 finished with value: 0.17732891887426377 and parameters: {'lr': 0.0530455667949822, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.4261849583553419}. Best is trial 13 with value: 0.09632550925016403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.10922030359506607, 0.2213161140680313, 0.15119968354701996, 0.20237210392951965, 0.20253638923168182]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.17732891887426377\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.04127704309802909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:41:02,104] Trial 18 finished with value: 0.11124455779790879 and parameters: {'lr': 0.00566287164339286, 'optimizer': 'Adam', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.32994745473477466}. Best is trial 13 with value: 0.09632550925016403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.13353712856769562, 0.12329677492380142, 0.10405325889587402, 0.11575790494680405, 0.0795777216553688]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.11124455779790879\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.018531531198683705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:42:08,876] Trial 19 finished with value: 0.1861196905374527 and parameters: {'lr': 0.0027474031487139832, 'optimizer': 'RMSprop', 'activation_function': 'tanh', 'lstm_units': 256, 'dropout_rate': 0.4119122348244036}. Best is trial 13 with value: 0.09632550925016403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.2657582759857178, 0.22236615419387817, 0.1483052372932434, 0.13749070465564728, 0.15667808055877686]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.1861196905374527\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.049633919772641324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:43:13,867] Trial 20 finished with value: 0.09609388262033462 and parameters: {'lr': 0.00690254467501205, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.1819752113031357}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14298656582832336, 0.08653944730758667, 0.10081083327531815, 0.08034215122461319, 0.06979041546583176]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09609388262033462\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02550470553597038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:44:15,546] Trial 21 finished with value: 0.09695971608161927 and parameters: {'lr': 0.0059940114829238975, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.18181889513317806}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14388015866279602, 0.08693771809339523, 0.10144804418087006, 0.08101064711809158, 0.07152201235294342]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09695971608161927\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025391191530163552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:45:15,832] Trial 22 finished with value: 0.09653527438640594 and parameters: {'lr': 0.0019971445798200615, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.19702439627218876}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14362598955631256, 0.08646523207426071, 0.10117638856172562, 0.08038449287414551, 0.07102426886558533]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09653527438640594\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025503491111258218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:46:11,474] Trial 23 finished with value: 0.09658022820949555 and parameters: {'lr': 0.006852814435402105, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.18031073724557728}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14443106949329376, 0.08732135593891144, 0.10006677359342575, 0.08048826456069946, 0.07059367746114731]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09658022820949555\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025775328668612926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:47:06,103] Trial 24 finished with value: 0.09658405184745789 and parameters: {'lr': 0.0019588466012259343, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.19554762583214902}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1426943689584732, 0.08723010867834091, 0.10117171704769135, 0.08049258589744568, 0.07133147865533829]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09658405184745789\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025025315175328584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:48:02,153] Trial 25 finished with value: 0.09635353684425355 and parameters: {'lr': 0.003572714461984668, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.14324497418805976}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14281171560287476, 0.08655858039855957, 0.10121366381645203, 0.07994932681322098, 0.07123439759016037]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09635353684425355\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025211083448101513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:49:01,242] Trial 26 finished with value: 0.1071693703532219 and parameters: {'lr': 0.02627910790663898, 'optimizer': 'SGD', 'activation_function': 'tanh', 'lstm_units': 256, 'dropout_rate': 0.14777755401977796}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1585037261247635, 0.10662350803613663, 0.10630158334970474, 0.08186835795640945, 0.08254967629909515]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.1071693703532219\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.027865884755572907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:50:14,539] Trial 27 finished with value: 0.22880819439888 and parameters: {'lr': 0.009531295273263145, 'optimizer': 'RMSprop', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.14264333726031408}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.15781129896640778, 0.2897554934024811, 0.1943066269159317, 0.2623620927333832, 0.2398054599761963]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.22880819439888\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.047312354664050246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:51:13,796] Trial 28 finished with value: 0.09800784438848495 and parameters: {'lr': 0.004654271386240413, 'optimizer': 'Adam', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.10146911750751378}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1352788507938385, 0.08447650820016861, 0.109346903860569, 0.08604434132575989, 0.07489261776208878]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09800784438848495\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02180934824675919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:52:48,830] Trial 29 finished with value: 0.09641646146774292 and parameters: {'lr': 0.003850336847596983, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.21767121002789985}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1430239975452423, 0.08636816591024399, 0.10129699110984802, 0.08026473969221115, 0.07112841308116913]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09641646146774292\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025287996124365456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:54:06,203] Trial 30 finished with value: 0.10593218505382537 and parameters: {'lr': 0.043501412043309526, 'optimizer': 'SGD', 'activation_function': 'tanh', 'lstm_units': 512, 'dropout_rate': 0.1536723464397123}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.15443795919418335, 0.0948890820145607, 0.10598552227020264, 0.08951940387487411, 0.08482895791530609]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.10593218505382537\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025256637449343734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:55:38,986] Trial 31 finished with value: 0.0965267390012741 and parameters: {'lr': 0.003506621335971516, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.22457582914157065}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14345264434814453, 0.0866718739271164, 0.10112302005290985, 0.08021710067987442, 0.07116905599832535]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.0965267390012741\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025413780306014398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:57:11,870] Trial 32 finished with value: 0.09667515605688096 and parameters: {'lr': 0.010235286111121579, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.22428617659480332}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14367781579494476, 0.08641654253005981, 0.10090742260217667, 0.081650510430336, 0.07072348892688751]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09667515605688096\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025422943405847206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 20:58:36,101] Trial 33 finished with value: 0.22975738644599913 and parameters: {'lr': 0.09139318567989267, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.24706068014043803}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.20230592787265778, 0.27680763602256775, 0.19804425537586212, 0.22323882579803467, 0.2483902871608734]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.22975738644599913\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.029538814692754732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:00:02,347] Trial 34 finished with value: 0.10229501575231552 and parameters: {'lr': 0.020627543665374313, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.16644684272960772}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1422477513551712, 0.10871639102697372, 0.10176172107458115, 0.07393839955329895, 0.08481081575155258]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.10229501575231552\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.023441563419311397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:01:47,816] Trial 35 finished with value: 0.132927605509758 and parameters: {'lr': 0.0014160190176237641, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.28862495393426046}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14036832749843597, 0.08816862106323242, 0.28542429208755493, 0.07939758151769638, 0.07127920538187027]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.132927605509758\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.07997494502220404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:04:02,519] Trial 36 finished with value: 0.15300098955631256 and parameters: {'lr': 0.0024299168257419495, 'optimizer': 'RMSprop', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.2194151163808285}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.20350119471549988, 0.1377403438091278, 0.12907177209854126, 0.16674742102622986, 0.127944216132164]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.15300098955631256\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.028887962027351926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:05:07,935] Trial 37 finished with value: 0.1068483129143715 and parameters: {'lr': 0.004333704829510351, 'optimizer': 'Adam', 'activation_function': 'relu', 'lstm_units': 512, 'dropout_rate': 0.3309463594001648}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.137269988656044, 0.11838633567094803, 0.11872000247240067, 0.08898717164993286, 0.07087806612253189]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.1068483129143715\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.0237167466510862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:06:36,044] Trial 38 finished with value: 0.09655612707138062 and parameters: {'lr': 0.007976841559441561, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 1024, 'dropout_rate': 0.11285814523441426}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14470961689949036, 0.08593285828828812, 0.10066115856170654, 0.0802374854683876, 0.07123951613903046]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09655612707138062\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.0259063411490978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:08:11,469] Trial 39 finished with value: 0.09651770293712617 and parameters: {'lr': 0.012701911901524856, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.12876411364913354}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14327967166900635, 0.08501072227954865, 0.10137367248535156, 0.08068646490573883, 0.07223798334598541]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09651770293712617\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025230163078424062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:09:31,757] Trial 40 finished with value: 0.34370445609092715 and parameters: {'lr': 0.0042085492453016815, 'optimizer': 'SGD', 'activation_function': 'relu', 'lstm_units': 512, 'dropout_rate': 0.25010852905196146}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.3453345000743866, 0.27164193987846375, 0.36188167333602905, 0.31377384066581726, 0.42589032649993896]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.34370445609092715\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.05133504367904619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:10:33,124] Trial 41 finished with value: 0.09675839841365814 and parameters: {'lr': 0.014185851797739015, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.13083764479330404}. Best is trial 20 with value: 0.09609388262033462.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14446744322776794, 0.08628062158823013, 0.1003836989402771, 0.08007486909627914, 0.07258535921573639]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09675839841365814\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025541164980222117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:11:40,400] Trial 42 finished with value: 0.09607883542776108 and parameters: {'lr': 0.017297460108067854, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.12775198153508777}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14504584670066833, 0.08696039766073227, 0.10147526860237122, 0.08006127923727036, 0.06685138493776321]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09607883542776108\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.026910375544689228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:12:33,459] Trial 43 finished with value: 0.11374440342187882 and parameters: {'lr': 0.02661545941806538, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.20119207518608465}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1307268887758255, 0.06684226542711258, 0.1303844451904297, 0.12410583347082138, 0.11666258424520493]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.11374440342187882\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02400408864886557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:13:28,200] Trial 44 finished with value: 0.09772240221500397 and parameters: {'lr': 0.017127305458592004, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.16480991211876428}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14457643032073975, 0.08646538108587265, 0.10131476074457169, 0.08181249350309372, 0.07444294542074203]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09772240221500397\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02501992733041793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:14:29,578] Trial 45 finished with value: 0.2515201404690742 and parameters: {'lr': 0.001433156365355548, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.10227789130725976}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.2743837535381317, 0.08653122186660767, 0.3827105164527893, 0.4211726784706116, 0.09280253201723099]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.2515201404690742\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.14066148420798574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:16:01,223] Trial 46 finished with value: 0.09831615835428238 and parameters: {'lr': 0.002414450098242043, 'optimizer': 'SGD', 'activation_function': 'tanh', 'lstm_units': 1024, 'dropout_rate': 0.16820410535549085}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14248579740524292, 0.08411385864019394, 0.09840288013219833, 0.0851704552769661, 0.08140780031681061]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09831615835428238\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02285332331477415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:17:23,547] Trial 47 finished with value: 0.16179269105195998 and parameters: {'lr': 0.009182623103948045, 'optimizer': 'Adam', 'activation_function': 'relu', 'lstm_units': 256, 'dropout_rate': 0.47334598200962974}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.22019007802009583, 0.2290065884590149, 0.15918564796447754, 0.09352253377437592, 0.10705860704183578]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.16179269105195998\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.0558415504980757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:18:45,170] Trial 48 finished with value: 3.0858033418655397 and parameters: {'lr': 0.1293630207451502, 'optimizer': 'RMSprop', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.2746806522360735}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[5.5046868324279785, 0.6288585662841797, 2.510220766067505, 4.84334659576416, 1.9419039487838745]\n",
      "Mean Cross Validation Accuracy:\n",
      "3.0858033418655397\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "1.822982961168399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:20:02,964] Trial 49 finished with value: 0.1349144384264946 and parameters: {'lr': 0.03708544947972483, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 512, 'dropout_rate': 0.14197124929831612}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.13966181874275208, 0.06432916969060898, 0.19724448025226593, 0.16260895133018494, 0.11072777211666107]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.1349144384264946\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.04525888369931961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:21:17,986] Trial 50 finished with value: 0.13111076056957244 and parameters: {'lr': 0.0013822707864792427, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.11692354959044057}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14323656260967255, 0.08662671595811844, 0.27328014373779297, 0.08008655160665512, 0.07232382893562317]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.13111076056957244\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.07536228770647546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:22:21,072] Trial 51 finished with value: 0.0965968281030655 and parameters: {'lr': 0.012874227402168745, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.12728385706273282}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14563702046871185, 0.08682595193386078, 0.10054872184991837, 0.07930833101272583, 0.07066411525011063]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.0965968281030655\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.026409943885273367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:23:35,480] Trial 52 finished with value: 0.09632810205221176 and parameters: {'lr': 0.006712895843642019, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.20967518895069154}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14303378760814667, 0.08690475672483444, 0.1014048233628273, 0.07987000793218613, 0.07042713463306427]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09632810205221176\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.0254468959796117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:24:56,394] Trial 53 finished with value: 0.09628060311079026 and parameters: {'lr': 0.0052800884349118865, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.20881604863062903}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14403589069843292, 0.0863196849822998, 0.10037153214216232, 0.08012876659631729, 0.07054714113473892]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09628060311079026\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02576670708858162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:26:00,372] Trial 54 finished with value: 0.0966462716460228 and parameters: {'lr': 0.005569231081221397, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.18504084041097613}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14337308704853058, 0.086625836789608, 0.10088033229112625, 0.08079198002815247, 0.07156012207269669]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.0966462716460228\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.025228575564378852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:27:02,909] Trial 55 finished with value: 0.09741108864545822 and parameters: {'lr': 0.006773727151321658, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.20420548821804327}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.14402151107788086, 0.08792807161808014, 0.1017516627907753, 0.08155406266450882, 0.07180013507604599]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.09741108864545822\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.02525337953968347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:28:05,854] Trial 56 finished with value: 0.12446857690811157 and parameters: {'lr': 0.9939437271268591, 'optimizer': 'SGD', 'activation_function': 'sigmoid', 'lstm_units': 256, 'dropout_rate': 0.2409191922686156}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.1371532529592514, 0.12182594835758209, 0.14487335085868835, 0.098636694252491, 0.11985363811254501]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.12446857690811157\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.015955081408586716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 21:29:12,562] Trial 57 finished with value: 0.11220882385969162 and parameters: {'lr': 0.021467130289707217, 'optimizer': 'Adam', 'activation_function': 'relu', 'lstm_units': 256, 'dropout_rate': 0.15730625231464285}. Best is trial 42 with value: 0.09607883542776108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracies:\n",
      "[0.16490031778812408, 0.11477502435445786, 0.09892759472131729, 0.10257495939731598, 0.07986622303724289]\n",
      "Mean Cross Validation Accuracy:\n",
      "0.11220882385969162\n",
      "Standard Deviation of Cross Validation Accuracy:\n",
      "0.028629443366070054\n"
     ]
    }
   ],
   "source": [
    "n_batch = 1\n",
    "nb_epoch = 100\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def mape (y_true, y_pred):\n",
    "    return 100*K.mean(K.sqrt(K.square(y_true - y_pred))/y_true)\n",
    "    \n",
    "def pearson (y_true, y_pred):\n",
    "    return (K.square(K.mean((y_true - K.mean(y_true))*(y_pred - K.mean(y_pred)))))/(K.mean(K.square(y_true - K.mean(y_true)))*K.mean(K.square(y_pred - K.mean(y_pred))))\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "#Adapted from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def create_model(trial, X, y, n_lag, n_seq, n_batch, nb_epoch):\n",
    "\n",
    "    cv_accuracies = []\n",
    "    \n",
    "    #Parameters:\n",
    "    #trial (array-like): Optuna parameters.\n",
    "    #train (array-like): Target values.\n",
    "    #n_lag (int): Number of lag observations.\n",
    "    #n_seq (int): Number of sequence observations\n",
    "    #nb_epoch (int): Maximum number of epochs\n",
    "    \n",
    "    # Hyperparameters to be tuned by Optuna (taken from Javier Leon's dissertation 'Fruit Prices')\n",
    "    lr = trial.suggest_float('lr', 1e-3, 1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "    \n",
    "    #Optuna will try either Rectified Linear Unit (ReLU) = max(0, x), tanh, or sigmoid functions\n",
    "    activation_function = trial.suggest_categorical('activation_function', ['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    lstm_units = trial.suggest_categorical('lstm_units', [256, 512, 1024])\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, return_sequences=True, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, input_dim=y.shape[1], activation=activation_function))\n",
    "    model.add(Dense(128, activation=activation_function))\n",
    "    model.add(Dense(n_seq))\n",
    "    model.compile(loss=rmse, optimizer=optimizer)\n",
    "        \n",
    "    return model\n",
    "    \n",
    "def objective(trial):\n",
    "    \n",
    "    cv_accuracies = []\n",
    "        \n",
    "    for i in range(5):\n",
    "        train1 = train[i]\n",
    "        test1 = test[i]\n",
    "        validation1 = validation[i]\n",
    "\n",
    "        X, y = train1[:, 0:-n_seq], train1[:, -n_seq:]\n",
    "        X_test, y_test = test1[:, 0:-n_seq], test1[:, -n_seq:]\n",
    "        X_val, y_val = validation1[:, 0:-n_seq], validation1[:, -n_seq:]\n",
    "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "        X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "        X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "    \n",
    "        model = create_model(trial, X, y, n_lag, n_seq, n_batch, nb_epoch)\n",
    "\n",
    "        history = model.fit(X, y, validation_data=(X_val, y_val), epochs=nb_epoch, verbose=0)\n",
    "\n",
    "        cv_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "        loss = history.history['val_loss'][-1]\n",
    "    \n",
    "        # Plotting the training and validation loss\n",
    "        #plt.figure(figsize=(10, 4))\n",
    "        #plt.plot(history.history['loss'], label='Training Loss')\n",
    "        #plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        #title1 = \"LSTM Training and Validation Loss for Fold \" + str(i+1)\n",
    "        #plt.title(title1)\n",
    "        #plt.xlabel('Epoch')\n",
    "        #plt.ylabel('Root Mean Squared Error Loss')\n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "            \n",
    "        cv_accuracies.append(cv_accuracy)\n",
    "    \n",
    "    print(\"Cross Validation Accuracies:\")\n",
    "    print(cv_accuracies)\n",
    "    print(\"Mean Cross Validation Accuracy:\")\n",
    "    print(np.mean(cv_accuracies))\n",
    "    print(\"Standard Deviation of Cross Validation Accuracy:\")\n",
    "    print(np.std(cv_accuracies))\n",
    "        \n",
    "    return np.mean(cv_accuracies)\n",
    "\n",
    "n_batch = 1\n",
    "nb_epoch = 100\n",
    "\n",
    "# optimize and fit model\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Fold \"+str(i+1)+\":\")\n",
    "    train1 = train[i]\n",
    "    test1 = test[i]\n",
    "    validation1 = validation[i]\n",
    "\n",
    "    X, y = train1[:, 0:-n_seq], train1[:, -n_seq:]\n",
    "    X_test, y_test = test1[:, 0:-n_seq], test1[:, -n_seq:]\n",
    "    X_val, y_val = validation1[:, 0:-n_seq], validation1[:, -n_seq:]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "    best_model = create_model(optuna.trial.FixedTrial(best_params), X, y, n_lag, n_seq, n_batch, nb_epoch)\n",
    "    history = best_model.fit(X, y, epochs=100, batch_size=n_batch, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Plotting the training and validation loss\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    title1 = \"CNN-LSTM Training and Validation Loss for Best Model\"\n",
    "    plt.title(title1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Root Mean Squared Error Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # make forecasts\n",
    "    forecasts = make_forecasts(best_model, X_test, y_test, n_lag, n_seq, n_test)\n",
    "    \n",
    "    # inverse transform forecasts and test\n",
    "    forecasts = inverse_transform(series, forecasts, scaler[i], n_test+2, n_seq)\n",
    "    actual = [row[-n_seq:] for row in test1]\n",
    "    actual = inverse_transform(series, actual, scaler[i], n_test+2, n_seq)\n",
    "\n",
    "    #print(\"Forecasts:\")\n",
    "    #print(forecasts)\n",
    "    #print(\"Actual:\")\n",
    "    #print(actual)\n",
    "\n",
    "    rmse_list = [] # list stores root mean squared errors for each future time prediction\n",
    "    mae_list = [] # list stores root mean squared errors for each future time prediction\n",
    "    mape_list = [] # list stores root mean squared errors for each future time prediction\n",
    "    r2_list = [] # list stores root mean squared errors for each future time prediction\n",
    "    \n",
    "    # evaluate forecasts\n",
    "    rmse_list, mae_list, mape_list, r2_list = evaluate_forecasts(actual, forecasts, n_lag, n_seq)\n",
    "\n",
    "    for j in range(len(X_test)):\n",
    "        print(\"Weather Station \"+str(j+1)+\":\")\n",
    "        dataset_df = pd.DataFrame(y_test[j].flatten())\n",
    "        dataset = dataset_df.values\n",
    "        dataset = dataset[:, 0]\n",
    "        dataset = np.array(dataset).reshape(-1, 1)\n",
    "        dataset = dataset.flatten()\n",
    "        dataset = pd.DataFrame(dataset)\n",
    "        series = scaler[i].inverse_transform(dataset)\n",
    "        series = pd.Series(series.flatten())\n",
    "\n",
    "    # plot forecasts\n",
    "    plot_forecasts(series, forecasts, 1)\n",
    "    \n",
    "    best_model.summary()\n",
    "\n",
    "    # Print out table of actual and predicted values for each weather station\n",
    "    for j in range(11):\n",
    "        print(\"Weather Station \"+str(j+1)+\":\")\n",
    "        print(\"Actual Temp\\tPredicted Temp\\tDifference\")\n",
    "        print(\"-----------\\t--------------\\t----------\")\n",
    "        for k in range(n_seq):\n",
    "            diff = forecasts[j][k] - actual[j][k]\n",
    "            print(f\"{actual[j][k]:.2f}\\t\\t{forecasts[j][k]:.2f}\\t\\t{diff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e0a49-8fc2-4e2f-8bf4-7bb9dde70c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e54bcc-51b3-4db4-adf7-a8041e2b237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16289125-ffc3-4177-a011-ecba68a7ffe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ec920-1d52-457b-b12f-421c8bfa1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study, params=['optimizer', 'activation_function', 'lstm_units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2ed1d-7fe4-445f-91bc-135f6dec0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study, params=['lr', 'dropout_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c7a5a-83c7-4dac-9e14-04bbba312ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# fit the best LSTM model using parameters found by Optuna\n",
    "def create_best_model(X, y, n_lag, n_seq, n_batch, nb_epoch):\n",
    "    \n",
    "    #Parameters:\n",
    "    #trial (array-like): Optuna parameters.\n",
    "    #train (array-like): Target values.\n",
    "    #n_lag (int): Number of lag observations.\n",
    "    #n_seq (int): Number of sequence observations\n",
    "    #nb_epoch (int): Maximum number of epochs\n",
    "    \n",
    "    # Hyperparameters from the best model\n",
    "    lr = 0.0017884462854274694\n",
    "    optimizer = Adam(learning_rate = lr)\n",
    "    activation_function = 'sigmoid'\n",
    "    lstm_units = 256\n",
    "    dropout_rate = 0.24151358736199507\n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    #model.add(Conv1D(filters=filters, kernel_size=1, activation='relu', input_shape=(X.shape[1], X.shape[2]))) # CNN-LSTM only\n",
    "    model.add(LSTM(lstm_units, return_sequences=True, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, input_dim=y.shape[1], activation=activation_function))\n",
    "    model.add(Dense(128, activation=activation_function))\n",
    "    model.add(Dense(n_seq))\n",
    "    model.compile(loss=rmse, optimizer=optimizer, metrics=['accuracy', 'mae', rmse, mape, pearson])\n",
    "        \n",
    "    return model\n",
    "\n",
    "# make one forecast with an LSTM,\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def forecast_lstm(model, X, n_seq, n_test):\n",
    "    # reshape input pattern to [samples, timesteps, features]\n",
    "    X = X.reshape(1, 1, X.shape[1])\n",
    "    # make forecast\n",
    "    forecast = model.predict(X)\n",
    "    # convert to array\n",
    "    return forecast\n",
    "     \n",
    "# evaluate the persistence model\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def make_forecasts(model, X_test, y_test, n_lag, n_seq, n_test):\n",
    "    forecasts = list()\n",
    "    for i in range(len(X_test)):\n",
    "        X, y = X_test[i, :], y_test[i, :]\n",
    "        # make forecast\n",
    "        forecast = forecast_lstm(model, X, n_seq, n_test)\n",
    "        # store the forecast\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "     \n",
    "# invert differenced forecast\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def inverse_difference(last_ob, forecast):\n",
    "    # invert first forecast\n",
    "    inverted = list()\n",
    "    inverted.append(forecast[0] + last_ob)\n",
    "    # propagate difference forecast using inverted first value\n",
    "    for i in range(1, len(forecast)):\n",
    "        inverted.append(forecast[i] + inverted[i-1])\n",
    "    return inverted\n",
    "     \n",
    "# inverse data transform on forecasts\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def inverse_transform(series, forecasts, scaler, n_test, n_seq):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        # create array from forecast\n",
    "        forecast = forecasts[i]\n",
    "        forecast = forecast.reshape(1, n_seq)\n",
    "        # invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        # invert differencing\n",
    "        index = len(series) - n_test + i\n",
    "        last_ob = series.values[index]\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        # store\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    "     \n",
    "# evaluate the RMSE for each forecast time step\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    rmse_list = []\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    r2_list = []\n",
    "    for i in range(n_seq):\n",
    "        actual = [row[i] for row in test]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        mae = mean_absolute_error(actual, predicted)\n",
    "        mse = mean_squared_error(actual, predicted)\n",
    "        mape = mean_absolute_percentage_error(actual, predicted)\n",
    "        r2 = r2_score(actual, predicted) \n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        mape_list.append(mape)\n",
    "        r2_list.append(r2)\n",
    "        print(\"Year at t+\"+str(i+1)+\":\")\n",
    "        print('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "        print('t+%d MAE: %f' % ((i+1), mae))\n",
    "        print('t+%d MAPE: %f' % ((i+1), mape))\n",
    "        print('t+%d R2_SCORE: %f' % ((i+1), r2))\n",
    "\n",
    "    return rmse_list, mae_list, mape_list, r2_list\n",
    "     \n",
    "# plot the forecasts in the context of the original dataset\n",
    "#Taken from: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "def plot_forecasts(series, forecasts, n_test, n_seq, n_lag):\n",
    "    # plot the entire dataset in blue\n",
    "    plt.plot(series[:n_lag+2+len(forecasts)].index, series[:n_lag+2+len(forecasts)].values)\n",
    "    # plot the forecasts in red\n",
    "    off_s = n_lag + 1\n",
    "    off_e = off_s + len(forecasts) + 1\n",
    "    xaxis = [1998+x for x in range(off_s, off_e)]\n",
    "    yaxis = [series.values[off_s]] + forecasts\n",
    "    print(xaxis)\n",
    "    print(yaxis)\n",
    "    plt.plot(xaxis, yaxis, color='red')\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Temperature\")\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "n_batch = 1\n",
    "n_test = 2\n",
    "nb_epoch = 100\n",
    "    \n",
    "rmse_avg_list = []\n",
    "mae_avg_list = []\n",
    "mape_avg_list = []\n",
    "r2_score_avg_list = []\n",
    "forecast_results = []\n",
    "actual_results = []\n",
    "    \n",
    "for i in range(5):\n",
    "    train1 = train[i]\n",
    "    test1 = test[i]\n",
    "    validation1 = validation[i]\n",
    "\n",
    "    X = train1[:, 0:-n_seq]\n",
    "    y = train1[:, -n_seq:]\n",
    "    X_test = test1[:, 0:-n_seq]\n",
    "    y_test = test1[:, -n_seq:]\n",
    "    X_val = validation1[:, 0:-n_seq]\n",
    "    y_val = validation1[:, -n_seq:]\n",
    "    \n",
    "    dataset_df = pd.DataFrame(val_y[i])\n",
    "    dataset_df = dataset_df.iloc[0:2, :]\n",
    "    dataset = dataset_df.values\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    series = pd.Series(dataset[:, 0]) # Using first column (temperatures)\n",
    "\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    X1 = X_test\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "\n",
    "    best_model = create_best_model(X, y, n_lag, n_seq, n_batch, nb_epoch)\n",
    "    history = best_model.fit(X, y, epochs=100, batch_size=n_batch, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'Test Loss: {loss}')\n",
    "\n",
    "    # make forecasts\n",
    "    forecasts = make_forecasts(best_model, X_test, y_test, n_lag, n_seq, n_test)\n",
    "    \n",
    "    # inverse transform forecasts and test\n",
    "    forecasts = inverse_transform(series, forecasts, scaler[i], n_test, n_seq)\n",
    "    actual = [row[-n_seq:] for row in test1]\n",
    "    actual = inverse_transform(series, actual, scaler[i], n_test, n_seq)\n",
    "\n",
    "    rmse_list = [] # list stores root mean squared errors for each future time prediction\n",
    "    mae_list = [] # list stores root mean squared errors for each future time prediction\n",
    "    mape_list = [] # list stores root mean squared errors for each future time prediction\n",
    "    r2_list = [] # list stores root mean squared errors for each future time prediction\n",
    "\n",
    "    # evaluate forecasts\n",
    "    rmse_list, mae_list, mape_list, r2_list = evaluate_forecasts(actual, forecasts, n_lag, n_seq)\n",
    "\n",
    "    rmse_avg_list.append(rmse_list)\n",
    "    mae_avg_list.append(mae_list)\n",
    "    mape_avg_list.append(mape_list)\n",
    "    r2_score_avg_list.append(r2_list)\n",
    "    forecast_results.append(forecasts)\n",
    "    actual_results.append(actual)\n",
    "\n",
    "    for j in range(2):\n",
    "        print(\"Weather Station \"+str(j+1)+\":\")\n",
    "        print(\"Actual Temp\\tPredicted Temp\\tDifference\")\n",
    "        print(\"-----------\\t--------------\\t----------\")\n",
    "        for k in range(n_seq):\n",
    "            diff = forecasts[j][k] - actual[j][k]\n",
    "            print(f\"{actual[j][k]:.2f}\\t\\t{forecasts[j][k]:.2f}\\t\\t{diff:.2f}\")\n",
    "    \n",
    "        # plot forecasts\n",
    "        dataset_df = pd.DataFrame(val_y[i])\n",
    "        dataset_df = dataset_df.iloc[0:2, :]\n",
    "        dataset_df = dataset_df.transpose()\n",
    "        dataset = dataset_df.values\n",
    "\n",
    "        series_ws = pd.Series(dataset[:, j]) # Using first column (temperatures)\n",
    "        forecasts_ws = forecasts[j]\n",
    "\n",
    "        # Set index starting from 1998\n",
    "        series_ws.index = range(1998, 1998 + len(series_ws))        \n",
    "        \n",
    "        plot_forecasts(series_ws, forecasts_ws, n_test, n_seq, n_lag)\n",
    "\n",
    "    # Print out plots of actual and predicted values for weather stations\n",
    "    ws = [1,2]\n",
    "    print(ws)\n",
    "    a = []\n",
    "    f = []\n",
    "    for q in range(len(actual)):\n",
    "        x = actual[q]\n",
    "        a.append(x[0])\n",
    "    for q in range(len(forecasts)):\n",
    "        x = forecasts[q]\n",
    "        f.append(x[0])\n",
    "    print(a)\n",
    "    print(f)\n",
    "    # Create a DataFrame for plotting\n",
    "    results_df = pd.DataFrame({\n",
    "        'ws': ws,\n",
    "        'Actual': a,\n",
    "        'Predicted': f\n",
    "    })\n",
    "\n",
    "    for k in range(n_seq):\n",
    "        print(\"Predictions for (t+\"+str(k)+\"):\")\n",
    "        # Print out plots of actual and predicted values for each weather station\n",
    "        results = []\n",
    "\n",
    "        # Create a DataFrame for plotting\n",
    "        for j in range(2):\n",
    "            results.append([j, actual[j][k], forecasts[j][k]])\n",
    "               \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.columns = ['Weather_Station', 'Actual', 'Predicted']\n",
    "\n",
    "        print(results_df)\n",
    "            \n",
    "        # Plotting the results\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.scatter(results_df['Weather_Station'], results_df['Actual'], label='Actual')\n",
    "        plt.scatter(results_df['Weather_Station'], results_df['Predicted'], label='Predicted', alpha=0.7)\n",
    "        title1='LSTM Model Comparison Temperature Prediction (Fold='+str(i)+', n_seq='+str(n_seq)+', features=All)'\n",
    "        plt.title(title1)\n",
    "        plt.xlabel('Weather Station')\n",
    "        plt.ylabel('Temperature')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    best_model.summary()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    title2 = 'LSTM Training and Validation Loss (Fold='+str(i)+', n_seq='+str(n_seq)+', features=All)'\n",
    "    plt.title(title2)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "print(rmse_avg_list)\n",
    "print(mae_avg_list)\n",
    "print(mape_avg_list)\n",
    "print(r2_score_avg_list)\n",
    "print(forecast_results)\n",
    "print(actual_results)\n",
    "print(\"Accuracy Results:\")\n",
    "print(\"RMSE for each fold:\")\n",
    "print(rmse_avg_list)\n",
    "print(\"Average RMSE:\"+str(np.mean(rmse_avg_list)))\n",
    "print(\"Average MAE:\"+str(np.mean(mae_avg_list)))\n",
    "print(\"Average MAPE:\"+str(np.mean(mape_avg_list)))\n",
    "print(\"Average R2 Score:\"+str(np.mean(r2_score_avg_list)))\n",
    "\n",
    "# Plot model architecture\n",
    "filename = \"lstm_model_optimized_CV_S5.png\"\n",
    "plot_model(best_model, to_file=filename, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2698c0-5237-41ef-b2ee-cb7e2b833453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed648019-0f5f-4c80-97e4-a40c0ca88069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
